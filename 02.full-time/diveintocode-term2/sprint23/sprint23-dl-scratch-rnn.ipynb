{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint23課題 深層学習スクラッチRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "Sprint11で作成したディープニューラルネットワークのクラスを拡張する形でRNNを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T02:05:26.882897Z",
     "start_time": "2019-06-24T02:05:26.323800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】SimpleRNNのフォワードプロパゲーション実装\n",
    "SimpleRNNのクラスSimpleRNNを作成してください。基本構造はFCクラスと同じになります。\n",
    "\n",
    "今回はバッチサイズをbatch_size、入力の特徴量数をn_features、RNNのノード数をn_nodesとして表記します。活性化関数はtanhとして進めますが、これまでのニューラルネットワーク同様にReLUなどに置き換えられます。\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。ndarrayのshapeがどうなるかを併記しています。\n",
    "\n",
    "$$\n",
    "a_t = x_{t}\\cdot W_{x} + h_{t-1}\\cdot W_{h} + b\\\\\n",
    "h_t = tanh(a_t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T04:33:58.937869Z",
     "start_time": "2019-06-24T04:33:58.920302Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleRNN:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch_size : int\n",
    "      入力データのバッチサイズ\n",
    "    n_sequences : int\n",
    "      入力データの時系列数\n",
    "    n_features : int\n",
    "      入力データの特徴量数\n",
    "    n_nodes : int\n",
    "      RNNのノード数\n",
    "    W_x : ndarray, shape (n_features, n_nodes)\n",
    "        入力に対する重み\n",
    "    W_h : ndarray, shape (n_nodes, n_nodes)\n",
    "        状態に対する重み\n",
    "    B : ndarray, shape(1,)\n",
    "        バイアス項\n",
    "    initializer : 初期化方法のインスタンス(今回は未使用)\n",
    "    optimizer : 最適化手法のインスタンス(今回は未使用)\n",
    "    \n",
    "    Attribute\n",
    "    ------------\n",
    "    self.H : ndarray, shape  (batch_size, n_nodes)\n",
    "        時刻tの状態・出力\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, batch_size, n_sequences, n_fetures, n_nodes, \n",
    "                         initializer, optimizer, W_x=None, W_h=None, B=None):\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        self.n_sequences = n_sequences\n",
    "        \n",
    "        # を初期化する\n",
    "        if W_x is None:\n",
    "            self.W_x = initializer.W(n_features, n_nodes)\n",
    "        else:\n",
    "            self.W_x = W_x\n",
    "            \n",
    "        if W_h is None:\n",
    "            self.W_h = initializer.W(n_nodes, n_nodes)\n",
    "        else:\n",
    "            self.W_h = W_h\n",
    "            \n",
    "        if B is None:\n",
    "            self.B = initializer.B(1)\n",
    "        else:\n",
    "            self.B = B\n",
    "            \n",
    "        self.H = np.zeros((batch_size, n_nodes))\n",
    "                    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_sequences, n_features)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        H : 次の形のndarray, shape (batch_size, n_nodes)\n",
    "            出力\n",
    "        \"\"\"                \n",
    "        for t in range(self.n_sequences):\n",
    "            A = X[:, t] @ self.W_x + self.H @ self.W_h + self.B\n",
    "            self.H = np.tanh(A)\n",
    "        \n",
    "        return self.H\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】小さな配列でのフォワードプロパゲーションの実験\n",
    "小さな配列でフォワードプロパゲーションを考えてみます。\n",
    "\n",
    "入力x、初期状態h、重みw_xとw_h、バイアスbを次のようにします。\n",
    "\n",
    "ここで配列xの軸はバッチサイズ、系列数、特徴量数の順番です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T04:34:00.079329Z",
     "start_time": "2019-06-24T04:34:00.067922Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100\n",
    "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100\n",
    "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100\n",
    "batch_size = x.shape[0] # 1\n",
    "n_sequences = x.shape[1] # 3\n",
    "n_features = x.shape[2] # 2\n",
    "n_nodes = w_x.shape[1] # 4\n",
    "h = np.zeros((batch_size, n_nodes))\n",
    "b = np.array([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フォワードプロパゲーションの出力が次のようになることを作成したコードで確認してください。\n",
    "\n",
    "```python\n",
    "h = np.array([[0.79494228, 0.81839002, 0.83939649, 0.85584174]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T04:34:01.903329Z",
     "start_time": "2019-06-24T04:34:01.897504Z"
    }
   },
   "outputs": [],
   "source": [
    "srnn = SimpleRNN(\n",
    "    batch_size=batch_size, \n",
    "    n_sequences=n_sequences, \n",
    "    n_fetures=n_features, \n",
    "    n_nodes=n_nodes,\n",
    "    initializer=None, \n",
    "    optimizer=None, \n",
    "    W_x=w_x, \n",
    "    W_h=w_h, \n",
    "    B=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T04:34:02.589945Z",
     "start_time": "2019-06-24T04:34:02.573595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79494228, 0.81839002, 0.83939649, 0.85584174]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srnn.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】（アドバンス課題）バックプロパゲーションの実装\n",
    "バックプロパゲーションを実装します。\n",
    "\n",
    "RNNの内部は全結合層を組み合わせた形になっているので、更新式は全結合層などと同様です。\n",
    "\n",
    "**※省略**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】（アドバンス課題）データセットでの学習・推定\n",
    "これまで使ってきたニューラルネットワークにSimpleRNNを組み込み学習させ、動くことを確認してください。\n",
    "\n",
    "[IMDB Review Dataset | Kaggle](https://www.kaggle.com/utathya/imdb-review-dataset)\n",
    "\n",
    "映画レビューデータセットを使用します。ベクトル化を行い、作成したRNNに入力してください。\n",
    "\n",
    "**※省略**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
