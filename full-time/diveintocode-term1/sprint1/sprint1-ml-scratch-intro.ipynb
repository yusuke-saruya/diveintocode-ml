{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint1課題　機械学習フロー"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】クロスバリデーション\n",
    "事前学習期間は検証用データを分割しておき、それに対して指標値を計算することで検証を行っていました。しかし、分割の仕方により精度は変化します。実践的には クロスバリデーション を行います。\n",
    "\n",
    "具体的には分割を複数回行い、それぞれに対して学習と検証を行う方法です。複数回の分割を行う関数はscikit-learnにKFoldとして用意されています。\n",
    "\n",
    "[sklearn.model_selection.KFold — scikit-learn 0.20.2 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】グリッドサーチ\n",
    "これまで分類器のパラメータは基本的にデフォルトの設定を使用していました。パラメータの詳細は今後のSprintで学んでいくことになりますが、パラメータは状況に応じて最適なものを選ぶ必要があります。パラメータを探索するために グリッドサーチ と呼ばれる総当たり的手法が一般的に利用されます。\n",
    "\n",
    "グリッドサーチをパイプラインの中に組み込みましょう。\n",
    "\n",
    "**※問題1と問題2の内容を同じプログラム内に組み込んでいます**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"\n",
    " ライブラリのインポート\n",
    " \"\"\"\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.csvの読み込み\n",
    "df_train = pd.read_csv(\"application_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXT_SOURCRに着目する\n",
    "X_train_EX = df_train.loc[:, ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']]\n",
    "\n",
    "# それぞれの欠損値に対しては平均代入法を利用する\n",
    "X_train_EX[\"EXT_SOURCE_1\"] = X_train_EX[\"EXT_SOURCE_1\"].fillna(X_train_EX[\"EXT_SOURCE_1\"].mean())\n",
    "X_train_EX[\"EXT_SOURCE_2\"] = X_train_EX[\"EXT_SOURCE_2\"].fillna(X_train_EX[\"EXT_SOURCE_2\"].mean())\n",
    "X_train_EX[\"EXT_SOURCE_3\"] = X_train_EX[\"EXT_SOURCE_3\"].fillna(X_train_EX[\"EXT_SOURCE_3\"].mean())\n",
    "\n",
    "#numpyに変更\n",
    "X= X_train_EX.values\n",
    "y = df_train['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#StratifiedKFoldの設定\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "# KFoldの設定\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#パラメータよりクロスバリデーション、グリッドサーチを実行する\n",
    "def cv_gs_skf(estimators, parameters):\n",
    "\n",
    "    # plを一つの分類器としてみなす\n",
    "    pl = Pipeline(estimators)\n",
    "\n",
    "    # 分類器を渡し、グリッドサーチのインスタンス生成\n",
    "    clf = GridSearchCV(pl, parameters, n_jobs=-1, cv=3)\n",
    "    \n",
    "    print(\"<StratifiedKFold>\")\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "        clf.fit(X[train_index], y[train_index]) \n",
    "\n",
    "        # ベストパラメータを出力\n",
    "        print('Best_estimator = {0}'.format(clf.best_params_))\n",
    "\n",
    "        # auc算出\n",
    "        lr_auc = roc_auc_score(y[test_index], clf.predict_proba(X[test_index])[:, 1])\n",
    "        print(\"classifier_auc: {}\".format(lr_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#パラメータよりクロスバリデーション、グリッドサーチを実行する\n",
    "def cv_gs_kf(estimators, parameters):\n",
    "\n",
    "    # plを一つの分類器としてみなす\n",
    "    pl = Pipeline(estimators)\n",
    "\n",
    "    # 分類器を渡し、グリッドサーチのインスタンス生成\n",
    "    clf = GridSearchCV(pl, parameters, n_jobs=-1, cv=3)\n",
    "    \n",
    "    print(\"<KFold>\")\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "        # 優れたハイパーパラメーターを探索\n",
    "        clf.fit(X[train_index], y[train_index])\n",
    "\n",
    "        # ベストパラメータを出力\n",
    "        print('Best_estimator = {0}'.format(clf.best_params_))\n",
    "\n",
    "        # auc算出\n",
    "        lr_auc = roc_auc_score(y[test_index], clf.predict_proba(X[test_index])[:, 1])\n",
    "        print(\"classifier_auc: {}\".format(lr_auc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ロジスティック回帰でクロスバリデーション&グリッドサーチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StratifiedKFold>\n",
      "Best_estimator = {'lr__C': 0.0774263682681127, 'lr__penalty': 'l1', 'lr__solver': 'liblinear', 'pca__n_components': 2}\n",
      "classifier_auc: 0.7160107649299055\n",
      "Best_estimator = {'lr__C': 1e-05, 'lr__penalty': 'l2', 'lr__solver': 'liblinear', 'pca__n_components': 2}\n",
      "classifier_auc: 0.7120298466816025\n",
      "Best_estimator = {'lr__C': 0.4641588833612782, 'lr__penalty': 'l1', 'lr__solver': 'liblinear', 'pca__n_components': 2}\n",
      "classifier_auc: 0.7197282371087573\n",
      "<KFold>\n",
      "Best_estimator = {'lr__C': 0.0774263682681127, 'lr__penalty': 'l1', 'lr__solver': 'liblinear', 'pca__n_components': 2}\n",
      "classifier_auc: 0.7161065322942142\n",
      "Best_estimator = {'lr__C': 1e-05, 'lr__penalty': 'l2', 'lr__solver': 'liblinear', 'pca__n_components': 2}\n",
      "classifier_auc: 0.711820492892695\n",
      "Best_estimator = {'lr__C': 0.01291549665014884, 'lr__penalty': 'l1', 'lr__solver': 'saga', 'pca__n_components': 2}\n",
      "classifier_auc: 0.7197081757226581\n"
     ]
    }
   ],
   "source": [
    "# PCAで次元削減、ロジスティック回帰での分類\n",
    "estimators = [('pca', PCA()),\n",
    "              ('lr', LogisticRegression())]\n",
    "\n",
    "# グリッドサーチでの探索パラメータ\n",
    "parameters = {\"pca__n_components\" : range(2, 3),\n",
    "              \"lr__penalty\" : [\"l2\", \"l1\"],\n",
    "              'lr__C': np.logspace(-5, 2, 10).tolist(), \n",
    "              'lr__solver' : ['liblinear', 'saga']\n",
    "             }\n",
    "\n",
    "#パラメータよりクロスバリデーション、グリッドサーチを実行する\n",
    "cv_gs_skf(estimators, parameters)\n",
    "\n",
    "#パラメータよりクロスバリデーション、グリッドサーチを実行する\n",
    "cv_gs_kf(estimators, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K近傍法でクロスバリデーション&グリッドサーチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StratifiedKFold>\n",
      "Best_estimator = {'kn__n_neighbors': 30, 'pca__n_components': 2}\n",
      "classifier_auc: 0.6676570894220896\n",
      "Best_estimator = {'kn__n_neighbors': 50, 'pca__n_components': 2}\n",
      "classifier_auc: 0.6834363543028925\n",
      "Best_estimator = {'kn__n_neighbors': 70, 'pca__n_components': 2}\n",
      "classifier_auc: 0.6956131954543117\n",
      "<KFold>\n",
      "Best_estimator = {'kn__n_neighbors': 30, 'pca__n_components': 2}\n",
      "classifier_auc: 0.6674848615518618\n",
      "Best_estimator = {'kn__n_neighbors': 50, 'pca__n_components': 2}\n",
      "classifier_auc: 0.6831681990226973\n",
      "Best_estimator = {'kn__n_neighbors': 70, 'pca__n_components': 2}\n",
      "classifier_auc: 0.696003084983554\n"
     ]
    }
   ],
   "source": [
    "#KNeighborsClassifierのインポート\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# PCAで次元削減、ロジスティック回帰での分類\n",
    "estimators = [('pca', PCA()),\n",
    "              ('kn', KNeighborsClassifier())]\n",
    "\n",
    "# グリッドサーチでの探索パラメータ\n",
    "parameters = {\"pca__n_components\" : range(2, 3),\n",
    "              \"kn__n_neighbors\" : [30, 40, 50, 60, 70, 80]\n",
    "             }\n",
    "\n",
    "#パラメータよりクロスバリデーション、グリッドサーチを実行する\n",
    "cv_gs_skf(estimators, parameters)\n",
    "\n",
    "#パラメータよりクロスバリデーション、グリッドサーチを実行する\n",
    "cv_gs_kf(estimators, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVCでクロスバリデーション&グリッドサーチ\n",
    "カーネル法有りのSVMでは処理が終わらない。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StratifiedKFold>\n",
      "Best_estimator = {'pca__n_components': 2, 'svc__C': 1e-07, 'svc__loss': 'hinge', 'svc__random_state': 1}\n",
      "classifier_auc: 0.7148936945698176\n",
      "Best_estimator = {'pca__n_components': 2, 'svc__C': 1e-07, 'svc__loss': 'hinge', 'svc__random_state': 1}\n",
      "classifier_auc: 0.7120135823895499\n",
      "Best_estimator = {'pca__n_components': 2, 'svc__C': 1e-07, 'svc__loss': 'hinge', 'svc__random_state': 1}\n",
      "classifier_auc: 0.7182900452165455\n",
      "<KFold>\n",
      "Best_estimator = {'pca__n_components': 2, 'svc__C': 1e-07, 'svc__loss': 'hinge', 'svc__random_state': 1}\n",
      "classifier_auc: 0.7150504299084475\n",
      "Best_estimator = {'pca__n_components': 2, 'svc__C': 1e-07, 'svc__loss': 'hinge', 'svc__random_state': 1}\n",
      "classifier_auc: 0.7118030288664075\n",
      "Best_estimator = {'pca__n_components': 2, 'svc__C': 1e-07, 'svc__loss': 'hinge', 'svc__random_state': 1}\n",
      "classifier_auc: 0.7183891636752728\n"
     ]
    }
   ],
   "source": [
    "#LinearSVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "# PCAで次元削減、ロジスティック回帰での分類\n",
    "estimators = [('pca', PCA()),\n",
    "              ('svc', LinearSVC())]\n",
    "\n",
    "# グリッドサーチでの探索パラメータ\n",
    "parameters = {\"pca__n_components\" : range(2, 3),\n",
    "              'svc__C' : np.logspace(-7, 3, 9).tolist(), \n",
    "              \"svc__loss\" : ['hinge', 'squared_hinge'],               \n",
    "              'svc__random_state' : [1]\n",
    "             }\n",
    "\n",
    "#パラメータよりクロスバリデーション、グリッドサーチを実行する\n",
    "cv_gs_skf(estimators, parameters)\n",
    "\n",
    "#パラメータよりクロスバリデーション、グリッドサーチを実行する\n",
    "cv_gs_kf(estimators, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 決定木でクロスバリデーション&グリッドサーチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StratifiedKFold>\n",
      "Best_estimator = {'dtc__criterion': 'entropy', 'dtc__min_samples_split': 4800, 'pca__n_components': 2}\n",
      "classifier_auc: 0.707682443865701\n",
      "Best_estimator = {'dtc__criterion': 'gini', 'dtc__min_samples_split': 4800, 'pca__n_components': 2}\n",
      "classifier_auc: 0.7064086081478116\n",
      "Best_estimator = {'dtc__criterion': 'gini', 'dtc__min_samples_split': 4900, 'pca__n_components': 2}\n",
      "classifier_auc: 0.7133792554589261\n",
      "<KFold>\n",
      "Best_estimator = {'dtc__criterion': 'entropy', 'dtc__min_samples_split': 4900, 'pca__n_components': 2}\n",
      "classifier_auc: 0.7079778810564739\n",
      "Best_estimator = {'dtc__criterion': 'gini', 'dtc__min_samples_split': 4900, 'pca__n_components': 2}\n",
      "classifier_auc: 0.7092478394685067\n",
      "Best_estimator = {'dtc__criterion': 'entropy', 'dtc__min_samples_split': 4900, 'pca__n_components': 2}\n",
      "classifier_auc: 0.7140699018865326\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifierのインポート\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "estimators = [('pca', PCA()),\n",
    "              ('dtc', DecisionTreeClassifier())]\n",
    "\n",
    "# グリッドサーチでの探索パラメータ\n",
    "parameters = {\"pca__n_components\" : range(2, 3),\n",
    "              'dtc__criterion' : ['gini', 'entropy'], \n",
    "              \"dtc__min_samples_split\" : range(3000, 5000, 100)\n",
    "             }\n",
    "\n",
    "#パラメータよりクロスバリデーション、グリッドサーチを実行する\n",
    "cv_gs_skf(estimators, parameters)\n",
    "\n",
    "#パラメータよりクロスバリデーション、グリッドサーチを実行する\n",
    "cv_gs_kf(estimators, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ランダムフォレストでクロスバリデーション&グリッドサーチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StratifiedKFold>\n",
      "Best_estimator = {'pca__n_components': 2, 'rfc__min_samples_split': 4000, 'rfc__n_estimators': 100}\n",
      "classifier_auc: 0.7159504432843572\n",
      "Best_estimator = {'pca__n_components': 2, 'rfc__min_samples_split': 4000, 'rfc__n_estimators': 100}\n",
      "classifier_auc: 0.7140886313502693\n",
      "Best_estimator = {'pca__n_components': 2, 'rfc__min_samples_split': 4000, 'rfc__n_estimators': 100}\n",
      "classifier_auc: 0.720657926579575\n",
      "<KFold>\n",
      "Best_estimator = {'pca__n_components': 2, 'rfc__min_samples_split': 4000, 'rfc__n_estimators': 100}\n",
      "classifier_auc: 0.7160470858304945\n",
      "Best_estimator = {'pca__n_components': 2, 'rfc__min_samples_split': 4000, 'rfc__n_estimators': 100}\n",
      "classifier_auc: 0.7135468823189142\n",
      "Best_estimator = {'pca__n_components': 2, 'rfc__min_samples_split': 4000, 'rfc__n_estimators': 100}\n",
      "classifier_auc: 0.7206130278066046\n"
     ]
    }
   ],
   "source": [
    "#RandomForestClassifierのインポート\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimators = [('pca', PCA()),\n",
    "              ('rfc', RandomForestClassifier())]\n",
    "\n",
    "# グリッドサーチでの探索パラメータ\n",
    "parameters = {\"pca__n_components\" : range(2, 3),\n",
    "              'rfc__n_estimators' : [100], \n",
    "              'rfc__min_samples_split' : [4000]\n",
    "             }\n",
    "\n",
    "#パラメータよりクロスバリデーション、グリッドサーチを実行する\n",
    "cv_gs_skf(estimators, parameters)\n",
    "\n",
    "#パラメータよりクロスバリデーション、グリッドサーチを実行する\n",
    "cv_gs_kf(estimators, parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### わずかであるが、ランダムフォレストのスコア(AUC)が高い結果を得られた。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】Kernelからの調査\n",
    "KaggleのKernelから自身にはなかったアイデアを見つけ出して、列挙してください。そして、効果があると考えられるものを検証してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下記の特徴量で検証\n",
    "1. ３つのEXT_SOURCEに対して重み付けをつけた特徴量\n",
    "1. ３つのEXT_SOURCEにおける行ごとの最小値\n",
    "1. ３つのEXT_SOURCEにおける行ごとの最大値\n",
    "1. \"DAYS_EMPLOYED\"(重要度が高い)  \n",
    "1. \"AMT_CREDIT\"(重要度が高い)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_EX2 = pd.DataFrame([])\n",
    "\n",
    "#重み付け\n",
    "a = 2\n",
    "b = 9\n",
    "c = 4\n",
    "\n",
    "#重み付けした\n",
    "X_train_EX2['EXT_SOURCE_WEIGH'] = (\n",
    "    X_train_EX['EXT_SOURCE_1'] * a + \n",
    "    X_train_EX['EXT_SOURCE_2'] * b + \n",
    "    X_train_EX['EXT_SOURCE_3'] * c\n",
    ") / (a + b + c)\n",
    "\n",
    "X_train_EX2['EXT_SOURCE_MAX'] = X_train_EX.max(axis='columns')\n",
    "X_train_EX2['EXT_SOURCE_MIN'] = X_train_EX.min(axis='columns')\n",
    "X_train_EX2['DAYS_EMPLOYED'] = df_train[\"DAYS_EMPLOYED\"]\n",
    "X_train_EX2['AMT_CREDIT'] = df_train[\"AMT_CREDIT\"]\n",
    "\n",
    "#numpyに変更\n",
    "X = X_train_EX2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StratifiedKFold>\n",
      "classifier_auc: 0.7244520052408318\n",
      "classifier_auc: 0.7264711391043173\n",
      "classifier_auc: 0.7218832497842361\n",
      "classifier_auc: 0.7283765565495782\n",
      "classifier_auc: 0.7289927880290354\n"
     ]
    }
   ],
   "source": [
    "#RandomForestClassifierのインポート\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#StandardScalerをインポート\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(min_samples_split=4000, n_estimators=100)\n",
    "\n",
    "print(\"<StratifiedKFold>\")\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    #インスタンス生成\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #学習用データに対してfit\n",
    "    #渡されたデータの最大値、最小値、平均、標準偏差、傾き...などの統計を取得して、内部メモリに保存する。\n",
    "    scaler.fit(X[train_index])\n",
    "\n",
    "    #学習用・検証用データにに対してtransform\n",
    "    #fit()で取得した統計情報を使って、渡されたデータを実際に書き換える。\n",
    "    X_train_transform = scaler.transform(X[train_index])\n",
    "    X_test_transform = scaler.transform(X[test_index])\n",
    "\n",
    "    clf.fit(X[train_index], y[train_index]) \n",
    "\n",
    "    # auc算出\n",
    "    lr_auc = roc_auc_score(y[test_index], clf.predict_proba(X[test_index])[:, 1])\n",
    "    print(\"classifier_auc: {}\".format(lr_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 121)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test.csvの読み込み\n",
    "df_test = pd.read_csv(\"application_test.csv\")\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "testデータの処理\n",
    "'''\n",
    "# EXT_SOURCEに着目する\n",
    "X_test_EX = df_test.loc[:, ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']]\n",
    "\n",
    "# それぞれの欠損値に対しては平均代入法を利用する\n",
    "X_test_EX[\"EXT_SOURCE_1\"] = X_test_EX[\"EXT_SOURCE_1\"].fillna(X_test_EX[\"EXT_SOURCE_1\"].mean())\n",
    "X_test_EX[\"EXT_SOURCE_2\"] = X_test_EX[\"EXT_SOURCE_2\"].fillna(X_test_EX[\"EXT_SOURCE_2\"].mean())\n",
    "X_test_EX[\"EXT_SOURCE_3\"] = X_test_EX[\"EXT_SOURCE_3\"].fillna(X_test_EX[\"EXT_SOURCE_3\"].mean())\n",
    "\n",
    "X_test_EX2 = pd.DataFrame([])\n",
    "\n",
    "#重み付け\n",
    "a = 2\n",
    "b = 10\n",
    "c = 7\n",
    "\n",
    "#重み付けした\n",
    "X_test_EX2['EXT_SOURCE_WEIGH'] = (\n",
    "    X_test_EX['EXT_SOURCE_1'] * a + \n",
    "    X_test_EX['EXT_SOURCE_2'] * b + \n",
    "    X_test_EX['EXT_SOURCE_3'] * c\n",
    ") / (a + b + c)\n",
    "\n",
    "X_test_EX2['EXT_SOURCE_MAX'] = X_test_EX.max(axis='columns')\n",
    "X_test_EX2['EXT_SOURCE_MIN'] = X_test_EX.min(axis='columns')\n",
    "X_test_EX2['DAYS_EMPLOYED'] = df_test[\"DAYS_EMPLOYED\"]\n",
    "X_test_EX2['AMT_CREDIT'] = df_test[\"AMT_CREDIT\"]\n",
    "\n",
    "#numpyに変更\n",
    "X_test = X_test_EX2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle提出用のdataframeを作成する\n",
    "submission = pd.DataFrame({'SK_ID_CURR': df_test['SK_ID_CURR'], 'TARGET': clf.predict_proba(X_test)[:, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle提出用のcsvファイルを作成する\n",
    "submission.to_csv('HomeCreditDefaultRisk_2019043005.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kaggleへの提出結果\n",
    "- Private Score : 0.70689\n",
    "- Public Score : 0.71441\n",
    "\n",
    "→train_data内でのクロスバリデーションよりも0.02〜0.03ほど低い結果となった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】高い汎化性能のモデル\n",
    "これまで学んだことを用いながら汎化性能の高いモデルを作成してください。今は全体の流れを掴むことを重視し、Sprintの時間内に結果を出すということも意識しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBMを用いた検証\n",
    "問題3で作成したランダムフォレストより汎化性能が高くなるか検証を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgb.LGBMClassifier(num_leaves=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StratifiedKFold>\n",
      "Best_estimator = {'lgb__num_leaves': 7}\n",
      "classifier_auc: 0.7281658047308912\n",
      "Best_estimator = {'lgb__num_leaves': 22}\n",
      "classifier_auc: 0.7299289251550388\n",
      "Best_estimator = {'lgb__num_leaves': 27}\n",
      "classifier_auc: 0.725271760558339\n",
      "Best_estimator = {'lgb__num_leaves': 22}\n",
      "classifier_auc: 0.7316000798771085\n",
      "Best_estimator = {'lgb__num_leaves': 12}\n",
      "classifier_auc: 0.7333050564379224\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "              ('lgb', lgb.LGBMClassifier())]\n",
    "\n",
    "# グリッドサーチでの探索パラメータ\n",
    "parameters = {\n",
    "              'lgb__num_leaves' : range(2,50,5)\n",
    "             }\n",
    "\n",
    "#パラメータよりクロスバリデーション、グリッドサーチを実行する\n",
    "cv_gs_skf(estimators, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StratifiedKFold>\n",
      "classifier_auc: 0.728428405609937\n",
      "classifier_auc: 0.7293840832624273\n",
      "classifier_auc: 0.7270026075839685\n",
      "classifier_auc: 0.7310837036894143\n",
      "classifier_auc: 0.732328615607197\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(num_leaves=10)\n",
    "\n",
    "print(\"<StratifiedKFold>\")\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    clf.fit(X[train_index], y[train_index]) \n",
    "\n",
    "    # auc算出\n",
    "    lr_auc = roc_auc_score(y[test_index], clf.predict_proba(X[test_index])[:, 1])\n",
    "    print(\"classifier_auc: {}\".format(lr_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle提出用のdataframeを作成する\n",
    "submission = pd.DataFrame({'SK_ID_CURR': df_test['SK_ID_CURR'], 'TARGET': clf.predict_proba(X_test)[:, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle提出用のcsvファイルを作成する\n",
    "submission.to_csv('HomeCreditDefaultRisk_2019043007.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kaggleへの提出結果\n",
    "- Private Score :　0.70838\n",
    "- Public Score : 0.71503\n",
    "\n",
    "→ランダムフォレストを使用した際よりもわずかに数値が上がったが、大きな変化はなし。  \n",
    "　ランダムフォレストと同様、train_data内でのクロスバリデーションよりも0.02〜0.03ほど低い結果となった。\n",
    "\n",
    "### まとめ\n",
    "今回は利用するモデル・ハイパーパラメータの比較を重点的に実施。パラーメータの設定によりスコアに差異が発生することを確認し、そん中でクロスバリデーションを実施することができた。\n",
    "モデルにより、処理時間に大きく違いがあり、今後の参考としたい。\n",
    "今回特徴量の改善が部分的であったため、より大きな改善を行うためにも特徴量に対する検証も必要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
