{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint21課題 セグメンテーション2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】コードレビュー\n",
    "転移学習を使用してセグメンテーションの精度を改善したコードを提示するので、レビューを行ってください。\n",
    "\n",
    "視点例\n",
    "\n",
    "- Sprint20で使用した実装とはどのように違うのか\n",
    "- 転移学習をどのように行っているか\n",
    "\n",
    "\n",
    "### 03-models_pretrained_and_more.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:19:16.783818Z",
     "start_time": "2019-07-14T06:19:16.767428Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:19:19.265660Z",
     "start_time": "2019-07-14T06:19:19.261392Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:19:20.128022Z",
     "start_time": "2019-07-14T06:19:20.112753Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:19:22.155780Z",
     "start_time": "2019-07-14T06:19:21.917240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('sample_submission.csv')\n",
    "depth = pd.read_csv('depths.csv')\n",
    "\n",
    "train_src = '../input/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:19:52.284026Z",
     "start_time": "2019-07-14T06:19:22.954949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:19:53.043336Z",
     "start_time": "2019-07-14T06:19:52.289027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efe189cf860>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:19:53.109459Z",
     "start_time": "2019-07-14T06:19:53.046012Z"
    }
   },
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:21:04.085394Z",
     "start_time": "2019-07-14T06:19:53.115328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
      "(804, 224, 224, 3) (804, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:21:04.157747Z",
     "start_time": "2019-07-14T06:21:04.095251Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T09:11:41.921073Z",
     "start_time": "2019-07-12T09:11:41.868550Z"
    }
   },
   "source": [
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:21:04.186447Z",
     "start_time": "2019-07-14T06:21:04.161143Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:21:04.210220Z",
     "start_time": "2019-07-14T06:21:04.190222Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('activation_1').output\n",
    "    encoder2 = base_model.get_layer('activation_10').output\n",
    "    encoder3 = base_model.get_layer('activation_22').output\n",
    "    encoder4 = base_model.get_layer('activation_40').output\n",
    "    encoder5 = base_model.get_layer('activation_49').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T09:14:57.142904Z",
     "start_time": "2019-07-12T09:14:29.021159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 42,912,065\n",
      "Trainable params: 42,856,833\n",
      "Non-trainable params: 55,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_resnet(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T09:24:10.624793Z",
     "start_time": "2019-07-12T09:15:06.366640Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 48,978,353\n",
      "Trainable params: 48,919,953\n",
      "Non-trainable params: 58,400\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3196 samples, validate on 804 samples\n",
      "Epoch 1/2\n",
      "3196/3196 [==============================] - 275s 86ms/step - loss: 0.7980 - my_iou_metric: 0.3218 - val_loss: 1.5171 - val_my_iou_metric: 0.2871\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.28706, saving model to unet_resnet.h5\n",
      "Epoch 2/2\n",
      "3196/3196 [==============================] - 241s 76ms/step - loss: 0.5960 - my_iou_metric: 0.4633 - val_loss: 1.1016 - val_my_iou_metric: 0.3910\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.28706 to 0.39104, saving model to unet_resnet.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T11:48:06.542921Z",
     "start_time": "2019-07-12T11:47:18.506765Z"
    }
   },
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:21:04.243573Z",
     "start_time": "2019-07-14T06:21:04.216054Z"
    }
   },
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:42<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.4917 at threshold: 0.880\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.431315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.029006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.390796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.412065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.424627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.444963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.491667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.431315\n",
       "std     0.204939   0.029006\n",
       "min     0.200000   0.390796\n",
       "25%     0.370000   0.412065\n",
       "50%     0.540000   0.424627\n",
       "75%     0.710000   0.444963\n",
       "max     0.880000   0.491667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efd1bc27438>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "ja"
   },
   "source": [
    "##結論：\n",
    "\n",
    " - 事前学習モデルはセグメンテーション問題に使用できます。\n",
    "     - いくつかのアーキテクチャは問題に容易に適応することができます（すなわちResNet）\n",
    "     - 他のアーキテクチャでは、特徴抽出とパディングのために適切なレイヤを選択することでより多くの実験が必要になるかもしれません（[Xception]の使用例（https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using） -kaggle-kernel））\n",
    "     - 特徴抽出のためのレイヤーの選択を試すことができます\n",
    "     - モデルによっては、エンコーダ/デコーダブロックの数を試してみることもできます。\n",
    " - しきい値最適化は、トレーニング中の直接メトリック最適化が難しい問題で重要です。\n",
    "     - より複雑な最適化方法（[scipy optimize]（https://docs.scipy.org/doc/scipy/reference/optimize.html）から）を使用することは可能ですが、これは電車や電車の配テストセットはよく似ています。検証セット上の閾値または他の任意のパラメータの過剰最適化は、より悪いテストセット結果をもたらし得る。\n",
    " - さまざまな損失を試してください -  BCE、Dice、BCEとDiceを組み合わせた、Lovashの損失。\n",
    "     - さまざまな損失でトレーニングされたモデルは異なる結果をもたらす可能性があります。これは、組み合わせる場合に有利になる可能性があります。\n",
    "\n",
    "\n",
    "###可能な実験：\n",
    "\n",
    " - 作成したセグメンテーションモデルのデコーダブロックの種類を変更する\n",
    " - あなた自身のデコーダブロックを作成する\n",
    " - 他の損失との訓練\n",
    " - もっと長い列車\n",
    " -  BCE / Diceでトレーニングし、モデルを保存してから、Lovash損失でウェイトをロードして微調整します\n",
    " - しきい値の最適化のためにさまざまな範囲と間隔を試す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprint20で使用した実装とはどのように違うのか\n",
    "- sprint20で使用した実装(U-Net)\n",
    "    - Encoder部分\n",
    "        - ４層畳み込み構造\n",
    "    - Decoder部分\n",
    "        - 4層畳み込み構造\n",
    "    - skip接続\n",
    "        - 上記のEncoder, Decoderの層ごとに特徴マップを連結している\n",
    "- sprint21で使用した実装(U-Net & Resnet)\n",
    "    - Encoder部分\n",
    "        - ResNet50モデルを用いて５０構造としている。\n",
    "    - Decoder部分\n",
    "        - 今回学習に利用したモデルではResnetの残差ブロックにおける　bottleneckアーキテクチャを利用している\n",
    "        - 4層のbottleneckアーキテクチャを採用している\n",
    "    - skip接続\n",
    "        - 1、10、22、40,49層目の特徴マップを抽出して、それぞれをDecoder部分へ連結している\n",
    "\n",
    "\n",
    "### 転移学習をどのように行っているか\n",
    "\n",
    "- ベースモデルとして\n",
    "下記のResnetモデルよりimagenet事前学習済みモデルの読み込みを行う\n",
    "\n",
    "```python\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "\n",
    "```\n",
    "\n",
    "- 読み込んだ事前学習済みモデルはU-NetのEncoder部分として扱い、Decodet部分にResnet残差ブロック層を構築して転移学習を行っている\n",
    "\n",
    "```python\n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('activation_1').output\n",
    "    encoder2 = base_model.get_layer('activation_10').output\n",
    "    encoder3 = base_model.get_layer('activation_22').output\n",
    "    encoder4 = base_model.get_layer('activation_40').output\n",
    "    encoder5 = base_model.get_layer('activation_49').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】コードの書き換え\n",
    "エンコーダーにResNetが使用されていたコードをVGGに変更してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:05:44.456123Z",
     "start_time": "2019-07-14T06:05:38.683627Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg_model = VGG19(\n",
    "    include_top=True, \n",
    "    weights='imagenet', \n",
    "    input_tensor=None, \n",
    "    input_shape=None, \n",
    "    pooling=None, \n",
    "    classes=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:05:24.846129Z",
     "start_time": "2019-07-14T06:05:24.805316Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:14:44.308562Z",
     "start_time": "2019-07-14T06:14:44.290707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_vgg(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = VGG19(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('block1_conv2').output\n",
    "    encoder2 = base_model.get_layer('block2_conv2').output\n",
    "    encoder3 = base_model.get_layer('block3_conv4').output\n",
    "    encoder4 = base_model.get_layer('block4_conv4').output\n",
    "    encoder5 = base_model.get_layer('block5_conv4').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    \n",
    "    # ここを退避しないとInvalidArgumentError\n",
    "    # output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        concat1, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】学習・推定\n",
    "ResNetとVGG双方のコードで学習・推定を行い、結果を比較してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T06:18:14.026878Z",
     "start_time": "2019-07-14T06:17:28.991438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 14, 14, 512)  2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 14, 14, 512)  100352      center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 14, 14, 512)  0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 14, 14, 256)  1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 14, 14, 256)  1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 14, 14, 256)  50176       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 14, 14, 256)  0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 14, 14, 512)  1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 14, 14, 512)  2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 14, 14, 512)  100352      center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 14, 14, 512)  0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 14, 14, 512)  0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 1024) 0           add_1[0][0]                      \n",
      "                                                                 block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 14, 14, 256)  2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 14, 14, 256)  1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 14, 14, 256)  50176       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 14, 14, 256)  0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 14, 14, 128)  295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 14, 14, 128)  512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 14, 14, 128)  25088       decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 14, 14, 128)  0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 14, 14, 256)  295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 14, 14, 256)  1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 14, 14, 256)  50176       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 14, 14, 256)  0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 14, 14, 256)  0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 28, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 28, 28, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 28, 28, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 28, 28, 128)  100352      decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 28, 28, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 28, 28, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 28, 28, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 28, 28, 64)   50176       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 28, 28, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 28, 28, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 28, 28, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 28, 28, 128)  100352      decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 28, 28, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 56, 56, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 56, 56, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 56, 56, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 56, 56, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 56, 56, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 56, 56, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 64) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 112, 112, 64) 110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 112, 112, 32) 18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 112, 112, 32) 128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 112, 112, 32) 401408      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 112, 112, 32) 0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 112, 112, 64) 18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 112, 112, 64) 0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 224, 224, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 36,339,185\n",
      "Trainable params: 36,333,905\n",
      "Non-trainable params: 5,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3196 samples, validate on 804 samples\n",
      "Epoch 1/2\n",
      "3196/3196 [==============================] - 295s 92ms/step - loss: 0.9294 - my_iou_metric: 0.1315 - val_loss: 1.1905 - val_my_iou_metric: 0.0958\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.09577, saving model to unet_vgg.h5\n",
      "Epoch 2/2\n",
      "3196/3196 [==============================] - 273s 85ms/step - loss: 0.7861 - my_iou_metric: 0.2002 - val_loss: 2.8296 - val_my_iou_metric: 0.1465\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.09577 to 0.14652, saving model to unet_vgg.h5\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_vgg = unet_vgg(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_vgg.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_vgg.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "epochs = 2  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_vgg.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model_vgg.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:44<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.4080 at threshold: 0.200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.351272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.035419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.291791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.319590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.353731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.381405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.407960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.351272\n",
       "std     0.204939   0.035419\n",
       "min     0.200000   0.291791\n",
       "25%     0.370000   0.319590\n",
       "50%     0.540000   0.353731\n",
       "75%     0.710000   0.381405\n",
       "max     0.880000   0.407960"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efd1b236668>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAIaCAYAAAA0thsoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd4VVWi/vF3nZNeqKEmELpSQwkQunVERbp0ZFSkCDqW8Tc6V2fulDtjQ0UFBCwoiIiKglhQkQ4BQm8CoYcaWkggPev3B8HLeBEihOxTvp9/PHuffc55z/PwwOs6a69lrLUCAAAAcGkupwMAAAAAnozCDAAAAFwGhRkAAAC4DAozAAAAcBkUZgAAAOAyKMwAAADAZVCYAQAAgMugMAMAAACXQWEGAAAALoPCDAAAAFxGgNMBfikqKsrWqFHD6RgAAADwcWvWrDlura1wpes8rjDXqFFDSUlJTscAAACAjzPG7CvKdUzJAAAAAC6DwgwAAABcBoUZAAAAuAyPm8MMAAAAz5Cbm6uUlBRlZWU5HeWahISEKCYmRoGBgVf1egozAAAALiklJUWRkZGqUaOGjDFOx7kq1lqdOHFCKSkpqlmz5lW9B1MyAAAAcElZWVkqX76815ZlSTLGqHz58tc0Sk5hBgAAwK/y5rJ8wbV+BwozAAAAPFbbtm2djkBhBgAAgOdavny50xEozAAAAPBcERERks7fvPfUU0+pUaNGaty4sT7++GNJ0sKFC9WlS5efrx89erSmTJlSrBlYJQMAAABX9Lcvt2jroTPF+p4NqpbSX+9pWKRrZ82apfXr12vDhg06fvy4WrZsqY4dOxZrnl/DCDMAAAA83tKlS9W/f3+53W5VqlRJnTp10urVq0vksxlhBgAAwBUVdSS4pAUEBKigoODn4+uxyQojzAAAAPB4HTp00Mcff6z8/HylpqZq8eLFatWqlWJjY7V161ZlZ2fr9OnTmj9/frF/NiPMAAAA8Hg9evTQihUrFBcXJ2OMXnzxRVWuXFmS1KdPHzVq1Eg1a9ZUs2bNiv2zjbW22N/0WsTHx9ukpCSnYwAAAPi9bdu2qX79+k7HKBaX+i7GmDXW2vgrvZYpGQAAAMBlUJgBAACAy/C4wpxf4FlTRAAAAODfPK4w7ziariU7U52OAQAAAJ3fYc/bXet38LjC7HYZ3ffuKr3y3XZGmwEAABwUEhKiEydOeHVpttbqxIkTCgkJuer38Lhl5epUjNCtzWP0+o/JWrnnpF7v30yVSl39FwQAAMDViYmJUUpKilJTvfvX/5CQEMXExFz16z12WbnP1qTo2S82KyzIrdf6NVWHuhWcjgYAAAAf4vXLyvVqEaM5o9upfESQ7nt3lcZ8t115+QVXfiEAAABQjDy2MEtS3UqRmj2qve5tEaM3fkzWwLdX6uiZ4t8fHAAAAPg1Hl2YJSk0yK0Xe8dpzL1x2piSprvGLtHiHd49jwYAAADew+ML8wW9WsToy0fOT9EY8h5TNAAAAFAyvKYwS1KdikzRAAAAQMnyqsIsMUUDAAAAJcvrCvMFv5yi8fI8pmgAAACg+HltYZb+d4pGnxbV9OaCZA1gigYAAACKmVcXZun8FI0XejfRK33itIkpGgAAAChmXl+YL+jZ/PwUjaiIYKZoAAAAoNj4TGGWzk/R+GJUu/+dojF5pY6kMUUDAAAAV8+nCrP0v1M0Xu0bp82H0nTbK4s0bkGysnLznY4GAAAAL+RzhfmCHs1i9PWjHdS2dnm9NG+7bn55oWatTVFBgXU6GgAAALyIzxZmSaoRFa5J98VrxrAEVYgM1hMzN+ieN5dq+a7jTkcDAACAl/DpwnxBQq3y+uLhdhrbr6lOn8vVgMkrNfT91Uo+luF0NAAAAHg4vyjMkuRyGXVrGq35T3bSnzrfqJW7T+qO1xbruS8263hGttPxAAAA4KGMtZ41pzc+Pt4mJSVd9885kZGtsfN36sOV+xUa6NbIm2rrwfY1FRLovu6fDQAAAOcZY9ZYa+OvdJ3fjDD/UvmIYP29WyN993hHJdQ6f2PgLS8v1OfruDEQAAAA/8tvC/MFtStE6O0h8frooQSVjwjW4x9vUNdxS7Vi1wmnowEAAMAD+H1hvqBN7fKaPaqdXu0bp5MZOeo/OVFD30/ixkAAAAA/R2G+iMtl1KNZjH7840166o4blLj7hO54bbH+MnuzTnBjIAAAgF/y25v+iuJ4RrbG/rBT01edvzHw4Ztr64F23BgIAADgC7jprxhERQTrH90bad5jHZVQq5xe/Ha7uo9bpuRj6U5HAwAAQAkpUmE2xnQ2xmw3xiQbY56+zHW9jDHWGBN/0blnCl+33RhzR3GELml1Kkbo7SEt9e7v45Wanq0ubyzVR6v2y9NG5wEAAFD8rliYjTFuSeMk3SmpgaT+xpgGl7guUtIfJK286FwDSf0kNZTUWdL4wvfzSrfcWEnf/KGD4mPL6ZlZmzRq+lqlnct1OhYAAACuo6KMMLeSlGyt3W2tzZE0Q1K3S1z3D0kvSMq66Fw3STOstdnW2j2Skgvfz2tVLBWiDx5opafvvFHfbTmqu15foqS9J52OBQAAgOukKIU5WtKBi45TCs/9zBjTXFI1a+1Xv/W13sjlMhrRqbY+HdlWAW6jPhNX6PX5O5XPhicAAAA+55pv+jPGuCS9IunJa3iPYcaYJGNMUmpq6rVGKjFNq5XR3Efaq1vTaL3y/Q71n5yoQ6cznY4FAACAYlSUwnxQUrWLjmMKz10QKamRpIXGmL2SEiTNKbzx70qvlSRZaydZa+OttfEVKlT4bd/AYZEhgXq1b1O90idOWw6m6c6xS/Tt5iNOxwIAAEAxKUphXi2prjGmpjEmSOdv4ptz4UlrbZq1NspaW8NaW0NSoqSu1tqkwuv6GWOCjTE1JdWVtKrYv4UH6Nk8Rl892kGx5cM0Ytoa/dfnm5SVm+90LAAAAFyjKxZma22epNGS5knaJmmmtXaLMebvxpiuV3jtFkkzJW2V9K2kUdZan22RNaLC9emIthreqZY+XLlfXd9cqu1HWLMZAADAm7HT33WyeEeqnpi5QelZuXr27voalBArY4zTsQAAAFCInf4c1rFeBX37WAe1qV1ez83eomFT1+jU2RynYwEAAOA3ojBfR1ERwXp3SEs916WBFm4/pjvHLtGKXSecjgUAAIDfgMJ8nblcRg+2r6nPH26nsCC3BrydqDHfbVdefoHT0QAAAFAEFOYS0ii6tL58pL16N4/RGz8mq8/EFTpw8pzTsQAAAHAFFOYSFB4coJfujdPr/Ztp59EM3TV2id5Zuke5jDYDAAB4LAqzA7rGVdXXf+igZrFl9Y+5W9X5tcVatMN7djgEAADwJxRmh1QrF6b372+pd4bEK7/Aasi7qzT0/dXac/ys09EAAABwEQqzg4wxurV+Jc17vKOevvNGrdh1Qr97dZH+/c02pWflOh0PAAAAojB7hOAAt0Z0qq0FT92k7k2jNXHRbt0yZpE+STqgggLP2lgGAADA31CYPUjFyBC9dG+cZo9qp5iyoXrq043qMX6Z1u4/5XQ0AAAAv0Vh9kBx1crosxFt9WrfOB05k6We45friY/X6+iZLKejAQAA+B0Ks4dyuYx6NIvRj0/epFE319bcjYd188sLNW5BsrJy852OBwAA4DcozB4uPDhAT91xo354opPa14nSS/O263evLta8LUdkLfObAQAArjcKs5eoXj5Mk+6L17QHWysk0KXhU9do0DsrteNoutPRAAAAfBqF2cu0rxulrx/toL91bajNB8/ozrFL9NfZm3X6XI7T0QAAAHwShdkLBbhdGtK2hhb88Sb1b1VNUxP36eaXF2pa4j7lswwdAABAsaIwe7Fy4UH6Z/fG+urRDrqhcqSe/WKzeoxfpg0HTjsdDQAAwGdQmH1A/Sql9NFDCXq9fzMdSctS9/HL9MysTTp1lmkaAAAA14rC7COMMeoaV1Xzn+ykB9rV1MykA7plzEJ9vHo/uwUCAABcAwqzj4kMCdRzXRroq0fbq07FCP3ps03q9dZybT6Y5nQ0AAAAr0Rh9lE3Vi6lmcPbaMy9cTpw8py6vrlUf529WWmZuU5HAwAA8CoUZh9mjFGvFjGa/+RNGpQQq6mJ+3TrmIX6bE0Km54AAAAUEYXZD5QODdTfuzXSnNHtFVM2TE9+skF9JyZq+xE2PQEAALgSCrMfaRRdWrNGttXzPRtr57F03fX6Ev1z7lZlZOc5HQ0AAMBjUZj9jMtl1K9Vdf345E3qE19N7yzbo1vHLNScDYeYpgEAAHAJFGY/VTY8SP/u2VifP9xOFSKD9ehH6zTonZVKPpbhdDQAAACPQmH2c02rldHsUe31j+6NtCklTXeOXawXvv1J53KYpgEAACBRmCHJ7TIanBCrH/94k7o1jdaEhbt025hFmrPhEJueAAAAv0dhxs+iIoL18r1x+mREG5UOC9KjH63TPW8u1aIdqcxvBgAAfovCjP+jZY1y+uqR9nqtb1OdycrVkHdXqf/kRK3df8rpaAAAACWOwoxLcrmMujeL1vwnbtLfujZU8rEM9Ry/XMM+SNLOo6zfDAAA/IfxtJ/a4+PjbVJSktMx8Atns/P07tI9mrR4t87m5Kln8xg9fns9RZcJdToaAADAVTHGrLHWxl/xOgozfouTZ3M0YWGy3l+xT7LS4Daxevim2iofEex0NAAAgN+Ewozr6tDpTL32ww59uiZFYUEBeqhDLT3YoaYiggOcjgYAAFAkFGaUiORj6Xp53g59u+WIyocHafQtdTSgdXUFB7idjgYAAHBZFGaUqPUHTuuFb37Sit0nFF0mVE/cXk/dm0XL7TJORwMAALikohZmVslAsWharYymP9RaUx9spbLhgXrykw26a+wS/bD1KGs4AwAAr0ZhRrExxqhD3QqaM6q93hzQTDn5BRr6QZJ6v7VCq/acdDoeAADAVaEwo9i5XEZdmlTVd4931L96NFbKqXPqM3GFXvluO6PNAADA61CYcd0Eul0a0Lq6Fv7xZvWJj9HrPybryZkblJNX4HQ0AACAImMNMFx3oUFuvdCriaqVDdOY73focFqW3hrcQqVDA52OBgAAcEWMMKNEGGP0yK119WrfOCXtO6neE5Yr5dQ5p2MBAABcEYUZJapHsxh98EBrHT2TpR7jl2tjymmnIwEAAFwWhRklrk3t8vpsZFsFuV3qOzFR87cddToSAADAr6IwwxF1K0Xq81FtVadihB76IElTV+x1OhIAAMAlUZjhmIqRIfp4eIJuubGinpu9Rf/6epsKClh2DgAAeBYKMxwVFhSgiYPjdV+bWE1avFujP1qrrNx8p2MBAAD8jMIMx7ldRn/r2lDP3l1f32w+ooFvr9TJszlOxwIAAJBEYYaHMMZoaIdaGj+guTYfTFPP8cu09/hZp2MBAABQmOFZ7mxcRdMfStCZrDz1GL9Ma/addDoSAADwcxRmeJwWsWU1a2RblQ4NVP/JK/X1psNORwIAAH6MwgyPVCMqXLMebqfG0aX18IdrNWnxLlnLChoAAKDkUZjhscqFB+nDoa11d+Mq+tfXP+kvs7coL7/A6VgAAMDPBDgdALickEC33ujfTDFlQzVx8W4dOp2pNwY0U1gQf3QBAEDJYIQZHs/lMnrmrvr6R7eGWrD9mPpOTNSx9CynYwEAAD9BYYbXGNymhibfF6/kYxn63auL9cysTVqefFz57A4IAACuI+NpN1LFx8fbpKQkp2PAg209dEZvLdqlH7Yd1bmcfEVFBOnORlXUpUkVtaxRTi6XcToiAADwAsaYNdba+CteR2GGt8rMydeC7cc0d+Mh/fjTMWXlFqhiZLDualxF98RVUbNqZSnPAADgV1GY4VfOZudp/k/HNHfDIS3ckaqcvAJVLR2iuxpXUZe4qoqLKS1jKM8AAOB/UZjht9KzcvXDtqP6auNhLdqRqtx8q5iyobq7SRXd06SqGlYtRXkGAAAUZkCS0jJz9d2WI/pq02Et3XlceQVWNcqH6e4mVdSlSVXdWDmS8gwAgJ+iMAO/cOpsjuYVluflu04ov8CqVoVwdWlSVT2aRatmVLjTEQEAQAmiMAOXcSIjW99sPqKvNh5W4p4TslZqXydKgxJidVv9igpws+IiAAC+jsIMFNHRM1maufqApq/ar8NpWapcKkT9WlVT/1bVValUiNPxAADAdUJhBn6jvPwC/fjTMU1buV+Ld6TK7TK6vX4lDW4Tq7a1yzPXGQAAH1PUwhxQEmEAbxDgdul3DSvrdw0ra9+Js5q+cr9mJh3Qt1uOqFZUuAa0rq57W1RT6bBAp6MCAIASxAgzcBlZufn6etNhTUvcp7X7Tys4wKV74qpqcEKs4qqVcToeAAC4BkzJAIrZ1kNnNG3lPn2x7qDO5eSrcXRpDUqorq5x0QoNcjsdDwAA/EbFWpiNMZ0ljZXklvS2tfb5Xzw/QtIoSfmSMiQNs9ZuNcYESnpbUnOdn/7xgbX235f7LAozPF16Vq4+X3dQ0xL3acfRDEWGBKhX8xgNSohVnYoRTscDAABFVGyF2RjjlrRD0u2SUiStltTfWrv1omtKWWvPFD7uKulha21nY8wASV2ttf2MMWGStkq6yVq799c+j8IMb2Gt1eq9pzQtcZ++2XxYuflWbWqVP780XYOKCg5g1BkAAE9WnDf9tZKUbK3dXfjGMyR10/nyK0m6UJYLhUu60MKtpHBjTICkUEk5ki6+FvBaxhi1qllOrWqWU2p6A81MOqDpK/dr1PS1igwO0O0NK6lLkypqX6eCggJY1xkAAG9VlMIcLenARccpklr/8iJjzChJT0gKknRL4elPdb5cH5YUJulxa+3JawkMeKIKkcEadXMdjehUW0uTj2vuhkOat+WIZq09qNKhgbqjYSXd3aSq2tYur0A2RQEAwKsU27Jy1tpxksYVTsN4VtIQnR+dzpdUVVJZSUuMMT9cGK2+wBgzTNIwSapevXpxRQJKnNtl1KleBXWqV0H/06OxluxM1VcbD+vrTUc0MylFZcMC1blRZXVpUlWta5ZjR0EAALxAUQrzQUnVLjqOKTz3a2ZImlD4eICkb621uZKOGWOWSYqX9B+F2Vo7SdIk6fwc5qJFBzxbUIBLt9avpFvrV1JWbr4W7ThfnmevP6SPVh1QVESQ7mxURXc3qaKWNcrJ7WJjFAAAPFFRCvNqSXWNMTV1vij30/ki/DNjTF1r7c7Cw7slXXi8X+enZ0w1xoRLSpD0WnEEB7xJSKBbdzSsrDsaVlZmTr4WbD+muRsP6ZM1BzQ1cZ8qRgbrrsZV1KVJFTWvXlYuyjMAAB7jioXZWptnjBktaZ7OLyv3rrV2izHm75KSrLVzJI02xtwmKVfSKZ2fjiFJ4yS9Z4zZIslIes9au/F6fBHAW4QGuXVX4yq6q3EVnc3O0/yfjmnuhkOavmq/pizfqyqlQ3R34/Mjz02rlWFLbgAAHMbGJYCHSM/K1Q/bjmruhsNavDNVuflWMWVD1TWuqu5rU0OVS4c4HREAAJ/CTn+AF0vLzNV3W45o7sbDWrIzVW6XUfem0RrWsZbqVop0Oh4AAD6Bwgz4iAMnz+ntJbv1cdIBZeUW6NYbK2pYx1pqVbMc0zUAALgGFGbAx5w8m6OpK/bp/RV7dfJsjppWK6MRnWrp9gaVWWEDAICrQGEGfFRmTr4+XZuiyYt3a//Jc6pRPkwPdaylXs1jFBLIdtwAABQVhRnwcfkFVvO2HNHERbu0ISVN5cOD9Pu2NTS4TazKhAU5HQ8AAI9HYQb8hLVWibtPatLiXVqwPVWhgW71bVlND7avqWrlwpyOBwCAx6IwA35o+5F0TVq8W7PXH5SVdHfjKhrWsZYaRZd2OhoAAB6Hwgz4scNpmXpv2V5NX7lfGdl5al8nSsM71VL7OlGsrAEAQCEKMwClZeZq+sr9em/ZHh1Lz1aDKqX057vqq33dKKejAQDguKIWZldJhAHgjNKhgRp5U20t+dPNerFXE2Xm5uuBKau1PPm409EAAPAaFGbADwQHuNWnZTV9/nBb1YwK10MfJGljymmnYwEA4BUozIAfKRMWpA8ebKWy4UH6/XurtSs1w+lIAAB4PAoz4GcqlQrR1Adby2Wk+95ZpcNpmU5HAgDAo1GYAT9UMypcU+5vpbTMXA1+Z5VOnc1xOhIAAB6Lwgz4qUbRpTX5vnjtP3lO909ZrbPZeU5HAgDAI1GYAT/WpnZ5vdG/mTamnNaIaWuUk1fgdCQAADwOhRnwc3c0rKznezbRkp3H9cTM9cov8Ky12QEAcFqA0wEAOK9Py2o6eS5Hz3/zk8qGBenv3RqyIyAAAIUozAAkSSM61dapszmauHi3yoUH6fHb6zkdCQAAj0BhBvCzp++8USfP5mjs/J0qFx6kIW1rOB0JAADHUZgB/MwYo3/3bKzTmbn67y+3qExYoLo1jXY6FgAAjuKmPwD/IcDt0hv9m6lVjXJ6cuYGLdx+zOlIAAA4isIM4P8ICXRr8pB41asUqZHT1mrNvlNORwIAwDEUZgCXVCokUO8/0EqVSgXrgSmrteNoutORAABwBIUZwK+qEBmsqQ+2VnCAS4PfWakDJ885HQkAgBJHYQZwWdXKhemDB1spMydf9727Ssczsp2OBABAiaIwA7iiGyuX0nv3t9ThtEz9/r1VSs/KdToSAAAlhsIMoEhaxJbThIEt9NPhdA37YI2ycvOdjgQAQImgMAMosptvrKiX743Tit0n9IcZ65SXX+B0JAAArjsKM4DfpHuzaP31ngaat+Wo/uvzzbLWOh0JAIDrip3+APxm97erqZNnc/TGj8nadDBNgxJi1a1pVYUH81cKAMD3MMIM4Ko8cXs9vdiriaykP3++SQn/mq+/zt6snazXDADwMcbTfk6Nj4+3SUlJTscAUETWWq3df1ofJu7T3I2HlZNfoFY1y2lQQqw6N6ysoAD+vxwA4JmMMWustfFXvI7CDKC4nDybo0+SDujDlfu1/+Q5RUUEqW/LaurfqrpiyoY5HQ8AgP9AYQbgmIICqyXJxzV1xT79+NNRSdLNN1TUoIRYdaxXQW6XcTghAAAUZgAe4uDpTM1YtV8zVh9Qanq2qpUL1YBWseoTH6PyEcFOxwMA+DEKMwCPkptfoO+2HNXUxL1K3H1SQW6X7mxcWYMSYhUfW1bGMOoMAChZFGYAHiv5WLqmJe7XZ2tSlJ6dpxsrR2pgQqx6NItWBEvTAQBKCIUZgMc7l5OnOesPadrKfdp88IzCgtzq3LCyejSPVtvaUcx1BgBcVxRmAF7DWqsNKWn6ePV+zd14WOlZeapUKljdmkare9NoNahayumIAAAfRGEG4JWycvP140/HNGvtQS3cfkx5BVY3Vo5Uj2bR6tY0WpVLhzgdEQDgIyjMALzeybM5mrvxkGatPaj1B07LGKld7Sj1aBatzo0qsxU3AOCaUJgB+JTdqRn6Yv0hfb4uRQdOZio00K07GlZS92bRal8nSgFudhQEAPw2FGYAPslaqzX7TmnWuoOau+GQzmTlqUJksLrGVVWPZtFqWLUUS9QBAIqEwgzA52Xn5WtB4XznBduPKTffql6lCPVoFqNuTauqaplQpyMCADwYhRmAXzl1NkdfbTqsz9cd1Jp9p2SMdE+TqnqxdxOFBLqdjgcA8EBFLczcMQPAJ5QND9KghFgNSojVvhNnNX3Vfk1ctFvHM7I1+b54bhAEAFw17pIB4HNiy4frmTvra8y9cUrcfUKD3lmptHO5TscCAHgpCjMAn9WrRYzGD2yhLQfPqO+kFUpNz3Y6EgDAC1GYAfi0zo0q6+0h8dp74qz6Tlyhg6cznY4EAPAyFGYAPq9jvQqa9mBrpaZnq89bK7Tn+FmnIwEAvAiFGYBfiK9RTh8NS1Bmbr7ufWuFth0+43QkAICXoDAD8BuNoktr5vAEBbiM+k1K1Lr9p5yOBADwAhRmAH6lTsVIfTKijUqHBmrg2yu1fNdxpyMBADwchRmA36lWLkyfjGijmLKh+v17q/XD1qNORwIAeDAKMwC/VKlUiD4e1kY3Vo7UiGlrNGfDIacjAQA8FIUZgN8qGx6kD4e2VvPYsvrDjHWavnK/05EAAB6IwgzAr0WGBOr9+1upU70K+vPnmzR58W6nIwEAPAyFGYDfCw1ya9LgeN3duIr+5+tteuW77bLWOh0LAOAhApwOAACeICjApdf7N1N4sFuv/5is9Ow8PXd3A7lcxuloAACHUZgBoJDbZfR8zyaKCA7Uu8v2KCMrT8/3aiI3pRkA/BqFGQAu4nIZPdelviJDAjR2/k6dy8nXq32bKiiAGWwA4K8ozADwC8YYPX57PUWGBOifX23T2Zw8TRjYQqFBbqejAQAcwJAJAPyKoR1q6fmejbVoR6qGvLdK6Vm5TkcCADiAwgwAl9GvVXW93q+Z1u47pd4TVijl1DmnIwEAShiFGQCu4J64qppyfysdSstU93HLtW7/KacjAQBKEIUZAIqgfd0off5wW4UFudV3UqK+ZCttAPAbFGYAKKI6FSP1xah2iosprUc+WqfX5+9kgxMA8ANFKszGmM7GmO3GmGRjzNOXeH6EMWaTMWa9MWapMabBRc81McasMMZsKbwmpDi/AACUpHLhQZo2tLV6NovWK9/v0OMfr1dWbr7TsQAA19EVl5UzxrgljZN0u6QUSauNMXOstVsvumy6tfatwuu7SnpFUmdjTICkaZIGW2s3GGPKS+I2cwBeLTjArTF94lS7YoRemrddKacyNXFwC5WPCHY6GgDgOijKCHMrScnW2t3W2hxJMyR1u/gCa+2Ziw7DJV34jfJ3kjZaazcUXnfCWstQDACvZ4zRqJvraNyA5tp0ME3dxy/TzqPpTscCAFwHRSnM0ZIOXHScUnjuPxhjRhljdkl6UdKjhafrSbLGmHnGmLXGmP93qQ8wxgwzxiQZY5JSU1N/2zcAAAfd3aSKPh7eRpk5Beo5frkW7+DvMADwNcV205+1dpy1trakP0l6tvB0gKT2kgYW/reHMebWS7x2krU23lobX6FCheKKBAAlomm1Mpo9up2iy4bq/imrNTVxn9ORAADFqCiF+aCkahcdxxSe+zUilgYUAAAgAElEQVQzJHUvfJwiabG19ri19pykryU1v5qgAODJosuE6tORbXVTvQp67ovN+tuXW5RfwAoaAOALilKYV0uqa4ypaYwJktRP0pyLLzDG1L3o8G5JOwsfz5PU2BgTVngDYCdJF98sCAA+IyI4QJPui9eD7WvqvWV79dAHScrIznM6FgDgGl2xMFtr8ySN1vnyu03STGvtFmPM3wtXxJCk0YXLxq2X9ISkIYWvPaXzK2aslrRe0lpr7VfX4XsAgEdwu4ye69JA/+zeSIt2pKr3hOU6eDrT6VgAgGtgPG3R/fj4eJuUlOR0DAC4Zkt2purhD9cqOMCtyfe1ULPqZZ2OBAC4iDFmjbU2/krXsdMfAFwnHepW+Hk77X6TEjV3I9tpA4A3ojADwHV0YTvtJjGlNXr6Or3BdtoA4HUozABwnV3YTrtHs2iN+X6Hnpi5Qdl57OEEAN7iiltjAwCuXXCAW6/0iVPtCuF6+bsdOnDynMYNbK5KpUKcjgYAuAJGmAGghBhjNPqWuho3oLm2HDqjzq8t1vxtR52OBQC4AgozAJSwu5tU0ZePtFeV0qF68P0k/fecLcrKZYoGAHgqCjMAOKBOxQh9PqqtHmhXU1OW71X3ccuUfCzd6VgAgEugMAOAQ4ID3PrLPQ307u/jdSw9W13eWKoZq/azigYAeBgKMwA47JYbK+nbP3RQfGw5PT1rk0ZPX6e0zFynYwEAClGYAcADVCwVog8eaKWn77xR87Yc0V1jlyhp70mnYwEARGEGAI/hchmN6FRbn45sqwC3UZ+JK/T6/J3KL2CKBgA4icIMAB6mabUymvtIe3WNq6pXvt+h/pMTdeh0ptOxAMBvUZgBwANFhgTqtX7N9EqfOG05mKY7xy7Rt5uPOB0LAPwShRkAPFjP5jGa+2gHVS8XphHT1ui/Pt/Ems0AUMIozADg4WpGheuzkW01vGMtfbhyv7q+uVTbj7BmMwCUFAozAHiBoACXnrmrvj54oJVOns1V1zeXauqKvazZDAAlgMIMAF6kY70K+vaxDkqoVV7Pzd6iYVPX6NTZHKdjAYBPozADgJeJigjWe79vqWfvrq+F24/pzrFLlLj7hNOxAMBnUZgBwAu5XEZDO9TS5w+3U1iQW4PeXqnZ6w86HQsAfBKFGQC8WKPo0vpidDs1jy2rxz5erw9W7HU6EgD4HAozAHi5UiGB+uCBVrr1xkr6y+wtevX7HdwMCADFiMIMAD4gJNCttwY1V+8WMRo7f6f+MnuLCthSGwCKRYDTAQAAxSPA7dJLvZuoXHiQJi3erVPncvRKn6YKCmBsBACuBYUZAHyIMUZ/vqu+yocH6d/f/KS0zFxNHNxCYUH8dQ8AV4thBwDwQcM71daLvZpoWfJxDZi8krWaAeAaUJgBwEf1aVlNEwa10NbDZ3TvxBU6nJbpdCQA8EoUZgDwYXc0rKz372+lI2lZ6j1hhXalZjgdCQC8DoUZAHxcm9rlNWNYgrLz8nXvWyu0MeW005EAwKtQmAHADzSKLq1PRrRVWJBb/SclalnycacjAYDXoDADgJ+oGRWuz0a2VUzZMN3/3mp9s+mw05EAwCtQmAHAj1QqFaKPhyeocUxpjZq+Vh+t2u90JADweBRmAPAzZcKCNO3B1upYr4KembVJ4xYks5U2AFwGhRkA/FBokFuT74tX96ZV9dK87frnV9vYShsAfgVbPwGAnwp0u/RKn6YqExakd5bu0amzOXqhdxMFuhlLAYCLUZgBwI+5XEZ/vaeByocHacz3O3Q6M1fjBjRXaJDb6WgA4DEYRgAAP2eM0SO31tU/uzfSgu3HNPidlUo7l+t0LADwGBRmAIAkaVBCrN7o30wbUk6rD1tpA8DPKMwAgJ91aVJVU+5vpYOnM9Vz/HLtOJrudCQAcByFGQDwH9rVidLHwxOUV2DVe8Jyrd570ulIAOAoCjMA4P9oWLW0Zo1sq6jIYA18e6W+3cyugAD8F4UZAHBJ1cqF6dMRbdWwaimN/HCtpq7Y63QkAHAEhRkA8KvKhQdp+tAE3XJDRT03e4temvcTuwIC8DsUZgDAZYUGuTVxcAv1a1lN4xbs0v/7dKNy8wucjgUAJYaNSwAAVxTgdunfPRurUqkQjZ2/U6kZ2Ro/sLnCgvhnBIDvY4QZAFAkxhg9fns9/atHYy3ekar+kxJ1PCPb6VgAcN1RmAEAv8mA1tU1cXC8th9NV+8Jy7XvxFmnIwHAdUVhBgD8Zrc3qKQPhybodGauek1Yrk0paU5HAoDrhsIMALgqLWLL6tMRbRUc4FbfSSu0aEeq05EA4LqgMAMArlqdihGa9XBbxZYP14NTVmvW2hSnIwFAsaMwAwCuSaVSIfp4eIJa1SynJ2Zu0ISFu1irGYBPoTADAK5ZqZBAvXd/S90TV1UvfPuT/vblVuUXUJoB+AYW0AQAFIvgALfG9m2qSpHBenvpHh1Lz9IrfZoqJNDtdDQAuCYUZgBAsXG5jJ7t0kCVS4fon19t04mMVZp0X7xKhwY6HQ0ArhpTMgAAxW5oh1oa26+p1u4/pT5vrdDhtEynIwHAVaMwAwCui25NozXl/lY6eDpTvcYv146j6U5HAoCrQmEGAFw37epE6ePhCcotsOo9YblW7z3pdCQA+M0ozACA66ph1dKaNbKtoiKDNfDtlfp282GnIwHAb0JhBgBcd9XKhenTEW3VsGopjfxwraau2Ot0JAAoMgozAKBElAsP0vShCbrlhop6bvYWvTTvJzY4AeAVKMwAgBITGuTWxMEt1L9VNY1bsEtPfbpRufkFTscCgMtiHWYAQIkKcLv0rx6NValUiF77YaeOZ2Rr3IDmCg/mnyQAnokRZgBAiTPG6LHb6unfPRtr8Y5U9Z+cqOMZ2U7HAoBLojADABzTv1V1TRocrx1H09V7wnLtO3HW6UgA8H9QmAEAjrqtQSV9ODRBpzNz1WvCcm1KSXM6EgD8BwozAMBxLWLL6tMRbRUc4FbfSSu0aEeq05EA4GcUZgCAR6hTMUKzHm6r2PLhenDKan22JsXpSAAgicIMAPAglUqFaObwBLWuVU5PfrJB4xcms1YzAMcVqTAbYzobY7YbY5KNMU9f4vkRxphNxpj1xpilxpgGv3i+ujEmwxjzx+IKDgDwTZEhgXrv963UNa6qXvx2u/57zhblF1CaATjnioteGmPcksZJul1SiqTVxpg51tqtF1023Vr7VuH1XSW9IqnzRc+/IumbYksNAPBpQQEuvda3qSqVCtbkJXuUmpGtV/o0VUig2+loAPxQUVaJbyUp2Vq7W5KMMTMkdZP0c2G21p656PpwST8PBRhjukvaI4m1ggAAReZyGf3X3Q1UqVSI/vnVNh3PWKXJg+NVOizQ6WgA/ExRpmRESzpw0XFK4bn/YIwZZYzZJelFSY8WnouQ9CdJf7v2qAAAfzS0Qy2N7ddU6/af0r0Tl+twWqbTkQD4mWK76c9aO85aW1vnC/Kzhaf/W9Kr1tqMy73WGDPMGJNkjElKTWUpIQDAf+rWNFpT7m+lQ6ez1HvCCp1gV0AAJagohfmgpGoXHccUnvs1MyR1L3zcWtKLxpi9kh6T9GdjzOhfvsBaO8laG2+tja9QoUKRggMA/Eu7OlGaNrS1UjOy9YcZ67kREECJKUphXi2prjGmpjEmSFI/SXMuvsAYU/eiw7sl7ZQka20Ha20Na20NSa9J+pe19s1iSQ4A8DtNq5XRP7s10tLk43rl++1OxwHgJ65405+1Nq9wVHieJLekd621W4wxf5eUZK2dI2m0MeY2SbmSTkkacj1DAwD8V5+W1bTuwCmNW7BLcTFl9LuGlZ2OBMDHGU9bED4+Pt4mJSU5HQMA4MGycvPVZ+IK7Uk9qzmPtFfNqHCnIwHwQsaYNdba+Ctdx05/AACvExLo1viBzeV2G42YukbncvKcjgTAh1GYAQBeKaZsmF7v10w7jqXrmVmb2EIbwHVDYQYAeK2O9Sroydvrafb6Q/pgxT6n4wDwURRmAIBXe/imOrqtfkX9Y+5Wrdl30uk4AHwQhRkA4NVcLqMxfZoqumyoHv5wrVLT2dQEQPGiMAMAvF7p0EBNGNhCaZm5Gj19rfLyC5yOBMCHUJgBAD6hQdVS+nfPxlq556RenMemJgCKD4UZAOAzejSL0X1tYjVp8W59vemw03EA+AgKMwDApzx7dwM1q15GT32yQcnH0p2OA8AHUJgBAD4lKMCl8QObKyTQreFT1ygjm01NAFwbCjMAwOdUKR2qNwY0057jZ/WnTzeyqQmAa0JhBgD4pLa1o/Snzjfqq02H9c7SPU7HAeDFKMwAAJ81rGMtdW5YWf/+5icl7j7hdBwAXorCDADwWcYYvXRvE8WWD9Po6et09EyW05EAeCEKMwDAp0WGBOqtQS10LidPD3+4Vjl5bGoC4LehMAMAfF69SpF6oVcTrdl3Sv/6epvTcQB4GQozAMAv3BNXVQ+2r6kpy/dq9vqDTscB4EUozAAAv/H0nTeqZY2yevqzTdp+hE1NABQNhRkA4DcC3S6NG9BcESEBGjFtjc5k5TodCYAXoDADAPxKxVIhGj+wuQ6cPKcnZ25QQQGbmgC4PAozAMDvtKxRTn++q76+33pUf/pso1JOnXM6EgAPFuB0AAAAnHB/uxo6dDpTU5bv1ax1B9WlSRUN61hLDauWdjoaAA9jrPWsn6Li4+NtUlKS0zEAAH7i0OlMvbt0jz5atV9nc/LVoW6UhnesrXZ1yssY43Q8ANeRMWaNtTb+itdRmAEAkNIyc/Xhyn16b9lepaZnq0GVUhreqZbublxFAW5mMAK+iMIMAMBVyM7L1xfrDmri4t3anXpWMWVD9WD7murbsprCgpjJCPgSCjMAANegoMBq/k/HNHHRLiXtO6UyYYEanBCrIW1rKCoi2Ol4AIoBhRkAgGKyZt9JTVy0W99vO6ogt0u9W8TooQ61VCMq3OloAK4BhRkAgGKWfCxDby/ZrVlrDyq3oECdG1bWsI611Kx6WaejAbgKFGYAAK6TY2eyNGX5Xk1N3Kf0rDy1qllOwzvW0s03VJTLxcoagLegMAMAcJ1lZOdpxqr9emfpHh1Oy1LdihH6w211dVejKhRnwAtQmAEAKCG5+QWau/GQxi/YpZ3HMtQ4urT+X+cb1L5OFGs5Ax6sqIWZhSUBALhGgW6XejSL0bePddSYe+N08myOBr+zSgPfXqn1B047HQ/ANWKEGQCAYpadl68PE/frzQXJOnk2R50bVtYf77hBdSpGOB0NwEWYkgEAgMMysvP09pLdmrx4tzJz83Vvi2r6w211VbVMqNPRAIjCDACAxziRka1xC3ZpWuI+yUhD2sTq4ZvqqGx4kNPRAL9GYQYAwMMcOHlOr/2wU7PWpSgiKEDDO9XS/e1qKjyYLbcBJ1CYAQDwUNuPpOvl77br+61HFRURrEdvraN+LasrKIB78YGSxCoZAAB4qBsqR2ryffH6bGQb1YoK119mb9GtryzUF+sOqqDAswayAFCYAQBwTIvYcvp4eILeu7+lIoID9djH63XX60u04Kdj8rRfgAF/RmEGAMBBxhjdfENFffVIe43t11TncvJ1/5TV6jsxUWv2nXQ6HgBRmAEA8Agul1G3ptH64YlO+ke3htp9/Kx6TVihoe8nafuRdKfjAX6Nm/4AAPBA53Ly9N6yvXpr4S5l5OSpR7NoPX5bPVUrF+Z0NMBnsEoGAAA+4NTZHL21aJemLN+rAms1sHWsRt9SR1ERwU5HA7wehRkAAB9yOC1TY3/YqZlJBxQa6NbQDrU0tENNRYYEOh0N8FoUZgAAfFDysQy98v12fb3piMqFB2nUzXU0KKG6ggPcTkcDvA6FGQAAH7bhwGm9NG+7liYfV3SZUD12W131bB4jt8s4HQ3wGmxcAgCAD4urVkbThrbWtAdbq3xEkJ76dKM6v7ZY3205whrOQDGjMAMA4MXa143S7FHtNH5gc+UXWA2bukY9JyxX4u4TTkcDfAaFGQAAL2eM0V2Nq+i7xzvq+Z6Ndfh0lvpNStSQd1dpy6E0p+MBXo85zAAA+Jis3Hx9sGKvxi3YpbTMXHWNq6onbq+nGlHhTkcDPAo3/QEA4OfSMnM1afEuvbt0r3LzC/Rgh5p66nc3KMDND8yAxE1/AAD4vdKhgXrqjhu16Kmb1Kt5jCYu2q37p6xW2rlcp6MBXoXCDACAj6tYKkQv9G6iF3o1VuLuE+o+fpmSj2U4HQvwGhRmAAD8RN+W1TX9oQSdycxVj/HLtHD7MacjAV6BwgwAgB9pWaOcZo9up5iyYXpgympNXrybdZuBK6AwAwDgZ2LKhumzkW10R8PK+p+vt+mPn2xUVm6+07EAj0VhBgDAD4UFBWjcgOZ67La6+mxtivpPTtSxM1lOxwI8EoUZAAA/5XIZPXZbPU0Y2Fw/HU5X1zeXaVMKG50Av0RhBgDAz93ZuIo+HdlGbpfRvROX68sNh5yOBHgUCjMAAFDDqqU1e3Q7NapaWo98tE4vz9uuggJuBgQkCjMAACgUFRGs6Q8lqG98Nb25IFnDp61RRnae07EAx1GYAQDAz4ICXHq+V2P99Z4Gmr/tqHqNX64DJ885HQtwFIUZAAD8B2OM7m9XU+8/0EqH0zLV9c2lWrHrhNOxAMdQmAEAwCV1qFtBs0e3V7nwIA1+Z6WmJe5zOhLgCAozAAD4VTWjwvX5qHbqUDdKz36xWc99sVm5+QVOxwJKFIUZAABcVqmQQL09pKWGd6ylqYn7dN87q3TqbI7TsYASQ2EGAABX5HYZPXNXfY25N05r9p1S13FLtf7AaadjASWCwgwAAIqsV4sYzRieoJy8AvUYv0zPzNrEaDN8XpEKszGmszFmuzEm2Rjz9CWeH2GM2WSMWW+MWWqMaVB4/nZjzJrC59YYY24p7i8AAABKVvPqZfXDE530QLuampl0QLeMWagZq/az0Ql8lrH28n+4jTFuSTsk3S4pRdJqSf2ttVsvuqaUtfZM4eOukh621nY2xjSTdNRae8gY00jSPGtt9OU+Lz4+3iYlJV3TlwIAACVj2+Ez+svszVq995SaVS+jf3RrpEbRpZ2OBRSJMWaNtTb+StcVZYS5laRka+1ua22OpBmSul18wYWyXChcki08v85ae2FD+i2SQo0xwUX5AgAAwPPVr1JKM4e30cv3xmn/iXPq+uZS/XX2ZqVl5jodDSg2RSnM0ZIOXHScUnjuPxhjRhljdkl6UdKjl3ifXpLWWmuzryYoAADwTMYY9W4Rox//eJMGJcRqauI+3TpmoT5bk6Ir/ZINeINiu+nPWjvOWltb0p8kPXvxc8aYhpJekDT8Uq81xgwzxiQZY5JSU1OLKxIAAChBpUMD9fdujTRndHvFlA3Tk59sUN+JifrpyJkrvxjwYEUpzAclVbvoOKbw3K+ZIan7hQNjTIykzyXdZ63ddakXWGsnWWvjrbXxFSpUKEIkAADgqRpFl9askW31fM/G2nksXXe/vlT/nLtVGdl5TkcDrkpRCvNqSXWNMTWNMUGS+kmac/EFxpi6Fx3eLWln4fkykr6S9LS1dlnxRAYAAJ7O5TLq16q6fnzyJvWJj9E7y/bo1jELNWfDIaZpwOtcsTBba/MkjZY0T9I2STOttVuMMX8vXBFDkkYbY7YYY9ZLekLSkAvnJdWR9JfCJefWG2MqFv/XAAAAnqhseJD+3bOJZo1sqwqRwXr0o3Ua+PZKJR/LcDoaUGRXXFaupLGsHAAAvim/wGr6yn16ad52Zebma2iHWnrkljoKCwpwOhr8VHEuKwcAAHDN3C6jwW1q6Mc/3qRuTaM1YeEu3TZmkb7dfJhpGvBoFGYAAFCioiKC9fK9cfpkRBuVCg3UiGlrdf+U1WyxDY9FYQYAAI5oWaOc5j7SXn/p0kDLd51Q77eWK+XUOadjAf8HhRkAADgmwO3SA+1ratqDrZWanq2e45dr6yHWbYZnoTADAADHtapZTp+ObCu3y6jvxBVavuu405GAn1GYAQCAR6hXKVKfjWyrKmVC9Pt3V+vLDYecjgRIojADAAAPUrVMqD4Z3lZNq5XRIx+t0ztL9zgdCaAwAwAAz1I6LFAfPNhKdzaqrH/M3ar/+WqrCgpYdg7OoTADAACPExLo1psDmuu+NrGavGSPHp+5Xjl5BU7Hgp9iax0AAOCR3C6jv3VtqMqlQ/Tit9t1IiNHEwY1V2RIoNPR4GcYYQYAAB7LGKOHb6qjMffGKXH3CfWdmKhj6VlOx4KfoTADAACP16tFjN4eEq+9J86q5/jl2p2a4XQk+BEKMwAA8Ao33VBRM4YlKDMnX70mLNfa/aecjgQ/QWEGAABeo0lMGX02sq1KhQZqwOREzd921OlI8AMUZgAA4FVqRIXrs5FtVa9SpB76IEkzVu13OhJ8HIUZAAB4naiIYH30UII61K2gp2dt0tgfdspa1mrG9UFhBgAAXik8OEBvD4lXr+YxevWHHfrz55uVl89azSh+rMMMAAC8VqDbpZfvbaLKpYM1bsEupaZn643+zRQa5HY6GnwII8wAAMCrGWP01B036u/dGmr+T0c18O1EnTqb43Qs+BAKMwAA8An3tamh8QOaa/OhM+oxfpm2HT7jdCT4CAozAADwGXc2rqLpQ1vrXE6+eoxfpllrU5yOBB9AYQYAAD4lvkY5zX20veJiyuiJmRv0X59vUnZevtOx4MUozAAAwOdUjAzRh0Nba3inWvpw5X71eWuFDp7OdDqWxzueka2cPFYa+SUKMwAA8EkBbpeeubO+3hrUQrtTz6rL60u0aEeq07E8VmZOvjq/tkS931qus9l5TsfxKBRmAADg0zo3qqw5j7RXpVIh+v17qzT2h50qKGCTk1/6csMhHc/I1saUNI38cK1yWdP6ZxRmAADg82pGhevzh9upR9NovfrDDj3w/mqWnruItVYfJO5VvUoReqFXYy3ekao/fbqR3RMLUZgBAIBfCA1ya0yfOP1Pj0ZannxCXd5Yqo0pp52O5RHWHTitzQfPaHCbGurbsrqevL2eZq07qOe//cnpaB6BwgwAAPyGMUYDW8fqkxFtJEm9J6zQ/2/vzuOjqu/9j78/mewLCRB2QkAIRUARCAREr1vrrtD2agEjUizWK6i32gW70Fb99d7q73d7f+5iUTQKiChI1YrWuhQMS8KeCMi+yb4LARK+949Me6PVySTMzJnMvJ7/kJmc8z1v8n1M8s7JOfOdunBL3J9JLSndrMyURH27bwdJ0vhLu6l4UCc9/eEGTZ630eN03qMwAwCAuNMnL0dv3HmBBnVtqZ/PWqkfv7JCx0/G51vP7T16Qm+u+Ezf7ddBmSmJkmp/sfjt9b11Za+2euCNSs1ZvsPjlN6iMAMAgLjUPCNZz40eoLsvK9BrS7fp20/M16a9n3sdK+JeXrxVJ2tO6+bB+V943pdg+u/h52lglxa6d8Yyfbxur0cJvUdhBgAAccuXYPrRt7rr2dEDtPNwla57dJ7eqdjpdayIqTntNHXhFp3ftaW6tc76p8+nJvn0zKhCnZWbqdtKylWx45AHKb1HYQYAAHHvkm+01p/GX6DOuRm6raRc//nn1aqOg7dVe++TXdp+8LhGfenscl3ZaUmaMmaAmqUmavRzi7V1/7EIJowOFGYAAABJeS3S9crtgzWyqJOe+nC9iicv1J4jJ7yOFVYlCzarXXaqvnl2m4DbtctO0/NjBupk9WmNenaR9h2N7a/Ll1GYAQAA/FKTfPrdt8/R/72hj5ZuOahrHvmbyjbt9zpWWGzYc1R/+3SvRg7spERf/ZWwoE2Wnh1dqB0Hj2vMlMVxtRoghRkAAOBL/rV/R826Y4jSkn0aPmmBXinb6nWkkCtZsFlJPtPwgZ2C3qd/fgs9NrKfVm4/pHFT42c1QAozAADAV+jZvpnmjL9Ag7u21E9fXaFXy7d5HSlkjp2s1szybbqqdzu1ykpp0L7f6tlG/+fb5+iDNXs04dWVcfEe1hRmAACAr5GdlqRnRhXqgm65+vHM5Zq9dLvXkUJi9tIdOlJVHfBmv0BGDOykH32zu15dsk0Pz10T4nTRh8IMAAAQQGqST5NuLtTgs1rqnhnLmvwiHs45vVC6SWe3a6b++c0bPc5dl3XTyKJOeuKD9ZoyP7ZXA6QwAwAA1CMt2ac/3lKoAZ1b6EcvL9ObKz7zOlKjlW0+oNU7j2jU4HyZWaPHMTM9MLS3Lu/ZRr99o1JvrGjav0gEQmEGAAAIQnpyop4dPUD9OuXorulL9faqplmaXyjdrKzURA09r/0Zj+VLMD0yoq8K85vrnpeX6+P1sbkaIIUZAAAgSBkpiXru+wPVp2O2xk9d2uRWBdx9pEpvr/pMN/TPU3pyYkjGTE3y6Y+jBqhzbrp++EK5KnccDsm40YTCDAAA0ACZKYl6fsxA9e6QrXFTl+i9T3Z5HSlo0xdt1akap5sbebPf18lOT9KU7w9UZmqiRj+3KOZWA6QwAwAANFBWapKeHzNQZ7drpn97cYk+WLPb60j1qq45rakLt+jCglx1yc0I+fjtc2pXA6w6VaNbnluk/Z+fDPkxvEJhBgAAaITstCSVjClSQZtM3VZSro/W7vE6UkB/+WSXdh6u0qjBncN2jO5tsjR59ABtP1C7GuCxk7GxGiCFGQAAoJGy05P04q1F6toqU2NfKNP8ddF709sLpZvVISdNl/ZoHdbjDOjcQo+M6KsV2w5q3EuxsRoghRkAAOAMNM9I1ks/KFKX3Azd+vxila7f53Wkf7Ju9xF9vH6fRhZ1ki+h8W8lF6wrerXVA8N66/01e/Qfb60O+/HCjcIMAABwhlpkJOvFHxQpr3m6xkxZrEUb93sd6QtKSjcr2Zeg4QPyInbMm4ry9f0hnfXs/I2atbRpLytOYQYAAAiB3MwUTR07SO1zUjX6uUUq2xQdpfnoiWq9umS7rjm3ncCUNt8AABHOSURBVFpmpkT02D+/+mwVdWmh+15bqVXbD0X02KFEYQYAAAiRVlkpmjZ2kNo2S9Xo5xZryZYDXkfSrKXbdfREdcjfSi4YSb4EPX5TPzVPT9btL5brQBN95wwKMwAAQAi1bpaqqWMHKTczWbdMXqTlWw96lsU5p5LSTerdoZn65uV4kiE3M0VPFffX7iMndOe0papugjcBUpgBAABCrG12qqbdNkjNM5J18+SFWrnNm8sRFm7cr7W7jmrUoM4yC//Nfl+nT16OHhzaW/PW7dXD76zxLEdjUZgBAADCoF12mqbdNkjN0pJUPHmhJ9fwlpRuVnZakq7r0z7ix/6yGwfkqXhQJz394Qa9sWKH13EahMIMAAAQJh1y0jRt7CBlpiSqePJCVe44HLFj7zpcpbkVO3VjYUelJfsidtxAJl7bS/3zm+snr6zQ6p2R+1qcKQozAABAGOW1SNfUsUVKS/KpePJCrdl5JCLHnbpwi2qcU/GgyN/s93WSExP05E39lJWaqB+WlOvQsVNeRwoKhRkAACDM8ltmaOrYQUrymUY+s0BLw/zuGadqTmvaoi26qHsr5bfMCOuxGqp1s1Q9WdxPOw4e190vL1XNaed1pHpRmAEAACKgS26Gpo0dpPQUn7739AK9vHhL2I41t2Kndh85oVEevJVcMPrnt9Cvr+ulD9bs0X//Za3XcepFYQYAAIiQs1plas64C1R0Vgv97NWV+sWslTpZHfq3WXuhdLPyWqTpou6tQz52qNxU1EnfK8zTo39dp7kVO72OExCFGQAAIIKaZyRryvcH6vaLuuqlhVs04pkF2n24KmTjr955WIs27ldxUb58Cd69lVx9zEy/HdpLfTpm694Zy7Vud2Su7W4MCjMAAECE+RJME67qocdG9lXljsO69tF5Kt8cmuuaS0o3KyUxQTcW5oVkvHBKTfLpyeL+Sk1K0G0l5TpSFZ03AVKYAQAAPHLtue01a9z5Sk3yafikUk1deGbXNR+uOqVZS7fruj7t1TwjOUQpw6t9TpoeH9lPW/Yd0z0zlut0FN4ESGEGAADwUI+2zTRn/BAN7pqrn89aqfteW6ET1TWNGuu18m06drImam/2+zpFZ7XUL645W+9W7tJj76/zOs4/oTADAAB4LCc9Wc+NHqA7Lu6qaYu2avikBdrVwOuanXMqWbBZffJydG7HnDAlDZ/R53fWd/p20B/+slZ/Xb3L6zhfQGEGAACIAr4E00+v7KEnbuqnNTuP6NpH56ls0/6g9/94/T6t3/O5RkXRQiUNYWb63XfOUc92zXT39GXauPdzryP9A4UZAAAgilx9TjvNHjdEGck+jXhmgV5csFnO1X9d7wulm9QiI1nXnNsu/CHDJDXJp6eK+ysxwfTDkjJ9fqLa60iSKMwAAABRp3ubLL0+7gIN6ZarX85epQmvrlTVqa+/rnnHweN6t3KXbizMU2qSL4JJQy+vRboeG9lP63Yf1U9mLg/ql4VwozADAABEoez0JE2+ZYDuvLSbXi7bqu9NWqDPDh3/ym2nLtwip9rFQGLBkG65mnBVD721cqee+nCD13EozAAAANHKl2C69/Jv6Kni/lq364iue3SeFm384nXNJ6prNH3xFl3Wo7XyWqR7lDT0xl54lq49t50enrtaH63d42mWoAqzmV1pZmvMbJ2ZTfiKz99uZivNbJmZzTOznnU+d59/vzVmdkUowwMAAMSDK3u31exxQ5SVmqSRzyzQC6Wb/nGpwturdmrv0ZO6eXBnTzOGmpnpoX89V93bZOnOaUu1df8xz7LUW5jNzCfpcUlXSeopaUTdQuw31Tl3jnPuPEkPSfov/749JQ2X1EvSlZKe8I8HAACABihok6XZ44boou6tNPH1Cv1k5gpVnapRSelmdW6Zrgu75XodMeTSkxP19M395ZzTbSXlOn6yce9PfaaCOcM8UNI659wG59xJSdMlDa27gXPucJ2HGZL+fnX2UEnTnXMnnHMbJa3zjwcAAIAGyk5L0jOjCnXXZQWaWb5N1z06T2WbD6h4UL4SEszreGGR3zJDj4zoq9U7D+u+11Z4kiGYwtxB0tY6j7f5n/sCMxtnZutVe4b5robsCwAAgOAkJJju+VZ3Tbq5vz47VKXUpATd0D/P61hhdfE3WuvfL+uu2ct26N3KyC9qErKb/pxzjzvnukr6maRfNmRfM7vNzMrMrGzPHm8v6gYAAGgKLu/VVn+++0LN+OFgZacneR0n7O64pKsKWmfqN3MqIn5pRjCFebukur+2dPQ/93WmSxrWkH2dc5Occ4XOucJWrVoFEQkAAAB5LdKb5DLYjZHkS9CDw3pr+8Hjeuz9TyN67GAK82JJBWbWxcySVXsT35y6G5hZQZ2H10j6+/9ijqThZpZiZl0kFUhadOaxAQAAEG+Kzmqp7/TtoEkfbdD6PUcjdtx6C7NzrlrSeElzJX0iaYZzrsLM7jez6/2bjTezCjNbJukeSbf4962QNENSpaS3JY1zznlzeyMAAACavPuuPlupST5NfH1VxFYBtGhYbrCuwsJCV1ZW5nUMAAAARKmS0k361esVemREX13fp32jxzGzcudcYX3bsdIfAAAAmpSRRfk6p0O2HnyjUkeqToX9eBRmAAAANCm+BNODw3prz9ET+sO74b8BkMIMAACAJqdPXo5GDuykKR9vVMWOQ2E9FoUZAAAATdJPr+ih5unJ+tXsVTp9Onz35VGYAQAA0CRlpydpwlU9tGTLQc0s3xa241CYAQAA0GR9t19HDejcXP/x50904POTYTkGhRkAAABNVkKC6YFhvXW4qloPzV0dnmOEZVQAAAAgQnq0baYxQzpr+uKtWrLlQMjHpzADAACgybv7m93VOitFv5q9StU1p0M6NoUZAAAATV5mSqImXttLFTsO68UFm0M6NoUZAAAAMeHqc9rqwoJc/b931mr3kaqQjUthBgAAQEwwM90/tLdOVJ/W7978JGTjUpgBAAAQM7rkZuj2i87S7GU79PH6vSEZk8IMAACAmHLHJd2U1yJNE1+v0MnqM78BkMIMAACAmJKa5NP91/fWut1HNXnexjMej8IMAACAmHNJj9a6vGcbPfLep9p24NgZjUVhBgAAQEyaeF1PSdL9f6o8o3EozAAAAIhJHZun667LCvRO5S79dfWuRo9DYQYAAEDMuvWCLurWOlO/nlOhqlM1jRqDwgwAAICYlZyYoPuH9tLW/cf1xPvrGjUGhRkAAAAx7fyuuRp2Xns99eEGbdz7eYP3pzADAAAg5v38mrOVkpigia+vknOuQftSmAEAABDzWmel6t7Lu+tvn+7VWyt3NmhfCjMAAADiQvGgfPVq30wPvFGpoyeqg96PwgwAAIC4kOhL0IPDemvXkSr9/7+sDXo/CjMAAADiRt9OzTV8QJ6enb8p6H0ozAAAAIgrP72ih5qlJga9PYUZAAAAcaV5RrIeGdE36O0pzAAAAIg7Fxa0CnpbCjMAAAAQAIUZAAAACIDCDAAAAARAYQYAAAACoDADAAAAAVCYAQAAgAAozAAAAEAAFGYAAAAgAAozAAAAEACFGQAAAAiAwgwAAAAEQGEGAAAAAqAwAwAAAAFQmAEAAIAAKMwAAABAABRmAAAAIAAKMwAAABAAhRkAAAAIgMIMAAAABEBhBgAAAAIw55zXGb7AzI5IWuN1DkiSciXt9ToEmIcowlxEB+YhejAX0YF5aLx851yr+jZKjESSBlrjnCv0OgQkMytjLrzHPEQP5iI6MA/Rg7mIDsxD+HFJBgAAABAAhRkAAAAIIBoL8ySvA+AfmIvowDxED+YiOjAP0YO5iA7MQ5hF3U1/AAAAQDSJxjPMAAAAQNTwrDCb2ZVmtsbM1pnZhK/4/D1mVmlmK8zsPTPL9yJnPAhiLm43s5VmtszM5plZTy9yxrr65qHOdt81M2dm3BEdBkG8Hkab2R7/62GZmf3Ai5zxIJjXhJnd6P9ZUWFmUyOdMR4E8Zr4Q53Xw1ozO+hFzngQxFx0MrP3zWypvz9d7UXOWOTJJRlm5pO0VtK3JG2TtFjSCOdcZZ1tLpG00Dl3zMz+TdLFzrnvRTxsjAtyLpo55w77P75e0h3OuSu9yBurgpkH/3ZZkt6UlCxpvHOuLNJZY1mQr4fRkgqdc+M9CRkngpyLAkkzJF3qnDtgZq2dc7s9CRyjgv3eVGf7OyX1dc6NiVzK+BDka2KSpKXOuSf9J7fecs519iJvrPHqDPNASeuccxuccyclTZc0tO4Gzrn3nXPH/A8XSOoY4YzxIpi5OFznYYYkLnwPvXrnwe8BSb+XVBXJcHEk2HlA+AUzF2MlPe6cOyBJlOWwaOhrYoSkaRFJFn+CmQsnqZn/42xJOyKYL6Z5VZg7SNpa5/E2/3Nf51ZJfw5rovgV1FyY2TgzWy/pIUl3RShbPKl3Hsysn6Q859ybkQwWZ4L93vRd/587Z5pZXmSixZ1g5qK7pO5mNt/MFpgZf/kKvaB/Xvsvnewi6a8RyBWPgpmL30gqNrNtkt6SdGdkosW+qL/pz8yKJRVKetjrLPHMOfe4c66rpJ9J+qXXeeKNmSVI+i9J93qdBfqTpM7OuXMlvSvpeY/zxLNESQWSLlbtmc1nzCzH00Txbbikmc65Gq+DxLERkqY45zpKulpSif/nB86QV1/E7ZLqnpXp6H/uC8zsm5J+Iel659yJCGWLN0HNRR3TJQ0La6L4VN88ZEnqLekDM9skaZCkOdz4F3L1vh6cc/vqfD/6o6T+EcoWb4L53rRN0hzn3Cnn3EbVXt9ZEKF88aIhPyOGi8sxwimYubhVtdf1yzlXKilVUm5E0sU4rwrzYkkFZtbFzJJV+yKbU3cDM+sr6WnVlmWuSwufYOai7g+gayR9GsF88SLgPDjnDjnncp1znf03cCxQ7WuDm/5CK5jXQ7s6D6+X9EkE88WTeudC0mzVnl2WmeWq9hKNDZEMGQeCmQeZWQ9JzSWVRjhfPAlmLrZIukySzOxs1RbmPRFNGaMSvTioc67azMZLmivJJ+lZ51yFmd0vqcw5N0e1l2BkSnrFzCRpi3Puei/yxrIg52K8/2z/KUkHJN3iXeLYFOQ8IMyCnIe7/O8WUy1pv6TRngWOYUHOxVxJl5tZpaQaST9xzu3zLnXsacD3puGSpjtWQwubIOfiXtVemvQj1d4AOJo5CQ1W+gMAAAAC4EJwAAAAIAAKMwAAABAAhRkAAAAIgMIMAAAABEBhBgAAAAKgMANAhJhZjpnd4f/4YjN7IwzHGG1mjzVwn03+9zH+8vO/MbMfhy4dADRNFGYAiJwcSXc0ZAcz84UpCwAgSBRmAIic/5TU1cyWyb84k5nNNLPVZvaS+Vdp8p/x/b2ZLZF0g5l1NbO3zazczP7mX1VNZnaDma0ys+Vm9lGd47T3b/+pmT309yfNbISZrfTv8/uvCmhmvzCztWY2T9I3wvWFAICmxJOV/gAgTk2Q1Ns5d56ZXSzpdUm9JO2QNF/SEEnz/Nvuc871kyQze0/S7c65T82sSNITki6VNFHSFc657WaWU+c450nqK+mEpDVm9qhqV8L7vaT+ql2x8x0zG+acm/33ncysv2pXbDtPtT8flkgqD/2XAQCaFgozAHhnkXNumyT5zzp31v8W5pf9z2dKOl/SK/4T0JKU4v93vqQpZjZD0mt1xn3POXfIv3+lpHxJLSV94Jzb43/+JUn/Iml2nf0ulDTLOXfMvw1LsgOAKMwA4KUTdT6u0Re/J3/u/zdB0kHn3Hlf3tk5d7v/jPM1ksr9Z4jrGxcA0EBcwwwAkXNEUlZDdnDOHZa00cxukCSr1cf/cVfn3ELn3ERJeyTlBRhqkaSLzCzXfyPhCEkffmmbjyQNM7M0M8uSdF1DsgJArOKsAwBEiHNun5nNN7NVko5L2hXkrjdJetLMfikpSdJ0ScslPWxmBZJM0nv+5/7pTLT/2J+Z2QRJ7/u3f9M59/qXtlliZi/7x9ktaXFD/48AEIvMOed1BgAAACBqcUkGAAAAEACFGQAAAAiAwgwAAAAEQGEGAAAAAqAwAwAAAAFQmAEAAIAAKMwAAABAABRmAAAAIID/AazUOSbIbUFaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 比較\n",
    "- ResNetでは、しきい値が1.0に近づくほどIoUの結果が高くなったが、VGGでは逆に1.0に近づくほどIoUの結果が下がる傾向となった\n",
    "- IoUのベストスコアの結果としては、ResNetが0.4917(しきい値:0.880)、VGGでは0.4080(しきい値:0.200)となった\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "ja"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "ja",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
