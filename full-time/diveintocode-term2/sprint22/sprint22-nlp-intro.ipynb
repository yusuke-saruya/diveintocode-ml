{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Sprint22課題 自然言語処理入門"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:09.395124Z",
     "start_time": "2019-06-25T08:02:01.778261Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 正規表現操作のライブラリ\n",
    "import re\n",
    "\n",
    "from janome.tokenizer import Tokenizer\n",
    "from janome.analyzer import Analyzer\n",
    "from janome.tokenfilter import POSKeepFilter, CompoundNounFilter, TokenCountFilter\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】BoWとN-gram(手計算)\n",
    "\n",
    "**目的**\n",
    "\n",
    "- 古典的かつ強力な手法BoWとN-gramの理解  \n",
    "\n",
    "以下は俳優K.Kさんのつぶやき(コーパス)です。\n",
    "\n",
    "```\n",
    "文1: 今撮影中で〜す！\n",
    "文2: 今休憩中で〜す(^^)\n",
    "文3: 今日ドラマ撮影で〜す！\n",
    "文4: 今日、映画瞬公開で〜す！！！\n",
    "```\n",
    "\n",
    "**【問】**\n",
    "特殊文字除去(!や〜など)、単語分割をし以下の2パターンで文1〜文4を数値化(ベクトル化)してください。\n",
    "\n",
    "- BoW(1-gram)\n",
    "- BoW(2-gram)\n",
    "\n",
    "手計算の後見やすい形にしてください。\n",
    "\n",
    "**例**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "vocabulary = [\"I\", \"love\", \"this\", \"is\", \"the\", \"baseball\"]\n",
    "ms_kk_texts = [\"I love baseball !!\", \"I love this !\"]\n",
    "texts_vec = [[1,1,0,0,0,1], [1,1,1,0,0,0]]\n",
    "\n",
    "df_bow_1gram = pd.DataFrame(data = texts_vec, columns = vocabulary, index = ms_kk_texts)\n",
    "df_bow_1gram\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:09.465373Z",
     "start_time": "2019-06-25T08:02:09.400084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>今</th>\n",
       "      <th>今日</th>\n",
       "      <th>ドラマ</th>\n",
       "      <th>撮影</th>\n",
       "      <th>休憩</th>\n",
       "      <th>映画</th>\n",
       "      <th>瞬</th>\n",
       "      <th>公開</th>\n",
       "      <th>中</th>\n",
       "      <th>です</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>今撮影中で〜す！</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今休憩中で〜す(^^)</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今日ドラマ撮影で〜す！</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今日、映画瞬公開で〜す！！！</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                今  今日  ドラマ  撮影  休憩  映画  瞬  公開  中  です\n",
       "今撮影中で〜す！        1   0    0   1   0   0  0   0  1   1\n",
       "今休憩中で〜す(^^)     1   0    0   0   1   0  0   0  1   1\n",
       "今日ドラマ撮影で〜す！     0   1    1   1   0   0  0   0  0   1\n",
       "今日、映画瞬公開で〜す！！！  0   1    0   0   0   1  1   1  0   1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = [\"今\",\"今日\", \"ドラマ\", \"撮影\", \"休憩\",\"映画\", \"瞬\",\"公開\", \"中\", \"です\"]\n",
    "\n",
    "ms_kk_texts = [\n",
    "    \"今撮影中で〜す！\", \n",
    "    \"今休憩中で〜す(^^)\", \n",
    "    \"今日ドラマ撮影で〜す！\",\n",
    "    \"今日、映画瞬公開で〜す！！！\"\n",
    "]\n",
    "\n",
    "texts_vec = [\n",
    "    [1,0,0,1,0,0,0,0,1,1], \n",
    "    [1,0,0,0,1,0,0,0,1,1], \n",
    "    [0,1,1,1,0,0,0,0,0,1],\n",
    "    [0,1,0,0,0,1,1,1,0,1]\n",
    "]\n",
    "\n",
    "df_bow_1gram = pd.DataFrame(data = texts_vec, columns = vocabulary, index = ms_kk_texts)\n",
    "df_bow_1gram\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:09.496860Z",
     "start_time": "2019-06-25T08:02:09.468819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>今撮影</th>\n",
       "      <th>撮影中</th>\n",
       "      <th>今休憩</th>\n",
       "      <th>休憩中</th>\n",
       "      <th>中です</th>\n",
       "      <th>今日ドラマ</th>\n",
       "      <th>ドラマ撮影</th>\n",
       "      <th>撮影です</th>\n",
       "      <th>今日映画</th>\n",
       "      <th>映画瞬</th>\n",
       "      <th>瞬公開</th>\n",
       "      <th>公開です</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>今撮影中で〜す！</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今休憩中で〜す(^^)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今日ドラマ撮影で〜す！</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今日、映画瞬公開で〜す！！！</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                今撮影  撮影中  今休憩  休憩中  中です  今日ドラマ  ドラマ撮影  撮影です  今日映画  映画瞬  瞬公開  \\\n",
       "今撮影中で〜す！          1    1    0    0    1      0      0     0     0    0    0   \n",
       "今休憩中で〜す(^^)       0    0    1    1    1      0      0     0     0    0    0   \n",
       "今日ドラマ撮影で〜す！       0    0    0    0    0      1      1     1     0    0    0   \n",
       "今日、映画瞬公開で〜す！！！    0    1    0    0    0      0      0     0     1    1    1   \n",
       "\n",
       "                公開です  \n",
       "今撮影中で〜す！           0  \n",
       "今休憩中で〜す(^^)        0  \n",
       "今日ドラマ撮影で〜す！        0  \n",
       "今日、映画瞬公開で〜す！！！     1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = [\n",
    "    \"今撮影\", \n",
    "    \"撮影中\", \n",
    "    \"今休憩\", \n",
    "    \"休憩中\", \n",
    "    \"中です\", \n",
    "    \"今日ドラマ\",\n",
    "    \"ドラマ撮影\",\n",
    "    \"撮影です\", \n",
    "    \"今日映画\", \n",
    "    \"映画瞬\", \n",
    "    \"瞬公開\", \n",
    "    \"公開です\"\n",
    "]\n",
    "\n",
    "ms_kk_texts = [\n",
    "    \"今撮影中で〜す！\", \n",
    "    \"今休憩中で〜す(^^)\", \n",
    "    \"今日ドラマ撮影で〜す！\",\n",
    "    \"今日、映画瞬公開で〜す！！！\"\n",
    "]\n",
    "\n",
    "texts_vec = [\n",
    "    [1,1,0,0,1,0,0,0,0,0,0,0], \n",
    "    [0,0,1,1,1,0,0,0,0,0,0,0], \n",
    "    [0,0,0,0,0,1,1,1,0,0,0,0],\n",
    "    [0,1,0,0,0,0,0,0,1,1,1,1]\n",
    "]\n",
    "\n",
    "df_bow_2gram = pd.DataFrame(\n",
    "    data = texts_vec, \n",
    "    columns = vocabulary, \n",
    "    index = ms_kk_texts\n",
    ")\n",
    "df_bow_2gram\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】TF-IDF(手計算)\n",
    "**目的**\n",
    "\n",
    "- 古典的かつ強力なTF-IDFの理解\n",
    "\n",
    "標準的なTF-IDFの公式  \n",
    "Term Frequency:\n",
    "\n",
    "$$\n",
    "tf(t,d) = \\frac{n_{t,d}}{\\sum_{s \\in d}n_{s,d}}\n",
    "$$\n",
    "\n",
    "$n_{t,d}$: 文書d内の単語tの出現回数  \n",
    "$\\sum_{s \\in d}n_{s,d}$文書dの全単語の出現回数の和  \n",
    "\n",
    "Inverse Document Frequency:\n",
    "\n",
    "$$\n",
    "idf(t) = \\log_2{\\frac{N}{df(t)}}\n",
    "$$\n",
    "\n",
    "$N$ : 全文書数  \n",
    "$df(t)$: 単語tが出現する文書数\n",
    "\n",
    "TF-IDF:\n",
    "\n",
    "$$\n",
    "tfidf(t, d) = tf(t, d) \\times idf(t)\n",
    "$$\n",
    "\n",
    "**【問】**  \n",
    "問題1のコーパスを使って、文1〜文4をTFIDFで数値化(ベクトル化)してください。   \n",
    "問題1と同様、手計算の後見やすい形にしてください。\n",
    "\n",
    "*正解例*  \n",
    "tfidf(今, 文書1) = 0.25 になります。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:09.518910Z",
     "start_time": "2019-06-25T08:02:09.501470Z"
    }
   },
   "outputs": [],
   "source": [
    "# 上記文章におけるtfidfの計算\n",
    "def tfidf(t, d):\n",
    "    '''\n",
    "    TF-IDFの計算\n",
    "    \n",
    "    Parameter\n",
    "    ----------\n",
    "    t : 単語\n",
    "    d : 文書\n",
    "    \n",
    "    Return\n",
    "    ---------\n",
    "    TF-IDF\n",
    "    '''\n",
    "    # TFの計算\n",
    "    tf = df_bow_1gram.loc[d ,[t]].values[0]\\\n",
    "                / sum(df_bow_1gram.loc[d])\n",
    "\n",
    "    # IDFの計算\n",
    "    idf = np.log2(df_bow_1gram.shape[0]\n",
    "                  / df_bow_1gram[df_bow_1gram[t]>0].shape[0])\n",
    "    \n",
    "    # TF-IDF\n",
    "    return tf * idf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:09.544554Z",
     "start_time": "2019-06-25T08:02:09.523430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf('今', '今撮影中で〜す！')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】テキストクリーニング(プログラミング)\n",
    "**目的**\n",
    "\n",
    "- 実データ対応のためのテキストクリーニングの理解\n",
    "- 正規表現の理解\n",
    "\n",
    "\n",
    "実際のテキストデータは非常に汚いことが多いです。  \n",
    "以下は3/6(水)にnoroさんがSlackで発言した文章で、良い例です。\n",
    "\n",
    "```\n",
    "<!everyone> *【スペシャル特典】有償のRubyMineやPyCharmの `6ヶ月間100%OFFクーポン` をご希望者の方先着100名様に贈呈いたします！*\\n\\nこの度、RubyMineやPyCharmのメーカーであるJetBrains社へのクーポンコードの提供交渉が実り、100クーポンをいただくことができました。\\n\\n```\\nRubyMine\\n<https://www.jetbrains.com/ruby/>\\n\\nPyCharm\\n<https://www.jetbrains.com/pycharm/>\\n```\\n\\n「ご希望の方は、手を挙げて！」方式で、ご希望の方はこの投稿の手あげスタンプをクリックしてください。\\n\\n期限は、 *`2019年3月20日（水）22:00まで`* とさせていただきます。\\nふるってのご希望をお待ちしております！ :smile:\n",
    "```\n",
    "\n",
    "**【問】**  \n",
    "このテキストに以下の処理を施してください。\n",
    "\n",
    "- urlを削除\n",
    "- 【〇〇】を削除\n",
    "- 改行等の特殊文字を削除\n",
    "- 絵文字除去\n",
    "\n",
    "\n",
    "ここではしませんが、数字を文字列NUMBERに置き換える処理をよくします。\n",
    "\n",
    "**正解例**  \n",
    "```\n",
    "有償のRubyMineやPyCharmの6ヶ月間100%OFFクーポンをご希望者の方先着100名様に贈呈いたします！この度、RubyMineやPyCharmのメーカーであるJetBrains社へのクーポンコードの提供交渉が実り、100クーポンをいただくことができました。RubyMinePyCharm「ご希望の方は、手を挙げて！」方式で、ご希望の方はこの投稿の手あげスタンプをクリックしてください。期限は、2019年3月20日（水）22:00までとさせていただきます。ふるってのご希望をお待ちしております！\n",
    "```\n",
    "\n",
    "**正規表現のサンプル**\n",
    "```python\n",
    "# 正規表現操作のライブラリ\n",
    "import re\n",
    "# 対象テキストデータ\n",
    "text = '【スペシャル特典】有償のRubyMineやPyCharmの `6ヶ月間100%OFFクーポン` をご希望者の方先着100名様に贈呈いたします！*\\n\\n'\n",
    "# re.compileを使うと処理が早くなります\n",
    "BAD_SYMBOL = re.compile('[\\n*！`]+')\n",
    "# re.sub(r'[\\n*！`]+', '', text)でもできます\n",
    "text = re.sub(BAD_SYMBOL, '', text)\n",
    "text\n",
    "```\n",
    "\n",
    "リアルタイムで正規表現を確認できるサイトです。  \n",
    "https://regex101.com/\n",
    "\n",
    "https://regex-testdrive.com/ja/dotest\n",
    "\n",
    "[re 正規表現操作](https://docs.python.org/ja/3/library/re.html)\n",
    "\n",
    "### Tips NLPのLinuxコマンド\n",
    "これまでpythonでファイルを読み込んで処理をしていましたが、\n",
    "簡単な作業においてはlinuxコマンドの方がメモリの使用料が半分以下だったりとパフォーマンスが良いです。\n",
    "\n",
    "例えばファイルの行数を数えたい場合、pythonでわざわざ書くのは面倒です。\n",
    "以下の1行のコマンドで実行できます。\n",
    "\n",
    "```\n",
    "wc -l 〇〇.txt\n",
    "```\n",
    "\n",
    "また分割したい場合はsplit  \n",
    "並び替えたい場合はsort  \n",
    "置換にはsed  \n",
    "文の先頭、後頭部分を見たければhead,tail  \n",
    "など便利なコマンドがあります。  \n",
    "詳しく知りたい方はNLP100本ノックで調べてみてください。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:09.563658Z",
     "start_time": "2019-06-25T08:02:09.547966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有償のRubyMineやPyCharmの6ヶ月間100%OFFクーポンをご希望者の方先着100名様に贈呈いたします！この度、RubyMineやPyCharmのメーカーであるJetBrains社へのクーポンコードの提供交渉が実り、100クーポンをいただくことができました。RubyMinePyCharm「ご希望の方は、手を挙げて！」方式で、ご希望の方はこの投稿の手あげスタンプをクリックしてください。期限は、2019年3月20日（水）22:00までとさせていただきます。ふるってのご希望をお待ちしております！\n"
     ]
    }
   ],
   "source": [
    "# 対象テキストデータ\n",
    "text = '<!everyone> *【スペシャル特典】有償のRubyMineやPyCharmの `6ヶ月間100%OFFクーポン` をご希望者の方先着100名様に贈呈いたします！*\\n\\nこの度、RubyMineやPyCharmのメーカーであるJetBrains社へのクーポンコードの提供交渉が実り、100クーポンをいただくことができました。\\n\\n```\\nRubyMine\\n<https://www.jetbrains.com/ruby/>\\n\\nPyCharm\\n<https://www.jetbrains.com/pycharm/>\\n```\\n\\n「ご希望の方は、手を挙げて！」方式で、ご希望の方はこの投稿の手あげスタンプをクリックしてください。\\n\\n期限は、 *`2019年3月20日（水）22:00まで`* とさせていただきます。\\nふるってのご希望をお待ちしております！ :smile:'\n",
    "\n",
    "# 正規表現一覧\n",
    "symbol_reg = r'[\\n*` ]+'  # 改行等の特殊文字を削除\n",
    "mention_reg = r'<.*?>'  #URL除去\n",
    "phraze_reg = r'【.*?】'  # 【〇〇】を削除\n",
    "command_reg = r':[^0-9０-９]+:'  # 絵文字除去\n",
    "\n",
    "reg_str = f'{symbol_reg}|{mention_reg}|{phraze_reg}|{command_reg}'\n",
    "reg_str = re.compile(reg_str)\n",
    "\n",
    "# re.sub(r'[\\n*！`]+', '', text)でもできます\n",
    "text = re.sub(reg_str, '', text)\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】形態素解析\n",
    "**目的**\n",
    "\n",
    "- 形態素解析の理解  \n",
    "\n",
    "形態素解析のツールはMecabやJanomeなど様々ですが、  \n",
    "ここでは手軽に導入できるJanomeを使います。  \n",
    "[Janome document](https://mocobeta.github.io/janome/)\n",
    "\n",
    "**【問】**\n",
    "上記のクリーニングしたテキストをJanomeを用いて形態素解析をし、  \n",
    "名詞または動詞の単語を抜き出してください。  \n",
    "\n",
    "**正解例**\n",
    "```python\n",
    "[\"有償\", \"RubyMine\", \"Pycharm\", ...]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:12.036767Z",
     "start_time": "2019-06-25T08:02:09.571406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有償\t名詞,一般,*,*,*,*,有償,ユウショウ,ユーショー\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "RubyMine\t名詞,一般,*,*,*,*,RubyMine,*,*\n",
      "や\t助詞,並立助詞,*,*,*,*,や,ヤ,ヤ\n",
      "PyCharm\t名詞,一般,*,*,*,*,PyCharm,*,*\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "6\t名詞,数,*,*,*,*,6,*,*\n",
      "ヶ月\t名詞,接尾,助数詞,*,*,*,ヶ月,カゲツ,カゲツ\n",
      "間\t名詞,接尾,一般,*,*,*,間,カン,カン\n",
      "100\t名詞,数,*,*,*,*,100,*,*\n",
      "%\t名詞,サ変接続,*,*,*,*,%,*,*\n",
      "OFF\t名詞,一般,*,*,*,*,OFF,*,*\n",
      "クーポン\t名詞,一般,*,*,*,*,クーポン,クーポン,クーポン\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "ご\t接頭詞,名詞接続,*,*,*,*,ご,ゴ,ゴ\n",
      "希望\t名詞,サ変接続,*,*,*,*,希望,キボウ,キボー\n",
      "者\t名詞,接尾,一般,*,*,*,者,シャ,シャ\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "方\t名詞,非自立,一般,*,*,*,方,ホウ,ホー\n",
      "先着\t名詞,サ変接続,*,*,*,*,先着,センチャク,センチャク\n",
      "100\t名詞,数,*,*,*,*,100,*,*\n",
      "名\t名詞,接尾,助数詞,*,*,*,名,メイ,メイ\n",
      "様\t名詞,接尾,人名,*,*,*,様,サマ,サマ\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "贈呈\t名詞,サ変接続,*,*,*,*,贈呈,ゾウテイ,ゾーテイ\n",
      "いたし\t動詞,非自立,*,*,五段・サ行,連用形,いたす,イタシ,イタシ\n",
      "ます\t助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "！\t記号,一般,*,*,*,*,！,！,！\n",
      "この\t連体詞,*,*,*,*,*,この,コノ,コノ\n",
      "度\t名詞,非自立,副詞可能,*,*,*,度,タビ,タビ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "RubyMine\t名詞,固有名詞,組織,*,*,*,RubyMine,*,*\n",
      "や\t助詞,並立助詞,*,*,*,*,や,ヤ,ヤ\n",
      "PyCharm\t名詞,一般,*,*,*,*,PyCharm,*,*\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "メーカー\t名詞,一般,*,*,*,*,メーカー,メーカー,メーカー\n",
      "で\t助動詞,*,*,*,特殊・ダ,連用形,だ,デ,デ\n",
      "ある\t助動詞,*,*,*,五段・ラ行アル,基本形,ある,アル,アル\n",
      "JetBrains\t名詞,一般,*,*,*,*,JetBrains,*,*\n",
      "社\t名詞,接尾,一般,*,*,*,社,シャ,シャ\n",
      "へ\t助詞,格助詞,一般,*,*,*,へ,ヘ,エ\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "クーポン\t名詞,一般,*,*,*,*,クーポン,クーポン,クーポン\n",
      "コード\t名詞,一般,*,*,*,*,コード,コード,コード\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "提供\t名詞,サ変接続,*,*,*,*,提供,テイキョウ,テイキョー\n",
      "交渉\t名詞,サ変接続,*,*,*,*,交渉,コウショウ,コーショー\n",
      "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "実り\t動詞,自立,*,*,五段・ラ行,連用形,実る,ミノリ,ミノリ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "100\t名詞,数,*,*,*,*,100,*,*\n",
      "クーポン\t名詞,一般,*,*,*,*,クーポン,クーポン,クーポン\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "いただく\t動詞,自立,*,*,五段・カ行イ音便,基本形,いただく,イタダク,イタダク\n",
      "こと\t名詞,非自立,一般,*,*,*,こと,コト,コト\n",
      "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "でき\t動詞,自立,*,*,一段,連用形,できる,デキ,デキ\n",
      "まし\t助動詞,*,*,*,特殊・マス,連用形,ます,マシ,マシ\n",
      "た\t助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "RubyMinePyCharm\t名詞,一般,*,*,*,*,RubyMinePyCharm,*,*\n",
      "「\t記号,括弧開,*,*,*,*,「,「,「\n",
      "ご\t接頭詞,名詞接続,*,*,*,*,ご,ゴ,ゴ\n",
      "希望\t名詞,サ変接続,*,*,*,*,希望,キボウ,キボー\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "方\t名詞,非自立,一般,*,*,*,方,ホウ,ホー\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "手\t名詞,一般,*,*,*,*,手,テ,テ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "挙げ\t動詞,自立,*,*,一段,連用形,挙げる,アゲ,アゲ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "！\t記号,一般,*,*,*,*,！,！,！\n",
      "」\t記号,括弧閉,*,*,*,*,」,」,」\n",
      "方式\t名詞,一般,*,*,*,*,方式,ホウシキ,ホーシキ\n",
      "で\t助詞,格助詞,一般,*,*,*,で,デ,デ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "ご\t接頭詞,名詞接続,*,*,*,*,ご,ゴ,ゴ\n",
      "希望\t名詞,サ変接続,*,*,*,*,希望,キボウ,キボー\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "方\t名詞,非自立,一般,*,*,*,方,ホウ,ホー\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "この\t連体詞,*,*,*,*,*,この,コノ,コノ\n",
      "投稿\t名詞,サ変接続,*,*,*,*,投稿,トウコウ,トーコー\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "手\t名詞,一般,*,*,*,*,手,テ,テ\n",
      "あげ\t動詞,自立,*,*,一段,連用形,あげる,アゲ,アゲ\n",
      "スタンプ\t名詞,一般,*,*,*,*,スタンプ,スタンプ,スタンプ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "クリック\t名詞,一般,*,*,*,*,クリック,クリック,クリック\n",
      "し\t動詞,自立,*,*,サ変・スル,連用形,する,シ,シ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "ください\t動詞,非自立,*,*,五段・ラ行特殊,命令ｉ,くださる,クダサイ,クダサイ\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "期限\t名詞,一般,*,*,*,*,期限,キゲン,キゲン\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "2019\t名詞,数,*,*,*,*,2019,*,*\n",
      "年\t名詞,接尾,助数詞,*,*,*,年,ネン,ネン\n",
      "3\t名詞,数,*,*,*,*,3,*,*\n",
      "月\t名詞,一般,*,*,*,*,月,ツキ,ツキ\n",
      "20\t名詞,数,*,*,*,*,20,*,*\n",
      "日\t名詞,接尾,助数詞,*,*,*,日,ニチ,ニチ\n",
      "（\t記号,括弧開,*,*,*,*,（,（,（\n",
      "水\t名詞,一般,*,*,*,*,水,ミズ,ミズ\n",
      "）\t記号,括弧閉,*,*,*,*,）,）,）\n",
      "22\t名詞,数,*,*,*,*,22,*,*\n",
      ":\t名詞,サ変接続,*,*,*,*,:,*,*\n",
      "00\t名詞,数,*,*,*,*,00,*,*\n",
      "まで\t助詞,副助詞,*,*,*,*,まで,マデ,マデ\n",
      "と\t助詞,格助詞,引用,*,*,*,と,ト,ト\n",
      "さ\t動詞,自立,*,*,サ変・スル,未然レル接続,する,サ,サ\n",
      "せ\t動詞,接尾,*,*,一段,連用形,せる,セ,セ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "いただき\t動詞,非自立,*,*,五段・カ行イ音便,連用形,いただく,イタダキ,イタダキ\n",
      "ます\t助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "ふるって\t副詞,一般,*,*,*,*,ふるって,フルッテ,フルッテ\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "ご\t接頭詞,名詞接続,*,*,*,*,ご,ゴ,ゴ\n",
      "希望\t名詞,サ変接続,*,*,*,*,希望,キボウ,キボー\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "お待ち\t名詞,サ変接続,*,*,*,*,お待ち,オマチ,オマチ\n",
      "し\t動詞,自立,*,*,サ変・スル,連用形,する,シ,シ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "おり\t動詞,非自立,*,*,五段・ラ行,連用形,おる,オリ,オリ\n",
      "ます\t助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "！\t記号,一般,*,*,*,*,！,！,！\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "for token in t.tokenize(text):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:12.079273Z",
     "start_time": "2019-06-25T08:02:12.051033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['有償', 'RubyMine', 'PyCharm', 'OFF', 'クーポン', 'PyCharm', 'メーカー', 'JetBrains', 'クーポン', 'コード', 'クーポン', 'RubyMinePyCharm', '手', '方式', '手', 'スタンプ', 'クリック', '期限', '月', '水']\n"
     ]
    }
   ],
   "source": [
    "print([token.surface for token in t.tokenize(text)\n",
    "      if token.part_of_speech.startswith('名詞,一般')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:12.126035Z",
     "start_time": "2019-06-25T08:02:12.083266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['いたし', '実り', 'いただく', 'でき', '挙げ', 'あげ', 'し', 'ください', 'さ', 'せ', 'いただき', 'し', 'おり']\n"
     ]
    }
   ],
   "source": [
    "print([token.surface for token in t.tokenize(text)\n",
    "      if token.part_of_speech.startswith('動詞')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】ニュースの分析\n",
    "**目的**\n",
    "\n",
    "- 日本語の自然言語処理の体験\n",
    "- 類似度の理解\n",
    "\n",
    "以下からldcc-20140209.tar.gzをダウンロードしてください。 \n",
    "[livedoor](https://www.rondhuit.com/download.html#ldcc)\n",
    "\n",
    "もしくはwgetコマンドを使っても良いです。\n",
    "\n",
    "```python\n",
    "# livedoorのnewsをダウンロード\n",
    "wget https://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
    "# 圧縮ファイルを解凍\n",
    "tar zxf ldcc-20140209.tar.gz\n",
    "# livedoorニュースの説明を表示\n",
    "cat text/README.txt\n",
    "```\n",
    "\n",
    "**サンプルコード**\n",
    "```python\n",
    "# サブフォルダまで賢く読み込んでもらう\n",
    "from sklearn.datasets import load_files\n",
    "# encodingをutf-8指定して読み込み\n",
    "bin_data = load_files('./text', encoding='utf-8')\n",
    "documents = bin_data.data\n",
    "# 今回はラベルが無いと仮定してください\n",
    "# targets = bin_data.target\n",
    "```\n",
    "\n",
    "【問】\n",
    "以下の流れでニュースを分析してください。\n",
    "\n",
    "- まずどんなニュースなのか読んでみる\n",
    "- 出現単語をカウントして分析する\n",
    "- テキストをクリーニングする\n",
    "- BoW + TFIDFでベクトル化する\n",
    "- あるニュースに一番cos類似度が近いニュースを出力する関数の作成\n",
    "- 別の類似度手法を1つ調べて上の関数に組み込む(切り替えられるようにする)\n",
    "- なぜそのような結果になったのか考察する\n",
    "\n",
    "[sklearn.feature_extraction.text](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:15.085674Z",
     "start_time": "2019-06-25T08:02:12.130430Z"
    }
   },
   "outputs": [],
   "source": [
    "# サブフォルダまで賢く読み込んでもらう\n",
    "from sklearn.datasets import load_files\n",
    "# encodingをutf-8指定して読み込み\n",
    "bin_data = load_files('./text', encoding='utf-8')\n",
    "documents = bin_data.data\n",
    "# 今回はラベルが無いと仮定してください\n",
    "# targets = bin_data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### まずどんなニュースなのか読んでみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:15.114699Z",
     "start_time": "2019-06-25T08:02:15.089116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://news.livedoor.com/article/detail/4931238/\\n2010-08-08T10:00:00+0900\\nNY名物イベントが日本でも！名店グルメを気軽に楽しむ\\nニューヨークで20年続いている食の祭典「レストラン・ウィーク」。その日本版がダイナーズクラブ特別協賛のもと7月30日よりスタート。8月31日までの期間中、青山・六本木、丸の内、銀座、横浜のエリアから、ラグジュアリーレストラン81店舗がこのイベントのために特別用意したランチメニュー2010円（税・サ別）、ディナー5000円（税・サ別）を気軽に楽しめる、とっておきのイベントです。\\n\\u3000\\n\\u3000実行委員長には、学校法人服部学園、服部栄養専門学校 理事長・校長であり医学博士でもある服部幸應氏を迎え、実行委員に石田純一さん、LA BETTOLAオーナーシェフ落合務氏、フードアナリスト協会会長、高賀右近氏、つきぢ田村三代目、田村隆氏に、そして放送作家・脚本家の小山薫堂さんなど、食のスペシャリストたちが勢揃い。\\n\\n参加レストランには、ミシュランのフランス版、東京版ともに星を獲得している吉野建シェフの「レストラン タテル ヨシノ 汐留」や、日本料理の名門「つきぢ田村」、「金田中 庵」、「赤坂璃宮」に「mikuni MARUNOUCHI」など、日本を代表するレストランがずらり。\\n\\u3000イベント期間の〜8月19日までは、特別協賛のダイナーズクラブカード会員、またはシティバンクに口座を持つシティゴールドメンバーが楽しめる先行期間となりますが、その後は誰でも参加できるので、日程のチェックは必須。\\n\\n\\u3000予約方法は必ず事前に、各店舗に問合せを行い「ジャパンレストラン・ウィーク2010」での予約であることを伝えればOK！憧れていたレストランの料理をリーズナブルにいただけるチャンスです！極上の味とラグジュアリーな空間を満喫。そんな幸せを実感できる「ジャパンレストラン・ウィーク2010」にぜひ参加しててみてはいかがですか？\\n\\nJAPAN RESTAURANT WEEK 2010 -公式サイト\\n',\n",
       " 'http://news.livedoor.com/article/detail/6655079/\\n2012-06-13T19:25:00+0900\\n小沢一郎氏の妻が支援者に離婚を報告。「週刊文春」報じる\\n13日、Web版「週刊文春」は、民主党の元代表・小沢一郎氏の妻が、支援者宛に離婚したことを伝える手紙を送ったと報じ、ツイッターやネット掲示板で大きな話題になっている。\\n\\n記事によると、その手紙は「小沢は放射能が怖くて秘書と一緒に逃げだしました」「隠し子が発覚した際、小沢元代表は和子夫人に謝るどころか、『いつでも離婚してやる』と言い放ち、和子夫人は一時は自殺まで考えた」という小沢氏の支持者にとってはショッキングな内容となっている。\\n\\nツイッターやネット掲示板では、「これが小沢一郎の本性か」「こりゃすごいな。てか、がっかりだなあ」などと、手紙の内容に驚く声が相次ぎ、その他にも「小沢潰しですかね?」「元秘書が交番で暴れて逮捕された件といい、小沢氏を潰したい何者かによる工作活動では?」といった声が挙がっていた。\\n\\n【関連情報】\\n・小沢一郎夫人が支援者に「離婚しました」（週刊文春）\\n',\n",
       " 'http://news.livedoor.com/article/detail/5172424/\\n2010-11-30T08:00:00+0900\\n【Sports Watch】田中＆里田の交際、アプローチは里田から\\nグラビアアイドル・ほしのあき＆騎手・三浦皇成がお互いのブログで交際を認めた日、東北楽天ゴールデンイーグルスのエース・田中将大とタレント・里田まいの交際もまた公のものとなったが、本日30日（火）発売の「週刊アサヒ芸能」（12.9号）では、「マー君を“ナンパ”した里田」との見出しで、両者の交際にまつわる関係者の証言を紹介した。\\n\\n同誌にコメントを寄せた芸能デスクによると、「周囲の事情はさておき、当人たちが盛り上がっているのは確か。結婚も完全に視野に入れているようで、すでに新居を探しているとの話まである」という。\\n\\nまた、二人の交際は里田からのアプローチによるものとのことで、前出の芸能デスクは、「2人は昨年末の番組共演時に、里田から猛アタック。『一緒に食事でも』と誘い、春頃にはつきあい始めた。里田は仲のいいスザンヌ（24）、木下優樹菜（22）には、早くから相談していたし、周囲にも浮かれてしゃべりまくっていた。次世代エースをゲットしたわけですから、賞味期限切れ間近の里田にすれば、してやったりでしょう」とも語っている。\\n\\nちなみに、同じく同誌にコメントする球団関係者は、「高校時代は同じ高校の女子生徒と在学中の3年間、ずっとつきあっていましたね。基本はオクテ。プロ入り後にキャバクラなども覚えましたが、まぁ、モテるタイプではないし、女あしらいも不慣れ。高校時代はかなりワガママで、元カノは苦労が絶えなかったと聞いています。同年代の女より、里田のような姉さんタイプのほうが勝負の世界では向いているケースも多いですからね」と明かしており、この交際も田中にとっては“吉”とした。\\n\\n・週刊アサヒ芸能 ［ライト版］＜デジタル＞（PC版）\\n・週刊アサヒ芸能（モバイル版）\\n',\n",
       " 'http://news.livedoor.com/article/detail/6419378/\\n2012-03-30T14:46:00+0900\\n被災地の缶詰を途上国に…「正気じゃない。人殺しだ!!」\\n30日、政府が被災地で製造された水産加工品を発展途上国へ送ると発表したが、その内容があまりにも酷いとネット掲示板で非難が殺到している。\\n\\nMSN産経ニュースの記事によると、東日本大震災の被災地で製造されたイワシやサバの水産加工品を、カンボジアなどの発展途上国の人々に食べてもらうため、政府は国連機関の世界食糧計画（WFP）と政府開発援助（ODA）に関する書簡を交換したことを発表。外務省の幹部は「安全性に問題がないものを輸出することで、海外に根強い風評被害の打破を図りたい」と述べているが、一部の市民団体は原発事故の影響を懸念して反発しているという。\\n\\nこの動きに対してネット掲示板では「風評被害の解決を途上国を使って解消とか、正気とは思えない。人殺しだろ」「こんなことしたら日本の信頼を損ねるだろうが」「餓死寸前の子供にセシウム入りの缶詰食わせるなんて…」「食べさせて応援ってなんか強制みたいだな」と政府を非難する声が相次いだ。\\n\\nまた、「こんなことをしたら風評被害がより拡大するのでは?」と懸念する声もあがっており、今後の政府の動きに注目が集まっている。\\n\\n【関連情報】\\n・食料支援で風評被害解消\\u3000被災地の缶詰を途上国に(MSN産経ニュース)\\n【関連情報】\\n・【食べさせて応援】被災地の缶詰を途上国に送りつけて風評被害を解決！(livedoor Blog)\\n',\n",
       " 'http://news.livedoor.com/article/detail/5113373/\\n2010-11-02T18:20:00+0900\\n仲間由紀恵さん、“生徒”亀梨和也さんを「大人の魅力が出てきた」と絶賛\\n\\u300011月に入り各地のイルミネーションが点灯されると、グっと高まるクリスマス・シーズン。女子の皆さんは彼へのプレゼント、そして彼におねだりするプレゼントの目星はついていますか？\\u3000「男性って何を貰ったら嬉しいんだろう？」「毎年アクセサリーやバッグじゃマンネリ…」とお悩みの皆さん。今年は“美容家電”のプレゼントはいかがでしょうか。\\n\\n\\u30002日、ザ・ペニンシュラ東京にてPanasonic Beauty「キレイを贈るクリスマス」キャンペーンの発表会が行われ、イメージキャラクターの仲間由紀恵さんと亀梨和也さんが登場しました。仲間さんは「ナノケア」シリーズ、亀梨さんは、「ラムダッシュ」のCMでお馴染みですが、2人もプライベートで商品を愛用しているそうです。\\n\\n\\u3000特に、仲間さんは美しい黒髪の秘訣である「ナノケア ヘアードライヤー」をお友達にプレゼントしたことがあるそうです。実は、最近仲間さんの様に“美容家電”を大切な人にプレゼントする人が増加中。夜寝たままお肌のケアを行える人気の「ナイトスチーマー」を「プレゼントされた」と回答した人は、3年前には使用者全体の12%でしたが、現在は28%と、4人に1人以上がプレゼントされている事が分かっています。\\n\\n\\u3000パナソニックが女性約100名に「定番以外でプレゼントして欲しいものは？」と聞いた調査では、「美容家電・エステ機器」を回答した人が36%とダントツの1位。実用的でありながら、自分を美しくしてくれるアイテムに人気が集まる結果となりました。彼にもらったプレゼントで、彼の為にもっと美しくなりたい！\\u3000そんな女ゴコロがこめられているのかもしれませんね。\\n\\n\\u3000Panasonic Beauty「キレイを贈るクリスマス」キャンペーンでは、本日2日から2010年12月31日（金）までの期間中、202名に素敵なプレゼントが当たるチャンスが。中でも、仲間さんがプロデュースした「オリジナルデコ ラムダッシュ」、亀梨さんがプロデュースした「オリジナルデコ スチーマー」は世界に1つしかない、超レアアイテムです。\\n\\n\\u3000亀梨さんをイメージして、「ラムダッシュ」のデコデザインをしたという仲間さんは「大人の魅力が出てきた亀梨さんにピッタリな、豪華で格好良いデザインにしました。5年前、初対面だったドラマの撮影では“演技の経験があまり無いんです”と初々しい表情を見せていた子が、みるみるうちに大きくなり、先生は嬉しいです！」と、ドラマ「ごくせん」のキャラクター“ヤンクミ”の表情を一瞬のぞかせました。\\n\\n\\u3000一方の亀梨さんは仲間さんについて「きれいなお姉さんだけど、キュートな一面もあって、ドラマの撮影時には生徒役の皆で“マジでカワイイよね”って話していました」と当時の思い出話を語りながらも、「美容家電のプレゼントって、他のプレゼントよりも相手と近くなれるというか、愛情を感じます」とコメント。司会者から「亀梨さんはこのラムダッシュを誰に贈りたいですか？」と尋ねられると「聖（KAT-TUNのメンバー田中聖）が、新しいの欲しがってるんですよ。でも、贈るかどうかは考えます（笑）」と会場の笑いを誘っていました。\\n\\n\\u3000本日からオープンしたPanasonic Beauty「キレイを贈るクリスマス」特設サイトでは、プレゼントキャンペーンの詳細の他、彼や彼女に欲しいアイテムを“おねだり”出来る「おねだりグリーティング」機能も。あなたも、LOVEメッセージ付きで、可愛く彼におねだりしちゃいましょう！\\n\\n・Panasonic Beauty「キレイを贈るクリスマス」 - キャンペーンサイト\\n',\n",
       " 'http://news.livedoor.com/article/detail/5769371/\\n2011-11-08T11:00:00+0900\\n「セクハラや不倫が横行している会社です…」 - 辛口説教部屋 vol.43\\n「3年で転職は早すぎる？」「将来が見えない」\\n「仕事が面白くない」・・・若手社会人の悩みは尽きないもの。\\nそんな様々な悩みに辛口4姉妹がお答えします。\\n\\n\\n今回のお悩み\\n\\nQ：セクハラや不倫が横行している会社です。こんな会社でも三年い続けないと評価してもらえないのでしょうか。\\n\\n\\n不動産業・営業\\n25歳\\u3000女性 <悩める相談者 No.043>\\n現在入社2年目。法人営業をしています。女性を積極的に採用している会社ということで、男女分け隔てなく活躍できると思い今の会社に入社しました。しかし、入社してみたらびっくり。女性は上司のセクハラ対象だったのです。社内恋愛が多い会社とは聞いていて、仲の良い会社なんだな、と思っていましたが、社内不倫まで横行している始末・・・。\\n仕事内容は楽しいのですが、こんな会社にこれ以上いるのは耐えられません。こんな会社でも３年間勤めないと転職市場では「我慢できない若者」の烙印を押されてしまうのでしょうか。 \\n\\n\\nプア子からの辛口アドバイス\\n\\nA：見られるのはあなたの活躍。\\n\\nどうも。年収200万円台のプア子です。昨日は奮発してマックでセットを買っちゃったの。\\n\\nお悩み見たわ。ひとつの会社に三年勤めないと書類選考でハンデを背負うのは確か。でも、ただ三年勤めれば有利なこともないのよ。大切なのは、何を考え、どんな結果を出してきたか。今の職場は確かにひどい環境だと思うけど、多かれ少なかれ、どこの会社にも似たような状態はあるもの。\\n\\n転職したい理由を環境のせいにせず、成果が正当に評価されない、くらいの気概がほしいわ。\\n\\n不動産って売れば売るほど稼げるんでしょ。うらやましいわよ。 \\n\\n\\n今回の説教\\n\\n環境のせいにせず、結果で勝負しなさい。\\n\\n（情報提供元：@type）\\n\\nlivedoor求人・転職\\nlivedoor求人・転職は、あなたがどんな求人情報を探しているのかを瞬時に判断しておすすめするコンテンツ。「心機一転、新たな環境で活躍できる！ 積極採用を行っている企業特集」など、耳寄り転職情報を提供中です。\\nhttp://type.jp/s/livedoor/\\n',\n",
       " \"http://news.livedoor.com/article/detail/4646466/\\n2010-03-08T21:00:00+0900\\nフラワープリントvs.マリンスタイル\\u3000あなたはどっちがお好き？\\n\\u30003月に入り、そろそろ気になるのが春夏のファッション・トレンド。6日に開催された「東京ガールズコレクション'10 S/S（以下、TGC）」では、全体的にロンパース、オールインワンと呼ばれるリラックスモードの“つなぎスタイル”やフラワープリントが多く見られました。また、昨年から引き続きボーダーを多用したマリンスタイルも人気を集めているようです。\\n\\n\\u3000TGCは日本のリアルクローズを世界へ向けてアピールすることを目的に初開催された国内最大級のファッションフェスタ。今回で記念すべき10回目を迎え、国内外からさらに多くの注目を集めています。\\n\\n\\u3000香里奈さん着用のCECIL McBEEのフラワー柄オールインワンは、ゴールドのビッグブレスレットで大人っぽさを演出しているのがポイント。峰えりかさん着用のマキシ丈ワンピースはタウンユースもリゾート使いも両方出来そうですね。クリスティーナさんがラブリーに着こなした、31 Sons de modeのワンピースは勝負デートの時に大活躍しちゃうかも。\\n\\n\\u3000藤井リナさん着用のボーダーのカットソーは、ショートパンツに合わせても、流行のボーイフレンドデニムとラフに着るのも可愛い優秀アイテム。トリンドル玲奈さんのスウィートなコーディネートは、着ているだけでHAPPYになれそうですね。\\n\\n\\u3000フラワーとボーダーという、不変的なモチーフだからこそ、ボトムや小物で変化をつけて、オン／オフ両方着回すのが賢いお仕事ガール。皆さんはどのコーディネートがお好みですか？\\n\\n・東京ガールズコレクション\\n\",\n",
       " 'http://news.livedoor.com/article/detail/6732499/\\n2012-07-07T17:00:00+0900\\nあなたの打たれ強さ度は?／イイ女を作る朝型生活など−【ライフスタイル】週間ランキング\\n人間関係をスムーズにするヒントやライフハック、節約ネタなど、今すぐ役立つ情報が詰まったPeachyの「ライフスタイル」カテゴリ。\\n\\nこのカテゴリのなかから、2012年6月27日〜7月4日の間に最も多く読まれた記事TOP5をご紹介します！\\n\\n第1位：1年間洗顔せずお化粧を続けるとこうなる!? 365日分のお化粧を施したらドロドロになってしもうたよ\\n\\nあなたはこんなことを考えたことがありますか？「私って、1年にどれくらい化粧品を使っているんだろう？」そんな素朴な疑問を、モデルを使って実際に目に見える形にしてしまった、2人のオランダ人アーティストがいました。彼らの名は、Lernert&Sander（ふたりとも男性です！）。ただしこのふたりが表現したかったことは、「人は1年に化粧品をどれくらい使うのか」ではなく、「どれくらい化粧品を使えば、人は自然な状態からとんでもない状態になるのか」ということ。彼らは「そうだ！\\u3000化粧品を1年分塗り重ねていけば、きっととんでもなくなるはずだ！」と、考えたわけです。\\n\\n第2位：あなたの「打たれ強さ度」を診断\\n\\n恋がうまくいかなかったり、理不尽なことで上司に怒られたり。生きていると凹むことっていっぱいありますよね。どん底気分のとき、あなたはすぐに回復できる人？\\u3000それともなかなか立ち直れないほう？\\u3000恋愛カウンセラー・ゆまさん監修の「究極の恋愛科学」では、あなたの「打たれ強さ度」をチェックできる心理テストを公開しています。\\n\\n第3位：レパートリーに悩むママ必見！夏のカンタン朝ごはんとは？\\n\\nあなたは毎日朝ごはんを食べていますか？\\u3000何かと慌しい朝。「時間がなくて毎日同じメニュー」なんて方も多いのではないでしょうか。\\nひとりだと適当にパンやおにぎりをコンビニで購入したり、ダイエットのために朝食を抜くこともあるかもしれませんが、家庭を持っているとそうはいきませんよね。\\n\\n第4位：いい女は朝を制す！朝型女子7の習慣\\n\\n「おはようございます」という挨拶からも気品が漂ってきそうな朝からシャキっと美しい女性、あなたの周りにいませんか？\\n\\n今回はそんな女性たちが実践しているであろう、いい女に欠かせない朝の習慣をまとめてみました。\\n\\n第5位：母性本能が強い女性6の特徴\\n\\n弱ってる男性を前に「この人は私がいないとダメだ、何とかしなきゃ！」とつい使命感に燃えてしまうことありませんか？今回はそんな母性本能が強い女性の特徴をまとめてみました。\\n\\n以上、先週の「ライフスタイル」カテゴリ週間ランキングでした！\\n',\n",
       " 'http://news.livedoor.com/article/detail/5779877/\\n2011-08-12T10:00:00+0900\\nスマホでゲリラ豪雨に備える【デジ通】\\n暑い夏が戻り、同時に、連日のようにゲリラ豪雨が都心を襲っている。無防備なまま出くわすと、濡れるだけではない被害に遭う。スマートフォン（高機能携帯電話）を使って、少しでもゲリラ豪雨を避けよう。\\n\\n■昨年より３割も多い！\\n東京アメッシュ\\n\\n大島克彦＠katsuosh［digi2（デジ通）］\\n\\ndigi2は「デジタル通」の略です。現在のデジタル機器は使いこなしが難しくなっています。\\n皆さんがデジタル機器の「通」に近づくための情報を、皆さんよりすこし通な執筆陣が提供します。    \\n\\n■関連記事\\n・スマホで熱中症を避ける【デジ通】\\n・iPhoneに差すだけ、はんだづけ不用、3500円の空間線量計自作キット【ガイガーカウンター特集：商品紹介】\\n・読書の夏！洋書好きにKindleがオススメな理由\\u3000【デジ通】\\n・真夏のオススメ・ホラー映画BEST5\\u3000【デジ通】\\n・【夏休み特集】読書感想文にスマホを活用する\\n',\n",
       " 'http://news.livedoor.com/article/detail/6798260/\\n2012-07-27T17:00:00+0900\\n音声認識で英語の発音練習しよう Siriを使うiPhoneアプリReal英会話【デジ通】\\nアップルのSiriは音声認識機能を持つバーチャルアシスタントだ。この音声認識機能を使用して、英会話の発音練習に活用している方もいると思われるが、英会話学習アプリでもこの機能を活用し始めている。その1つが、LT Boxの「Real英会話」だ。Real英会話はiPhoneやiPadなどに対応したユニバーサルアプリで、以前から実生活で使われるようなリアルな英会話の学習ができた人気のアプリだ。2012年5月に行われたアップデート（バージョン3.1）では、Siriによる音声認識を使った発音練習機能が追加されている。\\n\\nReal英会話自体は、TOEICなどの練習よりも、主に日常生活で使われているような英会話のリスニングなどを練習できるアプリで、それ自体にも価値があるが、発音認識機能がついたことでさらに価値を増している。\\n\\n単語や文法などは独学で学習できたとしても、発音練習を独学でやるのは難しい。最近利用が本格化してきた音声認識機能を活用すれば、独学での発音練習も現実的になってきた。\\n\\n■Siriの音声認識機能をそのまま利用する\\n実際に試してみると、アプリで学習する日常会話をSiriによる音声認識機能を使ってそのまま学習できるようになっている。アプリのフレーズクイズ内に発音練習があり、ここで練習できる。\\n\\n発音練習画面では、日本語の意味と、英語が表示される。ここに表示される英語を発音し音声認識で正しく認識できれば、そのフレーズを学習したことになる。\\n\\n認識精度はSiriの音声認識機能をそのまま使用するため非常に高い。しかし、日本の多くの学習者は日本語アクセントの英語で発音することが多いため、認識という点ではかなり厳しいのではないかと思われる。\\n\\nSiriの音声認識機能は、英語でも、アメリカ、イギリス、オーストラリアの3つの地域別に設定できる。日本語アクセントの英語という設定はないので、Real英会話アプリで機械的に緩く認識するようなことはない。日本語アクセントの英語で認識させようと思っても、ネイティブが聞き間違えるように間違えて認識されてしまう。\\n\\nReal英会話での学習のコツとしては、発音例も画面をタップすればすぐに再生されるので、英文を読むのではなく、発音例をまねてそのまま発音することだ。\\n\\n筆者も日本語アクセントの英語がやっとだが、なかなか認識されないフレーズについては、なるべくそっくりにまねして発音することで何とか認識されることが多かった。\\n\\n発音がうまくない多くの日本人にとって、かなり厳しい認識精度だが、発音練習の1つとして活用するにはもってこいのアプリだろう。\\n\\nReal英会話\\n\\n上倉賢 @kamikura [digi2(デジ通)] \\n\\ndigi2は「デジタル通」の略です。現在のデジタル機器は使いこなしが難しくなっています。\\n皆さんがデジタル機器の「通」に近づくための情報を、皆さんよりすこし通な執筆陣が提供します。\\n\\n■デジ通の記事をもっと見る\\n・iPhone 4Sの音声認識機能は使える 新しいiPadでも使える音声認識\\n・英語の音声認識で英会話練習 自分の発音を客観的に知る方法\\n・サービス終了後はどうなる！電子書籍は永遠に読めるのか\\n\\t・キンドルが日本に参入する？Amazonの電子書籍をおさらい\\n・iPhoneが据え置きゲーム機も殺す？多機能化するスマートフォン\\n\\n\\n【キヤノン純正インク】キャノンインクタンク 5色マルチパック BCI-321+320/5MP\\nキヤノン\\n販売元：Amazon.co.jp\\nクチコミを見る\\n']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データサイズが大きいため、一部抜粋。\n",
    "documents[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T11:20:14.006212Z",
     "start_time": "2019-06-23T11:20:13.984842Z"
    }
   },
   "source": [
    "#### 出現単語をカウントして分析する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:16.871394Z",
     "start_time": "2019-06-25T08:02:15.120008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/: 45\n",
      ".: 28\n",
      "こと: 26\n",
      "-: 25\n",
      "さん: 23\n",
      "の: 23\n",
      "認識: 23\n",
      ":: 20\n",
      "00: 17\n",
      "発音: 17\n",
      "人: 16\n",
      "livedoor: 14\n",
      "年: 14\n",
      "日: 14\n",
      "機能: 14\n",
      "通: 14\n",
      "プレゼント: 13\n",
      "音声: 13\n",
      "練習: 12\n",
      "英会話: 12\n",
      "http: 11\n",
      "://: 11\n",
      "+: 11\n",
      "2: 11\n",
      "1: 11\n",
      "あなた: 11\n",
      "会社: 11\n",
      "news: 10\n",
      "com: 10\n",
      "article: 10\n",
      "detail: 10\n",
      "T: 10\n",
      "0900: 10\n",
      "者: 10\n",
      "よう: 10\n",
      "2010: 9\n",
      "月: 9\n",
      "小沢: 9\n",
      "情報: 9\n",
      "里: 9\n",
      "田: 9\n",
      "英語: 9\n",
      "日本: 8\n",
      "仲間: 8\n",
      "亀梨: 8\n",
      "女性: 8\n",
      "朝: 8\n",
      "デジ: 8\n",
      "アプリ: 8\n",
      "学習: 8\n",
      "レストラン: 7\n",
      "版: 7\n",
      "ため: 7\n",
      "氏: 7\n",
      "3: 7\n",
      "デジタル: 7\n",
      "ん: 7\n",
      "皆さん: 7\n",
      "的: 7\n",
      "5: 7\n",
      "Siri: 7\n",
      "Real: 7\n",
      "08: 6\n",
      "2012: 6\n",
      "交際: 6\n",
      "もの: 6\n",
      "女: 6\n",
      "途上: 6\n",
      "国: 6\n",
      "品: 6\n",
      "被害: 6\n",
      "彼: 6\n",
      "位: 6\n",
      "転職: 6\n",
      "化粧: 6\n",
      "30: 5\n",
      "中: 5\n",
      "東京: 5\n",
      "田中: 5\n",
      "記事: 5\n",
      "11: 5\n",
      "芸能: 5\n",
      "被災: 5\n",
      "地: 5\n",
      "政府: 5\n",
      "風評: 5\n",
      "クリスマス: 5\n",
      "悩み: 5\n",
      "そう: 5\n",
      "4: 5\n",
      "機器: 5\n",
      "今回: 5\n",
      "iPhone: 5\n",
      "活用: 5\n",
      "日本語: 5\n",
      "10: 4\n",
      "イベント: 4\n",
      "期間: 4\n",
      "円: 4\n",
      "三: 4\n",
      "一郎: 4\n",
      "支援: 4\n",
      "離婚: 4\n",
      "ネット: 4\n",
      "掲示板: 4\n",
      "内容: 4\n",
      "声: 4\n",
      "関連: 4\n",
      "12: 4\n",
      "世界: 4\n",
      "缶詰: 4\n",
      "美容: 4\n",
      "家電: 4\n",
      "Panasonic: 4\n",
      "Beauty: 4\n",
      "キレイ: 4\n",
      "キャンペーン: 4\n",
      "ラム: 4\n",
      "ダッシュ: 4\n",
      "人気: 4\n",
      "現在: 4\n",
      "活躍: 4\n",
      "環境: 4\n",
      "提供: 4\n",
      "フラワー: 4\n",
      "夏: 4\n",
      "さ: 4\n",
      "digi: 4\n",
      "アクセント: 4\n",
      "ウィーク: 3\n",
      "特別: 3\n",
      "7: 3\n",
      "31: 3\n",
      "別: 3\n",
      "服部: 3\n",
      "田村: 3\n",
      "たち: 3\n",
      "参加: 3\n",
      "代表: 3\n",
      "サイト: 3\n",
      "週刊文春: 3\n",
      "手紙: 3\n",
      "夫人: 3\n",
      "本日: 3\n",
      "週刊: 3\n",
      "アサヒ: 3\n",
      "関係: 3\n",
      "紹介: 3\n",
      "コメント: 3\n",
      "確か: 3\n",
      "昨年: 3\n",
      "時: 3\n",
      "高校: 3\n",
      "女子: 3\n",
      "生徒: 3\n",
      "年間: 3\n",
      "勝負: 3\n",
      "発表: 3\n",
      "大人: 3\n",
      "男性: 3\n",
      "ケア: 3\n",
      "前: 3\n",
      "使用: 3\n",
      "%: 3\n",
      "以上: 3\n",
      "名: 3\n",
      "アイテム: 3\n",
      "結果: 3\n",
      "ドラマ: 3\n",
      "子: 3\n",
      "セクハラ: 3\n",
      "不倫: 3\n",
      "横行: 3\n",
      "辛口: 3\n",
      "仕事: 3\n",
      "入社: 3\n",
      "目: 3\n",
      "今: 3\n",
      "恋愛: 3\n",
      "状態: 3\n",
      "求人: 3\n",
      "特集: 3\n",
      "スタイル: 3\n",
      "6: 3\n",
      "S: 3\n",
      "ボーダー: 3\n",
      "多く: 3\n",
      "着用: 3\n",
      "07: 3\n",
      "度: 3\n",
      "ライフスタイル: 3\n",
      "カテゴリ: 3\n",
      "どれ: 3\n",
      "ゲリラ: 3\n",
      "豪雨: 3\n",
      "独学: 3\n",
      "フレーズ: 3\n",
      "気軽: 2\n",
      "20: 2\n",
      "食: 2\n",
      "協賛: 2\n",
      "8: 2\n",
      "店舗: 2\n",
      "メニュー: 2\n",
      "税: 2\n",
      "サ: 2\n",
      "実行: 2\n",
      "委員: 2\n",
      "長: 2\n",
      "学校: 2\n",
      "法人: 2\n",
      "シェフ: 2\n",
      "ぢ: 2\n",
      "料理: 2\n",
      "金: 2\n",
      "19: 2\n",
      "誰: 2\n",
      "チェック: 2\n",
      "予約: 2\n",
      "方法: 2\n",
      "ジャパン: 2\n",
      "チャンス: 2\n",
      "空間: 2\n",
      "いかが: 2\n",
      "13: 2\n",
      "25: 2\n",
      "妻: 2\n",
      "ツイッター: 2\n",
      "秘書: 2\n",
      "一緒: 2\n",
      "和子: 2\n",
      "これ: 2\n",
      "?」: 2\n",
      "アプローチ: 2\n",
      "エース: 2\n",
      "同誌: 2\n",
      "デスク: 2\n",
      "周囲: 2\n",
      "話: 2\n",
      "春: 2\n",
      "仲: 2\n",
      "相談: 2\n",
      "わけ: 2\n",
      "時代: 2\n",
      "入り: 2\n",
      "後: 2\n",
      "タイプ: 2\n",
      "姉さん: 2\n",
      "ほう: 2\n",
      "03: 2\n",
      "正気: 2\n",
      "人殺し: 2\n",
      "製造: 2\n",
      "水産: 2\n",
      "加工: 2\n",
      "発展: 2\n",
      "非難: 2\n",
      "MSN: 2\n",
      "産経: 2\n",
      "ニュース: 2\n",
      "懸念: 2\n",
      "動き: 2\n",
      "解決: 2\n",
      "解消: 2\n",
      "応援: 2\n",
      "注目: 2\n",
      "(: 2\n",
      "): 2\n",
      "由紀恵: 2\n",
      "和也: 2\n",
      "魅力: 2\n",
      "何: 2\n",
      "イメージ: 2\n",
      "キャラクター: 2\n",
      "ナノ: 2\n",
      "商品: 2\n",
      "最近: 2\n",
      "大切: 2\n",
      "まま: 2\n",
      "回答: 2\n",
      "全体: 2\n",
      "自分: 2\n",
      "プロデュース: 2\n",
      "オリジナルデコ: 2\n",
      "撮影: 2\n",
      "表情: 2\n",
      "他: 2\n",
      "聖: 2\n",
      "2011: 2\n",
      "説教: 2\n",
      "評価: 2\n",
      "不動産: 2\n",
      "営業: 2\n",
      "積極: 2\n",
      "採用: 2\n",
      "上司: 2\n",
      "社内: 2\n",
      "３: 2\n",
      "プア: 2\n",
      "理由: 2\n",
      "せい: 2\n",
      "type: 2\n",
      "jp: 2\n",
      "プリント: 2\n",
      "マリン: 2\n",
      "好き: 2\n",
      "開催: 2\n",
      "ガールズコレクション: 2\n",
      "TGC: 2\n",
      "オールインワン: 2\n",
      "リアル: 2\n",
      "ワンピース: 2\n",
      "両方: 2\n",
      "コーディネート: 2\n",
      "17: 2\n",
      "型: 2\n",
      "生活: 2\n",
      "週間: 2\n",
      "ランキング: 2\n",
      "27: 2\n",
      "分: 2\n",
      "私: 2\n",
      "彼ら: 2\n",
      "ふたり: 2\n",
      "とんでも: 2\n",
      "ごはん: 2\n",
      "毎日: 2\n",
      "方: 2\n",
      "習慣: 2\n",
      "母性: 2\n",
      "本能: 2\n",
      "特徴: 2\n",
      "スマ: 2\n",
      "ホ: 2\n",
      "スマート: 2\n",
      "フォン: 2\n",
      "略: 2\n",
      "執筆: 2\n",
      "陣: 2\n",
      "読書: 2\n",
      "オススメ: 2\n",
      "iPad: 2\n",
      "自体: 2\n",
      "日常: 2\n",
      "価値: 2\n",
      "利用: 2\n",
      "化: 2\n",
      "ここ: 2\n",
      "画面: 2\n",
      "表示: 2\n",
      "精度: 2\n",
      "設定: 2\n",
      "例: 2\n",
      "電子: 2\n",
      "書籍: 2\n",
      "Amazon: 2\n",
      "キヤノン: 2\n",
      "4931238: 1\n",
      "NY: 1\n",
      "名物: 1\n",
      "名店: 1\n",
      "グルメ: 1\n",
      "ニューヨーク: 1\n",
      "祭典: 1\n",
      "ダイナーズクラブ: 1\n",
      "もと: 1\n",
      "スタート: 1\n",
      "青山: 1\n",
      "六本木: 1\n",
      "丸の内: 1\n",
      "銀座: 1\n",
      "横浜: 1\n",
      "エリア: 1\n",
      "ラグジュアリーレストラン: 1\n",
      "81: 1\n",
      "用意: 1\n",
      "ランチ: 1\n",
      "ディナー: 1\n",
      "5000: 1\n",
      "学園: 1\n",
      "栄養: 1\n",
      "専門: 1\n",
      "理事: 1\n",
      "校長: 1\n",
      "医学: 1\n",
      "博士: 1\n",
      "幸: 1\n",
      "應氏: 1\n",
      "石田: 1\n",
      "純一: 1\n",
      "LA: 1\n",
      "BETTOLA: 1\n",
      "オーナー: 1\n",
      "落合: 1\n",
      "務: 1\n",
      "フード: 1\n",
      "アナリスト: 1\n",
      "協会: 1\n",
      "会長: 1\n",
      "高賀: 1\n",
      "右近: 1\n",
      "代目: 1\n",
      "隆: 1\n",
      "放送: 1\n",
      "作家: 1\n",
      "脚本: 1\n",
      "家: 1\n",
      "小山: 1\n",
      "薫: 1\n",
      "堂: 1\n",
      "スペシャリスト: 1\n",
      "勢揃い: 1\n",
      "ミシュラン: 1\n",
      "フランス: 1\n",
      "とも: 1\n",
      "星: 1\n",
      "獲得: 1\n",
      "吉野: 1\n",
      "建: 1\n",
      "タテル: 1\n",
      "ヨシノ: 1\n",
      "汐留: 1\n",
      "名門: 1\n",
      "庵: 1\n",
      "赤坂: 1\n",
      "璃宮: 1\n",
      "mikuni: 1\n",
      "MARUNOUCHI: 1\n",
      "ダイナーズクラブカード: 1\n",
      "会員: 1\n",
      "シティバンク: 1\n",
      "口座: 1\n",
      "シティゴールドメンバー: 1\n",
      "先行: 1\n",
      "その後: 1\n",
      "日程: 1\n",
      "必須: 1\n",
      "事前: 1\n",
      "問合せ: 1\n",
      "OK: 1\n",
      "リーズナブル: 1\n",
      "極上: 1\n",
      "味: 1\n",
      "ラグジュアリー: 1\n",
      "満喫: 1\n",
      "幸せ: 1\n",
      "実感: 1\n",
      "JAPAN: 1\n",
      "RESTAURANT: 1\n",
      "WEEK: 1\n",
      "公式: 1\n",
      "6655079: 1\n",
      "06: 1\n",
      "報告: 1\n",
      "Web: 1\n",
      "民主党: 1\n",
      "宛: 1\n",
      "話題: 1\n",
      "放射能: 1\n",
      "隠し子: 1\n",
      "発覚: 1\n",
      "際: 1\n",
      "いつ: 1\n",
      "一時: 1\n",
      "自殺: 1\n",
      "支持: 1\n",
      "ショッキング: 1\n",
      "本性: 1\n",
      "その他: 1\n",
      "潰し: 1\n",
      "?」「: 1\n",
      "交番: 1\n",
      "逮捕: 1\n",
      "件: 1\n",
      "何者: 1\n",
      "工作: 1\n",
      "活動: 1\n",
      "5172424: 1\n",
      "Sports: 1\n",
      "Watch: 1\n",
      "グラビア: 1\n",
      "アイドル: 1\n",
      "あき: 1\n",
      "騎手: 1\n",
      "三浦: 1\n",
      "皇: 1\n",
      "成: 1\n",
      "お互い: 1\n",
      "ブログ: 1\n",
      "東北: 1\n",
      "楽天: 1\n",
      "ゴールデンイーグルス: 1\n",
      "将: 1\n",
      "大: 1\n",
      "タレント: 1\n",
      "公: 1\n",
      "火: 1\n",
      "発売: 1\n",
      "9: 1\n",
      "号: 1\n",
      "マー: 1\n",
      "君: 1\n",
      "ナンパ: 1\n",
      "見出し: 1\n",
      "両者: 1\n",
      "証言: 1\n",
      "事情: 1\n",
      "当人: 1\n",
      "結婚: 1\n",
      "完全: 1\n",
      "視野: 1\n",
      "新居: 1\n",
      "二: 1\n",
      "出: 1\n",
      "末: 1\n",
      "番組: 1\n",
      "共演: 1\n",
      "アタック: 1\n",
      "食事: 1\n",
      "頃: 1\n",
      "スザンヌ: 1\n",
      "24: 1\n",
      "木下: 1\n",
      "優樹: 1\n",
      "菜: 1\n",
      "22: 1\n",
      "次世代: 1\n",
      "ゲット: 1\n",
      "賞味: 1\n",
      "期限切れ: 1\n",
      "間近: 1\n",
      "球団: 1\n",
      "在学: 1\n",
      "基本: 1\n",
      "オクテ: 1\n",
      "プロ: 1\n",
      "キャバクラ: 1\n",
      "モテ: 1\n",
      "あしらい: 1\n",
      "不慣れ: 1\n",
      "ワガママ: 1\n",
      "カノ: 1\n",
      "苦労: 1\n",
      "同年代: 1\n",
      "ケース: 1\n",
      "吉: 1\n",
      "ライト: 1\n",
      "PC: 1\n",
      "モバイル: 1\n",
      "6419378: 1\n",
      "14: 1\n",
      "46: 1\n",
      "!!」: 1\n",
      "殺到: 1\n",
      "東日本: 1\n",
      "大震災: 1\n",
      "イワシ: 1\n",
      "サバ: 1\n",
      "カンボジア: 1\n",
      "人々: 1\n",
      "国連: 1\n",
      "機関: 1\n",
      "食糧: 1\n",
      "計画: 1\n",
      "WFP: 1\n",
      "開発: 1\n",
      "援助: 1\n",
      "ODA: 1\n",
      "書簡: 1\n",
      "交換: 1\n",
      "外務省: 1\n",
      "幹部: 1\n",
      "安全: 1\n",
      "性: 1\n",
      "問題: 1\n",
      "輸出: 1\n",
      "海外: 1\n",
      "打破: 1\n",
      "一部: 1\n",
      "市民: 1\n",
      "団体: 1\n",
      "原発: 1\n",
      "事故: 1\n",
      "影響: 1\n",
      "反発: 1\n",
      "信頼: 1\n",
      "餓死: 1\n",
      "寸前: 1\n",
      "子供: 1\n",
      "セシウム: 1\n",
      "強制: 1\n",
      "みたい: 1\n",
      "拡大: 1\n",
      "今後: 1\n",
      "食料: 1\n",
      "！(: 1\n",
      "Blog: 1\n",
      "5113373: 1\n",
      "02: 1\n",
      "18: 1\n",
      "絶賛: 1\n",
      "各地: 1\n",
      "イルミネーション: 1\n",
      "点灯: 1\n",
      "グ: 1\n",
      "シーズン: 1\n",
      "目星: 1\n",
      "毎年: 1\n",
      "アクセサリー: 1\n",
      "バッグ: 1\n",
      "マンネリ: 1\n",
      "今年: 1\n",
      "ザ・ペニンシュラ: 1\n",
      "会: 1\n",
      "登場: 1\n",
      "シリーズ: 1\n",
      "CM: 1\n",
      "馴染み: 1\n",
      "プライベート: 1\n",
      "愛用: 1\n",
      "黒髪: 1\n",
      "秘訣: 1\n",
      "ヘアードライヤー: 1\n",
      "友達: 1\n",
      "様: 1\n",
      "増加: 1\n",
      "夜: 1\n",
      "肌: 1\n",
      "ナイトスチーマー: 1\n",
      "28: 1\n",
      "事: 1\n",
      "パナソニック: 1\n",
      "100: 1\n",
      "定番: 1\n",
      "以外: 1\n",
      "調査: 1\n",
      "エステ: 1\n",
      "36: 1\n",
      "ダントツ: 1\n",
      "実用: 1\n",
      "為: 1\n",
      "ゴコロ: 1\n",
      "202: 1\n",
      "素敵: 1\n",
      "スチーマー: 1\n",
      "レアアイテム: 1\n",
      "デコデザイン: 1\n",
      "豪華: 1\n",
      "格好: 1\n",
      "デザイン: 1\n",
      "初対面: 1\n",
      "演技: 1\n",
      "経験: 1\n",
      "うち: 1\n",
      "先生: 1\n",
      "ヤン: 1\n",
      "クミ: 1\n",
      "一瞬: 1\n",
      "きれい: 1\n",
      "キュート: 1\n",
      "一: 1\n",
      "面: 1\n",
      "役: 1\n",
      "皆: 1\n",
      "マジ: 1\n",
      "カワイイ: 1\n",
      "当時: 1\n",
      "思い出: 1\n",
      "相手: 1\n",
      "近く: 1\n",
      "愛情: 1\n",
      "司会: 1\n",
      "KAT: 1\n",
      "TUN: 1\n",
      "メンバー: 1\n",
      "笑: 1\n",
      "会場: 1\n",
      "笑い: 1\n",
      "オープン: 1\n",
      "特設: 1\n",
      "詳細: 1\n",
      "彼女: 1\n",
      "グリーティング: 1\n",
      "LOVE: 1\n",
      "メッセージ: 1\n",
      "付き: 1\n",
      "5769371: 1\n",
      "部屋: 1\n",
      "vol: 1\n",
      "43: 1\n",
      "将来: 1\n",
      "若手: 1\n",
      "社会: 1\n",
      "様々: 1\n",
      "姉妹: 1\n",
      "お答え: 1\n",
      "Q: 1\n",
      "業: 1\n",
      "歳: 1\n",
      "<: 1\n",
      "No: 1\n",
      "043: 1\n",
      ">: 1\n",
      "男女: 1\n",
      "分け: 1\n",
      "びっくり: 1\n",
      "対象: 1\n",
      "始末: 1\n",
      "市場: 1\n",
      "我慢: 1\n",
      "若者: 1\n",
      "烙印: 1\n",
      "アドバイス: 1\n",
      "A: 1\n",
      "年収: 1\n",
      "200: 1\n",
      "万: 1\n",
      "台: 1\n",
      "昨日: 1\n",
      "奮発: 1\n",
      "マック: 1\n",
      "セット: 1\n",
      "ひとつ: 1\n",
      "書類: 1\n",
      "選考: 1\n",
      "ハンデ: 1\n",
      "有利: 1\n",
      "職場: 1\n",
      "どこ: 1\n",
      "成果: 1\n",
      "正当: 1\n",
      "気概: 1\n",
      "：@: 1\n",
      "瞬時: 1\n",
      "判断: 1\n",
      "おすすめ: 1\n",
      "コンテンツ: 1\n",
      "心機一転: 1\n",
      "新た: 1\n",
      "企業: 1\n",
      "耳寄り: 1\n",
      "s: 1\n",
      "4646466: 1\n",
      "21: 1\n",
      "vs: 1\n",
      "どっち: 1\n",
      "気: 1\n",
      "ファッション: 1\n",
      "トレンド: 1\n",
      "': 1\n",
      "以下: 1\n",
      "ロンパース: 1\n",
      "リラックス: 1\n",
      "モード: 1\n",
      "つなぎ: 1\n",
      "多用: 1\n",
      "クローズ: 1\n",
      "アピール: 1\n",
      "目的: 1\n",
      "国内: 1\n",
      "最大: 1\n",
      "級: 1\n",
      "ファッションフェスタ: 1\n",
      "記念: 1\n",
      "回: 1\n",
      "国内外: 1\n",
      "香里奈: 1\n",
      "CECIL: 1\n",
      "McBEE: 1\n",
      "柄: 1\n",
      "ゴールド: 1\n",
      "ビッグ: 1\n",
      "ブレスレット: 1\n",
      "演出: 1\n",
      "ポイント: 1\n",
      "峰: 1\n",
      "えりか: 1\n",
      "マキシ: 1\n",
      "丈: 1\n",
      "タウン: 1\n",
      "ユース: 1\n",
      "リゾート: 1\n",
      "使い: 1\n",
      "クリスティーナ: 1\n",
      "ラブリー: 1\n",
      "Sons: 1\n",
      "de: 1\n",
      "mode: 1\n",
      "デート: 1\n",
      "藤井: 1\n",
      "リナ: 1\n",
      "カットソー: 1\n",
      "ショート: 1\n",
      "パンツ: 1\n",
      "流行: 1\n",
      "ボーイフレンド: 1\n",
      "デニム: 1\n",
      "ラフ: 1\n",
      "優秀: 1\n",
      "トリンドル: 1\n",
      "玲奈: 1\n",
      "スウィート: 1\n",
      "HAPPY: 1\n",
      "不変: 1\n",
      "モチーフ: 1\n",
      "ボトム: 1\n",
      "小物: 1\n",
      "変化: 1\n",
      "オン: 1\n",
      "オフ: 1\n",
      "着: 1\n",
      "ガール: 1\n",
      "好み: 1\n",
      "6732499: 1\n",
      "?／: 1\n",
      "人間: 1\n",
      "スムーズ: 1\n",
      "ヒント: 1\n",
      "ライフハック: 1\n",
      "節約: 1\n",
      "ネタ: 1\n",
      "Peachy: 1\n",
      "なか: 1\n",
      "間: 1\n",
      "TOP: 1\n",
      "洗顔: 1\n",
      "!?: 1\n",
      "365: 1\n",
      "ドロドロ: 1\n",
      "うた: 1\n",
      "素朴: 1\n",
      "疑問: 1\n",
      "モデル: 1\n",
      "形: 1\n",
      "オランダ: 1\n",
      "アーティスト: 1\n",
      "Lernert: 1\n",
      "&: 1\n",
      "Sander: 1\n",
      "表現: 1\n",
      "自然: 1\n",
      "塗り: 1\n",
      "はず: 1\n",
      "診断: 1\n",
      "恋: 1\n",
      "理不尽: 1\n",
      "どん底: 1\n",
      "気分: 1\n",
      "とき: 1\n",
      "回復: 1\n",
      "カウンセラー: 1\n",
      "ゆ: 1\n",
      "監修: 1\n",
      "究極: 1\n",
      "科学: 1\n",
      "心理: 1\n",
      "テスト: 1\n",
      "公開: 1\n",
      "レパートリー: 1\n",
      "ママ: 1\n",
      "必見: 1\n",
      "カンタン: 1\n",
      "時間: 1\n",
      "ひとり: 1\n",
      "適当: 1\n",
      "パン: 1\n",
      "おにぎり: 1\n",
      "コンビニ: 1\n",
      "購入: 1\n",
      "ダイエット: 1\n",
      "朝食: 1\n",
      "家庭: 1\n",
      "挨拶: 1\n",
      "気品: 1\n",
      "シャキ: 1\n",
      "周り: 1\n",
      "実践: 1\n",
      "ダメ: 1\n",
      "使命: 1\n",
      "感: 1\n",
      "先週: 1\n",
      "5779877: 1\n",
      "連日: 1\n",
      "都心: 1\n",
      "無防備: 1\n",
      "携帯: 1\n",
      "電話: 1\n",
      "割: 1\n",
      "アメッシュ: 1\n",
      "大島: 1\n",
      "克彦: 1\n",
      "katsuosh: 1\n",
      "熱中: 1\n",
      "症: 1\n",
      "はんだづけ: 1\n",
      "不用: 1\n",
      "3500: 1\n",
      "線量: 1\n",
      "自作: 1\n",
      "キット: 1\n",
      "ガイガーカウンター: 1\n",
      "洋書: 1\n",
      "Kindle: 1\n",
      "真夏: 1\n",
      "ホラー: 1\n",
      "映画: 1\n",
      "BEST: 1\n",
      "夏休み: 1\n",
      "感想: 1\n",
      "文: 1\n",
      "スマホ: 1\n",
      "6798260: 1\n",
      "アップル: 1\n",
      "バーチャル: 1\n",
      "アシスタント: 1\n",
      "LT: 1\n",
      "Box: 1\n",
      "対応: 1\n",
      "ユニバーサルアプリ: 1\n",
      "以前: 1\n",
      "実生活: 1\n",
      "アップデート: 1\n",
      "バージョン: 1\n",
      "追加: 1\n",
      "TOEIC: 1\n",
      "主: 1\n",
      "リスニング: 1\n",
      "それ: 1\n",
      "単語: 1\n",
      "文法: 1\n",
      "本格: 1\n",
      "現実: 1\n",
      "会話: 1\n",
      "クイズ: 1\n",
      "内: 1\n",
      "意味: 1\n",
      "非常: 1\n",
      "点: 1\n",
      "アメリカ: 1\n",
      "イギリス: 1\n",
      "オーストラリア: 1\n",
      "地域: 1\n",
      "機械: 1\n",
      "ネイティブ: 1\n",
      "コツ: 1\n",
      "タップ: 1\n",
      "再生: 1\n",
      "英文: 1\n",
      "筆者: 1\n",
      "まね: 1\n",
      "日本人: 1\n",
      "もってこい: 1\n",
      "上倉: 1\n",
      "賢: 1\n",
      "@: 1\n",
      "kamikura: 1\n",
      "[: 1\n",
      ")]: 1\n",
      "客観: 1\n",
      "サービス: 1\n",
      "終了: 1\n",
      "永遠: 1\n",
      "キン: 1\n",
      "ドル: 1\n",
      "参入: 1\n",
      "さらい: 1\n",
      "据え置き: 1\n",
      "ゲーム: 1\n",
      "機: 1\n",
      "純正: 1\n",
      "インク: 1\n",
      "キャノンインクタンク: 1\n",
      "色: 1\n",
      "マルチ: 1\n",
      "パック: 1\n",
      "BCI: 1\n",
      "321: 1\n",
      "320: 1\n",
      "MP: 1\n",
      "販売元: 1\n",
      "co: 1\n",
      "クチコミ: 1\n"
     ]
    }
   ],
   "source": [
    "token_count = [POSKeepFilter('名詞,一般'), TokenCountFilter(sorted=True)]\n",
    "a = Analyzer(token_filters=token_count)\n",
    "for k,v in a.analyze(''.join(documents[0:10])):\n",
    "    print('%s: %d'%(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### テキストをクリーニングする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:16.897454Z",
     "start_time": "2019-06-25T08:02:16.874790Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2010-08-08T10:00:00+0900NY名物イベントが日本でも！名店グルメを気軽に楽しむニューヨークで20年続いている食の祭典「レストラン・ウィーク」。その日本版がダイナーズクラブ特別協賛のもと7月30日よりスタート。8月31日までの期間中、青山・六本木、丸の内、銀座、横浜のエリアから、ラグジュアリーレストラン81店舗がこのイベントのために特別用意したランチメニュー2010円（税・サ別）、ディナー5000円（税・サ別）を気軽に楽しめる、とっておきのイベントです。\\u3000\\u3000実行委員長には、学校法人服部学園、服部栄養専門学校理事長・校長であり医学博士でもある服部幸應氏を迎え、実行委員に石田純一さん、LABETTOLAオーナーシェフ落合務氏、フードアナリスト協会会長、高賀右近氏、つきぢ田村三代目、田村隆氏に、そして放送作家・脚本家の小山薫堂さんなど、食のスペシャリストたちが勢揃い。参加レストランには、ミシュランのフランス版、東京版ともに星を獲得している吉野建シェフの「レストランタテルヨシノ汐留」や、日本料理の名門「つきぢ田村」、「金田中庵」、「赤坂璃宮」に「mikuniMARUNOUCHI」など、日本を代表するレストランがずらり。\\u3000イベント期間の〜8月19日までは、特別協賛のダイナーズクラブカード会員、またはシティバンクに口座を持つシティゴールドメンバーが楽しめる先行期間となりますが、その後は誰でも参加できるので、日程のチェックは必須。\\u3000予約方法は必ず事前に、各店舗に問合せを行い「ジャパンレストラン・ウィーク2010」での予約であることを伝えればOK！憧れていたレストランの料理をリーズナブルにいただけるチャンスです！極上の味とラグジュアリーな空間を満喫。そんな幸せを実感できる「ジャパンレストラン・ウィーク2010」にぜひ参加しててみてはいかがですか？JAPANRESTAURANTWEEK2010-公式サイト', '2012-06-13T19:25:00+0900小沢一郎氏の妻が支援者に離婚を報告。「週刊文春」報じる13日、Web版「週刊文春」は、民主党の元代表・小沢一郎氏の妻が、支援者宛に離婚したことを伝える手紙を送ったと報じ、ツイッターやネット掲示板で大きな話題になっている。記事によると、その手紙は「小沢は放射能が怖くて秘書と一緒に逃げだしました」「隠し子が発覚した際、小沢元代表は和子夫人に謝るどころか、『いつでも離婚してやる』と言い放ち、和子夫人は一時は自殺まで考えた」という小沢氏の支持者にとってはショッキングな内容となっている。ツイッターやネット掲示板では、「これが小沢一郎の本性か」「こりゃすごいな。てか、がっかりだなあ」などと、手紙の内容に驚く声が相次ぎ、その他にも「小沢潰しですかね?」「元秘書が交番で暴れて逮捕された件といい、小沢氏を潰したい何者かによる工作活動では?」といった声が挙がっていた。【関連情報】・小沢一郎夫人が支援者に「離婚しました」（週刊文春）', '2010-11-30T08:00:00+0900【SportsWatch】田中＆里田の交際、アプローチは里田からグラビアアイドル・ほしのあき＆騎手・三浦皇成がお互いのブログで交際を認めた日、東北楽天ゴールデンイーグルスのエース・田中将大とタレント・里田まいの交際もまた公のものとなったが、本日30日（火）発売の「週刊アサヒ芸能」（12.9号）では、「マー君を“ナンパ”した里田」との見出しで、両者の交際にまつわる関係者の証言を紹介した。同誌にコメントを寄せた芸能デスクによると、「周囲の事情はさておき、当人たちが盛り上がっているのは確か。結婚も完全に視野に入れているようで、すでに新居を探しているとの話まである」という。また、二人の交際は里田からのアプローチによるものとのことで、前出の芸能デスクは、「2人は昨年末の番組共演時に、里田から猛アタック。『一緒に食事でも』と誘い、春頃にはつきあい始めた。里田は仲のいいスザンヌ（24）、木下優樹菜（22）には、早くから相談していたし、周囲にも浮かれてしゃべりまくっていた。次世代エースをゲットしたわけですから、賞味期限切れ間近の里田にすれば、してやったりでしょう」とも語っている。ちなみに、同じく同誌にコメントする球団関係者は、「高校時代は同じ高校の女子生徒と在学中の3年間、ずっとつきあっていましたね。基本はオクテ。プロ入り後にキャバクラなども覚えましたが、まぁ、モテるタイプではないし、女あしらいも不慣れ。高校時代はかなりワガママで、元カノは苦労が絶えなかったと聞いています。同年代の女より、里田のような姉さんタイプのほうが勝負の世界では向いているケースも多いですからね」と明かしており、この交際も田中にとっては“吉”とした。・週刊アサヒ芸能［ライト版］＜デジタル＞（PC版）・週刊アサヒ芸能（モバイル版）', '2012-03-30T14:46:00+0900被災地の缶詰を途上国に…「正気じゃない。人殺しだ!!」30日、政府が被災地で製造された水産加工品を発展途上国へ送ると発表したが、その内容があまりにも酷いとネット掲示板で非難が殺到している。MSN産経ニュースの記事によると、東日本大震災の被災地で製造されたイワシやサバの水産加工品を、カンボジアなどの発展途上国の人々に食べてもらうため、政府は国連機関の世界食糧計画（WFP）と政府開発援助（ODA）に関する書簡を交換したことを発表。外務省の幹部は「安全性に問題がないものを輸出することで、海外に根強い風評被害の打破を図りたい」と述べているが、一部の市民団体は原発事故の影響を懸念して反発しているという。この動きに対してネット掲示板では「風評被害の解決を途上国を使って解消とか、正気とは思えない。人殺しだろ」「こんなことしたら日本の信頼を損ねるだろうが」「餓死寸前の子供にセシウム入りの缶詰食わせるなんて…」「食べさせて応援ってなんか強制みたいだな」と政府を非難する声が相次いだ。また、「こんなことをしたら風評被害がより拡大するのでは?」と懸念する声もあがっており、今後の政府の動きに注目が集まっている。【関連情報】・食料支援で風評被害解消\\u3000被災地の缶詰を途上国に(MSN産経ニュース)【関連情報】・【食べさせて応援】被災地の缶詰を途上国に送りつけて風評被害を解決！(livedoorBlog)', '2010-11-02T18:20:00+0900仲間由紀恵さん、“生徒”亀梨和也さんを「大人の魅力が出てきた」と絶賛\\u300011月に入り各地のイルミネーションが点灯されると、グっと高まるクリスマス・シーズン。女子の皆さんは彼へのプレゼント、そして彼におねだりするプレゼントの目星はついていますか？\\u3000「男性って何を貰ったら嬉しいんだろう？」「毎年アクセサリーやバッグじゃマンネリ…」とお悩みの皆さん。今年は“美容家電”のプレゼントはいかがでしょうか。\\u30002日、ザ・ペニンシュラ東京にてPanasonicBeauty「キレイを贈るクリスマス」キャンペーンの発表会が行われ、イメージキャラクターの仲間由紀恵さんと亀梨和也さんが登場しました。仲間さんは「ナノケア」シリーズ、亀梨さんは、「ラムダッシュ」のCMでお馴染みですが、2人もプライベートで商品を愛用しているそうです。\\u3000特に、仲間さんは美しい黒髪の秘訣である「ナノケアヘアードライヤー」をお友達にプレゼントしたことがあるそうです。実は、最近仲間さんの様に“美容家電”を大切な人にプレゼントする人が増加中。夜寝たままお肌のケアを行える人気の「ナイトスチーマー」を「プレゼントされた」と回答した人は、3年前には使用者全体の12%でしたが、現在は28%と、4人に1人以上がプレゼントされている事が分かっています。\\u3000パナソニックが女性約100名に「定番以外でプレゼントして欲しいものは？」と聞いた調査では、「美容家電・エステ機器」を回答した人が36%とダントツの1位。実用的でありながら、自分を美しくしてくれるアイテムに人気が集まる結果となりました。彼にもらったプレゼントで、彼の為にもっと美しくなりたい！\\u3000そんな女ゴコロがこめられているのかもしれませんね。\\u3000PanasonicBeauty「キレイを贈るクリスマス」キャンペーンでは、本日2日から2010年12月31日（金）までの期間中、202名に素敵なプレゼントが当たるチャンスが。中でも、仲間さんがプロデュースした「オリジナルデコラムダッシュ」、亀梨さんがプロデュースした「オリジナルデコスチーマー」は世界に1つしかない、超レアアイテムです。\\u3000亀梨さんをイメージして、「ラムダッシュ」のデコデザインをしたという仲間さんは「大人の魅力が出てきた亀梨さんにピッタリな、豪華で格好良いデザインにしました。5年前、初対面だったドラマの撮影では“演技の経験があまり無いんです”と初々しい表情を見せていた子が、みるみるうちに大きくなり、先生は嬉しいです！」と、ドラマ「ごくせん」のキャラクター“ヤンクミ”の表情を一瞬のぞかせました。\\u3000一方の亀梨さんは仲間さんについて「きれいなお姉さんだけど、キュートな一面もあって、ドラマの撮影時には生徒役の皆で“マジでカワイイよね”って話していました」と当時の思い出話を語りながらも、「美容家電のプレゼントって、他のプレゼントよりも相手と近くなれるというか、愛情を感じます」とコメント。司会者から「亀梨さんはこのラムダッシュを誰に贈りたいですか？」と尋ねられると「聖（KAT-TUNのメンバー田中聖）が、新しいの欲しがってるんですよ。でも、贈るかどうかは考えます（笑）」と会場の笑いを誘っていました。\\u3000本日からオープンしたPanasonicBeauty「キレイを贈るクリスマス」特設サイトでは、プレゼントキャンペーンの詳細の他、彼や彼女に欲しいアイテムを“おねだり”出来る「おねだりグリーティング」機能も。あなたも、LOVEメッセージ付きで、可愛く彼におねだりしちゃいましょう！・PanasonicBeauty「キレイを贈るクリスマス」-キャンペーンサイト', '2011-11-08T11:00:00+0900「セクハラや不倫が横行している会社です…」-辛口説教部屋vol.43「3年で転職は早すぎる？」「将来が見えない」「仕事が面白くない」・・・若手社会人の悩みは尽きないもの。そんな様々な悩みに辛口4姉妹がお答えします。今回のお悩みQ：セクハラや不倫が横行している会社です。こんな会社でも三年い続けないと評価してもらえないのでしょうか。不動産業・営業25歳\\u3000女性<悩める相談者No.043>現在入社2年目。法人営業をしています。女性を積極的に採用している会社ということで、男女分け隔てなく活躍できると思い今の会社に入社しました。しかし、入社してみたらびっくり。女性は上司のセクハラ対象だったのです。社内恋愛が多い会社とは聞いていて、仲の良い会社なんだな、と思っていましたが、社内不倫まで横行している始末・・・。仕事内容は楽しいのですが、こんな会社にこれ以上いるのは耐えられません。こんな会社でも３年間勤めないと転職市場では「我慢できない若者」の烙印を押されてしまうのでしょうか。プア子からの辛口アドバイスA：見られるのはあなたの活躍。どうも。年収200万円台のプア子です。昨日は奮発してマックでセットを買っちゃったの。お悩み見たわ。ひとつの会社に三年勤めないと書類選考でハンデを背負うのは確か。でも、ただ三年勤めれば有利なこともないのよ。大切なのは、何を考え、どんな結果を出してきたか。今の職場は確かにひどい環境だと思うけど、多かれ少なかれ、どこの会社にも似たような状態はあるもの。転職したい理由を環境のせいにせず、成果が正当に評価されない、くらいの気概がほしいわ。不動産って売れば売るほど稼げるんでしょ。うらやましいわよ。今回の説教環境のせいにせず、結果で勝負しなさい。（情報提供元：@type）livedoor求人・転職livedoor求人・転職は、あなたがどんな求人情報を探しているのかを瞬時に判断しておすすめするコンテンツ。「心機一転、新たな環境で活躍できる！積極採用を行っている企業特集」など、耳寄り転職情報を提供中です。', \"2010-03-08T21:00:00+0900フラワープリントvs.マリンスタイル\\u3000あなたはどっちがお好き？\\u30003月に入り、そろそろ気になるのが春夏のファッション・トレンド。6日に開催された「東京ガールズコレクション'10S/S（以下、TGC）」では、全体的にロンパース、オールインワンと呼ばれるリラックスモードの“つなぎスタイル”やフラワープリントが多く見られました。また、昨年から引き続きボーダーを多用したマリンスタイルも人気を集めているようです。\\u3000TGCは日本のリアルクローズを世界へ向けてアピールすることを目的に初開催された国内最大級のファッションフェスタ。今回で記念すべき10回目を迎え、国内外からさらに多くの注目を集めています。\\u3000香里奈さん着用のCECILMcBEEのフラワー柄オールインワンは、ゴールドのビッグブレスレットで大人っぽさを演出しているのがポイント。峰えりかさん着用のマキシ丈ワンピースはタウンユースもリゾート使いも両方出来そうですね。クリスティーナさんがラブリーに着こなした、31Sonsdemodeのワンピースは勝負デートの時に大活躍しちゃうかも。\\u3000藤井リナさん着用のボーダーのカットソーは、ショートパンツに合わせても、流行のボーイフレンドデニムとラフに着るのも可愛い優秀アイテム。トリンドル玲奈さんのスウィートなコーディネートは、着ているだけでHAPPYになれそうですね。\\u3000フラワーとボーダーという、不変的なモチーフだからこそ、ボトムや小物で変化をつけて、オン／オフ両方着回すのが賢いお仕事ガール。皆さんはどのコーディネートがお好みですか？・東京ガールズコレクション\", '2012-07-07T17:00:00+0900あなたの打たれ強さ度は?／イイ女を作る朝型生活など−【ライフスタイル】週間ランキング人間関係をスムーズにするヒントやライフハック、節約ネタなど、今すぐ役立つ情報が詰まったPeachyの「ライフスタイル」カテゴリ。このカテゴリのなかから、2012年6月27日〜7月4日の間に最も多く読まれた記事TOP5をご紹介します！第1位：1年間洗顔せずお化粧を続けるとこうなる!?365日分のお化粧を施したらドロドロになってしもうたよあなたはこんなことを考えたことがありますか？「私って、1年にどれくらい化粧品を使っているんだろう？」そんな素朴な疑問を、モデルを使って実際に目に見える形にしてしまった、2人のオランダ人アーティストがいました。彼らの名は、Lernert&Sander（ふたりとも男性です！）。ただしこのふたりが表現したかったことは、「人は1年に化粧品をどれくらい使うのか」ではなく、「どれくらい化粧品を使えば、人は自然な状態からとんでもない状態になるのか」ということ。彼らは「そうだ！\\u3000化粧品を1年分塗り重ねていけば、きっととんでもなくなるはずだ！」と、考えたわけです。第2位：あなたの「打たれ強さ度」を診断恋がうまくいかなかったり、理不尽なことで上司に怒られたり。生きていると凹むことっていっぱいありますよね。どん底気分のとき、あなたはすぐに回復できる人？\\u3000それともなかなか立ち直れないほう？\\u3000恋愛カウンセラー・ゆまさん監修の「究極の恋愛科学」では、あなたの「打たれ強さ度」をチェックできる心理テストを公開しています。第3位：レパートリーに悩むママ必見！夏のカンタン朝ごはんとは？あなたは毎日朝ごはんを食べていますか？\\u3000何かと慌しい朝。「時間がなくて毎日同じメニュー」なんて方も多いのではないでしょうか。ひとりだと適当にパンやおにぎりをコンビニで購入したり、ダイエットのために朝食を抜くこともあるかもしれませんが、家庭を持っているとそうはいきませんよね。第4位：いい女は朝を制す！朝型女子7の習慣「おはようございます」という挨拶からも気品が漂ってきそうな朝からシャキっと美しい女性、あなたの周りにいませんか？今回はそんな女性たちが実践しているであろう、いい女に欠かせない朝の習慣をまとめてみました。第5位：母性本能が強い女性6の特徴弱ってる男性を前に「この人は私がいないとダメだ、何とかしなきゃ！」とつい使命感に燃えてしまうことありませんか？今回はそんな母性本能が強い女性の特徴をまとめてみました。以上、先週の「ライフスタイル」カテゴリ週間ランキングでした！', '2011-08-12T10:00:00+0900スマホでゲリラ豪雨に備える【デジ通】暑い夏が戻り、同時に、連日のようにゲリラ豪雨が都心を襲っている。無防備なまま出くわすと、濡れるだけではない被害に遭う。スマートフォン（高機能携帯電話）を使って、少しでもゲリラ豪雨を避けよう。■昨年より３割も多い！東京アメッシュ大島克彦＠katsuosh［digi2（デジ通）］digi2は「デジタル通」の略です。現在のデジタル機器は使いこなしが難しくなっています。皆さんがデジタル機器の「通」に近づくための情報を、皆さんよりすこし通な執筆陣が提供します。■関連記事・スマホで熱中症を避ける【デジ通】・iPhoneに差すだけ、はんだづけ不用、3500円の空間線量計自作キット【ガイガーカウンター特集：商品紹介】・読書の夏！洋書好きにKindleがオススメな理由\\u3000【デジ通】・真夏のオススメ・ホラー映画BEST5\\u3000【デジ通】・【夏休み特集】読書感想文にスマホを活用する', '2012-07-27T17:00:00+0900音声認識で英語の発音練習しようSiriを使うiPhoneアプリReal英会話【デジ通】アップルのSiriは音声認識機能を持つバーチャルアシスタントだ。この音声認識機能を使用して、英会話の発音練習に活用している方もいると思われるが、英会話学習アプリでもこの機能を活用し始めている。その1つが、LTBoxの「Real英会話」だ。Real英会話はiPhoneやiPadなどに対応したユニバーサルアプリで、以前から実生活で使われるようなリアルな英会話の学習ができた人気のアプリだ。2012年5月に行われたアップデート（バージョン3.1）では、Siriによる音声認識を使った発音練習機能が追加されている。Real英会話自体は、TOEICなどの練習よりも、主に日常生活で使われているような英会話のリスニングなどを練習できるアプリで、それ自体にも価値があるが、発音認識機能がついたことでさらに価値を増している。単語や文法などは独学で学習できたとしても、発音練習を独学でやるのは難しい。最近利用が本格化してきた音声認識機能を活用すれば、独学での発音練習も現実的になってきた。■Siriの音声認識機能をそのまま利用する実際に試してみると、アプリで学習する日常会話をSiriによる音声認識機能を使ってそのまま学習できるようになっている。アプリのフレーズクイズ内に発音練習があり、ここで練習できる。発音練習画面では、日本語の意味と、英語が表示される。ここに表示される英語を発音し音声認識で正しく認識できれば、そのフレーズを学習したことになる。認識精度はSiriの音声認識機能をそのまま使用するため非常に高い。しかし、日本の多くの学習者は日本語アクセントの英語で発音することが多いため、認識という点ではかなり厳しいのではないかと思われる。Siriの音声認識機能は、英語でも、アメリカ、イギリス、オーストラリアの3つの地域別に設定できる。日本語アクセントの英語という設定はないので、Real英会話アプリで機械的に緩く認識するようなことはない。日本語アクセントの英語で認識させようと思っても、ネイティブが聞き間違えるように間違えて認識されてしまう。Real英会話での学習のコツとしては、発音例も画面をタップすればすぐに再生されるので、英文を読むのではなく、発音例をまねてそのまま発音することだ。筆者も日本語アクセントの英語がやっとだが、なかなか認識されないフレーズについては、なるべくそっくりにまねして発音することで何とか認識されることが多かった。発音がうまくない多くの日本人にとって、かなり厳しい認識精度だが、発音練習の1つとして活用するにはもってこいのアプリだろう。Real英会話上倉賢@kamikura[digi2(デジ通)]digi2は「デジタル通」の略です。現在のデジタル機器は使いこなしが難しくなっています。皆さんがデジタル機器の「通」に近づくための情報を、皆さんよりすこし通な執筆陣が提供します。■デジ通の記事をもっと見る・iPhone4Sの音声認識機能は使える新しいiPadでも使える音声認識・英語の音声認識で英会話練習自分の発音を客観的に知る方法・サービス終了後はどうなる！電子書籍は永遠に読めるのか\\t・キンドルが日本に参入する？Amazonの電子書籍をおさらい・iPhoneが据え置きゲーム機も殺す？多機能化するスマートフォン【キヤノン純正インク】キャノンインクタンク5色マルチパックBCI-321+320/5MPキヤノン販売元：Amazon.co.jpクチコミを見る']\n"
     ]
    }
   ],
   "source": [
    "# 正規表現一覧\n",
    "symbol_reg = r'[\\n*` ]+'  # 改行等の特殊文字を削除\n",
    "url_reg = r'(https?|ftp)(:\\/\\/[-_.!~*\\'()a-zA-Z0-9;\\/?:\\@&=+\\$,%#]+)'  # URL削除\n",
    "\n",
    "reg_str = f'{symbol_reg}|{url_reg}'\n",
    "reg_str = re.compile(reg_str)\n",
    "\n",
    "# re.sub(r'[\\n*！`]+', '', text)でもできます\n",
    "document_clean = []\n",
    "for i in range(10):\n",
    "    document_clean.append(re.sub(reg_str, '', ''.join(documents[i]))) \n",
    "\n",
    "print(document_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BoW + TFIDFでベクトル化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:18.538163Z",
     "start_time": "2019-06-25T08:02:16.916768Z"
    }
   },
   "outputs": [],
   "source": [
    "a = Analyzer(token_filters=[CompoundNounFilter(), POSKeepFilter(\"名詞,一般\")])\n",
    "\n",
    "docs = []\n",
    "for i in range(10):\n",
    "    docs.append(\" \".join([tok.surface for tok in a.analyze(document_clean[i])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:18.587038Z",
     "start_time": "2019-06-25T08:02:18.541012Z"
    }
   },
   "outputs": [],
   "source": [
    "#ベクトル化\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:18.615322Z",
     "start_time": "2019-06-25T08:02:18.592062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['レストラン' 'ウィーク2010' 'イベント' 'ジャパンレストラン' '参加' '気軽' 'サ別' '日本' '予約方法'\n",
      "  '服部幸應氏']]\n",
      "[['離婚' '手紙' '週刊文春' '秘書' '小沢' 'ツイッター' '支援者' '和子夫人' '小沢氏' 'ネット掲示板']]\n",
      "[['里田' '交際' '週刊アサヒ芸能' '周囲' '高校時代' '田中' '芸能デスク' 'アプローチ' '同誌' 'コメント']]\n",
      "[['途上国' '被災地' '風評被害' '政府' '缶詰' '製造' '発表' '懸念' 'msn産経ニュース' '非難']]\n",
      "[['プレゼント' '亀梨さん' '仲間さん' 'クリスマス' 'panasonicbeauty' 'キレイ' '美容家電' 'ドラマ'\n",
      "  'ラムダッシュ' '亀梨和也さん']]\n",
      "[['会社' '横行' '環境' '転職' '三年' '悩み' '活躍' '女性' '不倫' 'せい']]\n",
      "[['ボーダー' '東京ガールズコレクション' 'tgc' '開催' 'コーディネート' 'マリンスタイル' 'そう' 'トレンド'\n",
      "  'ショートパンツ' 'スウィート']]\n",
      "[['化粧品' 'あなた' 'こと' 'ライフスタイル' 'さ度' 'どれ' '特徴' 'とんでも' '化粧' '母性本能']]\n",
      "[['デジ通' 'ゲリラ豪雨' 'オススメ' 'スマホ' 'デジタル機器' 'digi2' '皆さん' '12t10' '関連記事' '空間線量']]\n",
      "[['英語' '音声認識機能' 'siri' '認識' '発音' '発音練習' '学習' 'アプリ' '音声認識' '日本語アクセント']]\n"
     ]
    }
   ],
   "source": [
    "# 各文書で重要な単語上位10語を表示する\n",
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "feature_words_list = np.empty([0,100])\n",
    "for vec in X:\n",
    "    index = np.argsort(vec.toarray(), axis=1)[:,::-1]\n",
    "    feature_words = feature_names[index]\n",
    "    print(feature_words[:,:10])\n",
    "    feature_words_list = np.vstack((feature_words_list, feature_words[0][:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T12:39:25.721958Z",
     "start_time": "2019-06-24T12:39:25.710480Z"
    }
   },
   "source": [
    "#### あるニュースに一番cos類似度が近いニュースを出力する関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:19.951895Z",
     "start_time": "2019-06-25T08:02:18.621240Z"
    }
   },
   "outputs": [],
   "source": [
    "docs2 = []\n",
    "for i in range(10):\n",
    "    docs2.append([tok.surface for tok in a.analyze(document_clean[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:20.012772Z",
     "start_time": "2019-06-25T08:02:19.975378Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_cos(dictA, dictB):\n",
    "    \"\"\"\n",
    "    cos類似度を計算する関数\n",
    "    @param dictA 1つ目の文章\n",
    "    @param dictB 2つ目の文章\n",
    "    @return cos類似度を計算した結果。0〜1で1に近ければ類似度が高い。\n",
    "    \"\"\"\n",
    "    # 文書Aのベクトル長を計算\n",
    "    lengthA = 0.0\n",
    "    for key,value in dictA.items():\n",
    "        lengthA = lengthA + value*value\n",
    "    lengthA = math.sqrt(lengthA)\n",
    "\n",
    "    # 文書Bのベクトル長を計算\n",
    "    lengthB = 0.0\n",
    "    for key,value in dictB.items():\n",
    "        lengthB = lengthB + value*value\n",
    "    lengthB = math.sqrt(lengthB)\n",
    "\n",
    "    # AとBの内積を計算\n",
    "    dotProduct = 0.0\n",
    "    for keyA,valueA in dictA.items():\n",
    "        for keyB,valueB in dictB.items():\n",
    "            if keyA==keyB:\n",
    "                dotProduct = dotProduct + valueA*valueB\n",
    "    # cos類似度を計算\n",
    "    cos = dotProduct / (lengthA*lengthB)\n",
    "    return cos\n",
    "\n",
    "\n",
    "def words_to_freqdict(words):\n",
    "    \"\"\"\n",
    "    単語の配列を、単語と頻度の辞書に変換する関数\n",
    "    例: [\"X\",\"X\",\"Y\",\"Z\",\"X\"] => {\"X\":3, \"Y\":1, \"Z\":1}\n",
    "    @param words 単語の配列\n",
    "    @return 単語と頻度の辞書\n",
    "    \"\"\"\n",
    "    freqdict = {}\n",
    "    for word in words:\n",
    "        if word in freqdict:\n",
    "            freqdict[word] = freqdict[word] + 1\n",
    "        else:\n",
    "            freqdict[word] = 1\n",
    "    return freqdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T02:05:40.017098Z",
     "start_time": "2019-06-25T02:05:40.011735Z"
    }
   },
   "source": [
    "- 文書0をその他の文書を比較する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:20.029011Z",
     "start_time": "2019-06-25T08:02:20.016660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2010-08-08T10:00:00+0900NY名物イベントが日本でも！名店グルメを気軽に楽しむニューヨークで20年続いている食の祭典「レストラン・ウィーク」。その日本版がダイナーズクラブ特別協賛のもと7月30日よりスタート。8月31日までの期間中、青山・六本木、丸の内、銀座、横浜のエリアから、ラグジュアリーレストラン81店舗がこのイベントのために特別用意したランチメニュー2010円（税・サ別）、ディナー5000円（税・サ別）を気軽に楽しめる、とっておきのイベントです。\\u3000\\u3000実行委員長には、学校法人服部学園、服部栄養専門学校理事長・校長であり医学博士でもある服部幸應氏を迎え、実行委員に石田純一さん、LABETTOLAオーナーシェフ落合務氏、フードアナリスト協会会長、高賀右近氏、つきぢ田村三代目、田村隆氏に、そして放送作家・脚本家の小山薫堂さんなど、食のスペシャリストたちが勢揃い。参加レストランには、ミシュランのフランス版、東京版ともに星を獲得している吉野建シェフの「レストランタテルヨシノ汐留」や、日本料理の名門「つきぢ田村」、「金田中庵」、「赤坂璃宮」に「mikuniMARUNOUCHI」など、日本を代表するレストランがずらり。\\u3000イベント期間の〜8月19日までは、特別協賛のダイナーズクラブカード会員、またはシティバンクに口座を持つシティゴールドメンバーが楽しめる先行期間となりますが、その後は誰でも参加できるので、日程のチェックは必須。\\u3000予約方法は必ず事前に、各店舗に問合せを行い「ジャパンレストラン・ウィーク2010」での予約であることを伝えればOK！憧れていたレストランの料理をリーズナブルにいただけるチャンスです！極上の味とラグジュアリーな空間を満喫。そんな幸せを実感できる「ジャパンレストラン・ウィーク2010」にぜひ参加しててみてはいかがですか？JAPANRESTAURANTWEEK2010-公式サイト'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:20.066620Z",
     "start_time": "2019-06-25T08:02:20.033721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文書0と文書1のcos類似度 : 0.025\n",
      "文書0と文書2のcos類似度 : 0.006\n",
      "文書0と文書3のcos類似度 : 0.043\n",
      "文書0と文書4のcos類似度 : 0.019\n",
      "文書0と文書5のcos類似度 : 0.009\n",
      "文書0と文書6のcos類似度 : 0.024\n",
      "文書0と文書7のcos類似度 : 0.047\n",
      "文書0と文書8のcos類似度 : 0.009\n",
      "文書0と文書9のcos類似度 : 0.042\n"
     ]
    }
   ],
   "source": [
    "freqdict0 = words_to_freqdict(docs2[0]) \n",
    "for i in range(9):\n",
    "    freqdict_i = words_to_freqdict(docs2[i+1]) \n",
    "    \n",
    "    cos0_i = calc_cos(freqdict0,freqdict_i)\n",
    "    \n",
    "    print('文書0と文書{}のcos類似度 : {:.3f}'.format(i+1, cos0_i)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "わずかに文書0と文書7のcos類似度が高くなった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:20.084160Z",
     "start_time": "2019-06-25T08:02:20.073101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2012-07-07T17:00:00+0900あなたの打たれ強さ度は?／イイ女を作る朝型生活など−【ライフスタイル】週間ランキング人間関係をスムーズにするヒントやライフハック、節約ネタなど、今すぐ役立つ情報が詰まったPeachyの「ライフスタイル」カテゴリ。このカテゴリのなかから、2012年6月27日〜7月4日の間に最も多く読まれた記事TOP5をご紹介します！第1位：1年間洗顔せずお化粧を続けるとこうなる!?365日分のお化粧を施したらドロドロになってしもうたよあなたはこんなことを考えたことがありますか？「私って、1年にどれくらい化粧品を使っているんだろう？」そんな素朴な疑問を、モデルを使って実際に目に見える形にしてしまった、2人のオランダ人アーティストがいました。彼らの名は、Lernert&Sander（ふたりとも男性です！）。ただしこのふたりが表現したかったことは、「人は1年に化粧品をどれくらい使うのか」ではなく、「どれくらい化粧品を使えば、人は自然な状態からとんでもない状態になるのか」ということ。彼らは「そうだ！\\u3000化粧品を1年分塗り重ねていけば、きっととんでもなくなるはずだ！」と、考えたわけです。第2位：あなたの「打たれ強さ度」を診断恋がうまくいかなかったり、理不尽なことで上司に怒られたり。生きていると凹むことっていっぱいありますよね。どん底気分のとき、あなたはすぐに回復できる人？\\u3000それともなかなか立ち直れないほう？\\u3000恋愛カウンセラー・ゆまさん監修の「究極の恋愛科学」では、あなたの「打たれ強さ度」をチェックできる心理テストを公開しています。第3位：レパートリーに悩むママ必見！夏のカンタン朝ごはんとは？あなたは毎日朝ごはんを食べていますか？\\u3000何かと慌しい朝。「時間がなくて毎日同じメニュー」なんて方も多いのではないでしょうか。ひとりだと適当にパンやおにぎりをコンビニで購入したり、ダイエットのために朝食を抜くこともあるかもしれませんが、家庭を持っているとそうはいきませんよね。第4位：いい女は朝を制す！朝型女子7の習慣「おはようございます」という挨拶からも気品が漂ってきそうな朝からシャキっと美しい女性、あなたの周りにいませんか？今回はそんな女性たちが実践しているであろう、いい女に欠かせない朝の習慣をまとめてみました。第5位：母性本能が強い女性6の特徴弱ってる男性を前に「この人は私がいないとダメだ、何とかしなきゃ！」とつい使命感に燃えてしまうことありませんか？今回はそんな母性本能が強い女性の特徴をまとめてみました。以上、先週の「ライフスタイル」カテゴリ週間ランキングでした！'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_clean[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 別の類似度手法を1つ調べて上の関数に組み込む(切り替えられるようにする)\n",
    "- Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:20.103819Z",
     "start_time": "2019-06-25T08:02:20.090270Z"
    }
   },
   "outputs": [],
   "source": [
    "#import gensim\n",
    "\n",
    "def tokenize(text):\n",
    "    t = Tokenizer()\n",
    "    tokens = t.tokenize(text)\n",
    "    word = []\n",
    "    for token in tokens:\n",
    "        part_of_speech = token.part_of_speech.split(\",\")[0]\n",
    "        #名詞だけで比較\n",
    "        if part_of_speech == \"名詞\":\n",
    "            word.append(token.surface)\n",
    "        '''\n",
    "        if part_of_speech == \"動詞\":\n",
    "            word.append(token.base_form)\n",
    "        if part_of_speech == \"形容詞\":\n",
    "            word.append(token.base_form)\n",
    "        if part_of_speech == \"形容動詞\":\n",
    "            word.append(token.base_form)\n",
    "        '''\n",
    "    return word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:23.435437Z",
     "start_time": "2019-06-25T08:02:20.113062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文書0と文書1の類似度 : 0.999\n",
      "文書0と文書2の類似度 : 0.999\n",
      "文書0と文書3の類似度 : 0.998\n",
      "文書0と文書4の類似度 : 0.997\n",
      "文書0と文書5の類似度 : 0.999\n",
      "文書0と文書6の類似度 : 0.999\n",
      "文書0と文書7の類似度 : 0.999\n",
      "文書0と文書8の類似度 : 0.998\n",
      "文書0と文書9の類似度 : 0.936\n"
     ]
    }
   ],
   "source": [
    "training_docs = []\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    words=tokenize(document_clean[i])\n",
    "\n",
    "    sent = TaggedDocument(words=words ,  tags=[i])\n",
    "\n",
    "    training_docs.append(sent)\n",
    "\n",
    "model = Doc2Vec(documents=training_docs, dm=1,\n",
    "                vector_size=300, window=8, min_count=1, workers=4)\n",
    "\n",
    "model.train(training_docs, total_examples=model.corpus_count, epochs=50)\n",
    "\n",
    "#cos類似度\n",
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "\n",
    "for i in range(9):\n",
    "    ret =cos_sim(model.docvecs[0], model.docvecs[i+1])\n",
    "    print('文書0と文書{}の類似度 : {:.3f}'.format(i+1, ret)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全体として類似度が高く、その中でも文書1,2,5,6との類似度が高くなった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:23.448352Z",
     "start_time": "2019-06-25T08:02:23.438319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2010-11-30T08:00:00+0900【SportsWatch】田中＆里田の交際、アプローチは里田からグラビアアイドル・ほしのあき＆騎手・三浦皇成がお互いのブログで交際を認めた日、東北楽天ゴールデンイーグルスのエース・田中将大とタレント・里田まいの交際もまた公のものとなったが、本日30日（火）発売の「週刊アサヒ芸能」（12.9号）では、「マー君を“ナンパ”した里田」との見出しで、両者の交際にまつわる関係者の証言を紹介した。同誌にコメントを寄せた芸能デスクによると、「周囲の事情はさておき、当人たちが盛り上がっているのは確か。結婚も完全に視野に入れているようで、すでに新居を探しているとの話まである」という。また、二人の交際は里田からのアプローチによるものとのことで、前出の芸能デスクは、「2人は昨年末の番組共演時に、里田から猛アタック。『一緒に食事でも』と誘い、春頃にはつきあい始めた。里田は仲のいいスザンヌ（24）、木下優樹菜（22）には、早くから相談していたし、周囲にも浮かれてしゃべりまくっていた。次世代エースをゲットしたわけですから、賞味期限切れ間近の里田にすれば、してやったりでしょう」とも語っている。ちなみに、同じく同誌にコメントする球団関係者は、「高校時代は同じ高校の女子生徒と在学中の3年間、ずっとつきあっていましたね。基本はオクテ。プロ入り後にキャバクラなども覚えましたが、まぁ、モテるタイプではないし、女あしらいも不慣れ。高校時代はかなりワガママで、元カノは苦労が絶えなかったと聞いています。同年代の女より、里田のような姉さんタイプのほうが勝負の世界では向いているケースも多いですからね」と明かしており、この交際も田中にとっては“吉”とした。・週刊アサヒ芸能［ライト版］＜デジタル＞（PC版）・週刊アサヒ芸能（モバイル版）'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_clean[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### なぜそのような結果になったのか考察する\n",
    "- 今回使用した文書の中では人の目から見ても特段関連性は考えにくい\n",
    "- そのため、cos類似度で低い値を出したのは理解できるが、doc2vecで高い値が返されたのは理解しがたい\n",
    "- 最初の日付構成が一致している等により、類似度が高くなった可能性もある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】感情分析\n",
    "**目的**\n",
    "\n",
    "- NLP定番の感情分析の経験\n",
    "- 英語の処理の実践\n",
    "\n",
    "以下からLarge Movie Review Datasetをダウンロードしてください。\n",
    "[IMDBレビュー](http://ai.stanford.edu/~amaas/data/sentiment/)\n",
    "\n",
    "同じようにwgetコマンドでも可能です。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:37.991295Z",
     "start_time": "2019-06-25T08:02:23.451979Z"
    }
   },
   "outputs": [],
   "source": [
    "# サブフォルダまで自動で読み込んでもらう\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "train_review = load_files('./aclImdb/train/', encoding='utf-8')\n",
    "train_text, train_y = train_review.data, train_review.target\n",
    "\n",
    "test_review = load_files('./aclImdb/test/', encoding='utf-8')\n",
    "test_text, test_y = test_review.data, test_review.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問】\n",
    "IMDBという映画に対するレビューのデータセットを使います。\n",
    "良いレビューか悪いレビューかを判定するモデルを作ってください。\n",
    "テストデータに対する正解率が90%を超えるまで、調査=>実行=>改善を繰り返してください。\n",
    "前処理になぜその処理をしたのかを書くとエンジニアリングとしても完璧です。  \n",
    "**注意**: 必ず間違っていたデータを観察してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:02:43.775707Z",
     "start_time": "2019-06-25T08:02:37.994349Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(train_text)\n",
    "reviews_test_clean = preprocess_reviews(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:03:03.952053Z",
     "start_time": "2019-06-25T08:02:43.778801Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:03:15.817887Z",
     "start_time": "2019-06-25T08:03:03.955466Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yusuke-saruya/.pyenv/versions/anaconda3-2018.12/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/Users/yusuke-saruya/.pyenv/versions/anaconda3-2018.12/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.87168\n",
      "Accuracy for C=0.05: 0.87856\n",
      "Accuracy for C=0.25: 0.87776\n",
      "Accuracy for C=0.5: 0.8752\n",
      "Accuracy for C=1: 0.8728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, train_y, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:03:17.987236Z",
     "start_time": "2019-06-25T08:03:15.823158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.88152\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(C=0.05)\n",
    "final_model.fit(X, train_y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(test_y, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 間違っているデータの観察"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 悪いレビューだが、良い(1)と予測されたレビュー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:03:18.050275Z",
     "start_time": "2019-06-25T08:03:17.994650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 25, 32, 34, 57, 65, 70, 71, 73, 91])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#対象インデックス確認\n",
    "np.where(([test_y!=final_model.predict(X_test)]) & (test_y==0))[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:03:18.128784Z",
     "start_time": "2019-06-25T08:03:18.062259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test : 0\n",
      "y_predict : 1\n",
      "predict_prob : 0.786\n",
      "\n",
      "Even Disney are guilty of the cash cow disease, after the roaring success of The Love Bug in 1968, the house of mouse cashed in with Herbie Rides Again, Herbie Goes To Monte Carlo, and Herbie Goes Bananas. Neither sequel capturing the charm and inoffensive appeal of The Love Bug back in 68, in this one we find race driver Jim Douglas and his sidekick Wheely Applegate, entering Herbie in the Monte Carlo Rally. Naturally things outside of the race start to take over priorities, they get mixed up in a diamond robbery and Herbie falls in love with another car!. The car stunts are of course pleasant and easy on the eye, and it would be churlish of me to really vent venom on such a friendly piece of fluff, it's just that the film goes nowhere fast and personally now i can see it for the coin motivated piece of work it is. Still you get to see Herbie take a bath, foil the baddies and of course dance for the lady in his life, so something there for everyone i think....................4/10.\n"
     ]
    }
   ],
   "source": [
    "print('y_test : {}'.format(test_y[11]))\n",
    "print('y_predict : {}'.format(final_model.predict(X_test)[11]))\n",
    "print('predict_prob : {:.3f}'.format(final_model.predict_proba(X_test)[:,1][11]))\n",
    "print()\n",
    "print(test_text[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- レビューというより、映画の要約であり、人が読んでも良いか悪いか判断がし辛い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:03:18.211029Z",
     "start_time": "2019-06-25T08:03:18.135461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test : 0\n",
      "y_predict : 1\n",
      "predict_prob : 0.806\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"While The Twilight Zone was a wonderful show, it was also very uneven--with some great episodes, some lousy ones and many in between. Don't believe the die-hard fans--there were some stinkers and this was definitely one of them.<br /><br />In a plot that is obviously meant to be an attack on Fidel Castro, a near lookalike (Peter Falk in lots of makeup and a beard) obtains a magic mirror that allows him to realize who all his enemies are so he can liquidate them. While I do believe that Castro is a thug and dictator (and tens of thousands of refugees and political prisoners will attest to this), it's amazing how this sort of preachy episode actually makes audiences laugh at the American efforts to marginalize the creep and actually makes Castro seem okay!! Think about it--Serling and company wanted to hurt Castro but instead only seemed to be obvious, preachy and silly in the process.<br /><br />It's indeed bad--almost laughably bad when seen today.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('y_test : {}'.format(test_y[25]))\n",
    "print('y_predict : {}'.format(final_model.predict(X_test)[25]))\n",
    "print('predict_prob : {:.3f}'.format(final_model.predict_proba(X_test)[:,1][25]))\n",
    "print()\n",
    "test_text[25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 冒頭に一部分だけ良い評価をしている\n",
    "- 直接的に悪いワードが少なく、良いレビューとして予測された？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 良いレビューだが、悪い(0)と予測されたレビュー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:03:18.281118Z",
     "start_time": "2019-06-25T08:03:18.216273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 16,  37,  43,  56,  68,  79,  93, 131, 132, 147])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#対象インデックス確認\n",
    "np.where(([test_y!=final_model.predict(X_test)]) & (test_y==1))[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:03:18.368867Z",
     "start_time": "2019-06-25T08:03:18.285969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test : 1\n",
      "y_predict : 0\n",
      "predict_prob : 0.478\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The great James Cagney, top-billed in big letters, doesn\\'t show up till the movie\\'s second third, and probably has less screen time than Dudley Digges, who plays the eee-vill reform-school potentate. But when Jimmy arrives, as a deputy commissioner of something-or-other out to reform reform schools, he slashes the air with his hands and jumps on the balls of his feet and spits out punchy Warners-First National dialogue with all the customary, and expected, panache. The psychology in this crisp antique, one of Warners\\' many efforts to assert its place as the \"socially conscious\" studio, doesn\\'t run deep: Digges is bad just because the script requires him to be, and there\\'s the quaint notion that juvenile delinquents will turn into swell kids if they\\'re just given a dash of autonomy. But it\\'s made in that spare, fast style that the studio specialized in, and it never bores. Frankie Darro, who got into all kinds of onscreen trouble during a brief tenure as Warners\\' favorite Rotten Street Kid, is an ideal JD -- a handsome, charismatic toughie with a pug nose and a hate-filled stare that could wither steel. No kid actor today can touch him.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('y_test : {}'.format(test_y[16]))\n",
    "print('y_predict : {}'.format(final_model.predict(X_test)[16]))\n",
    "print('predict_prob : {:.3f}'.format(final_model.predict_proba(X_test)[:,1][16]))\n",
    "print()\n",
    "test_text[16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bores(退屈な)が悪いレビュー結果に影響したか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T08:03:18.475651Z",
     "start_time": "2019-06-25T08:03:18.377991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test : 1\n",
      "y_predict : 0\n",
      "predict_prob : 0.193\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You have to be awfully patient to sit through a film with one-liners so flat and unfunny that you wonder what all the fuss was about when WHISTLING IN THE DARK opened to such an enthusiastic greeting from audiences in the 1940s.<br /><br />On top of some weak one-liners and ordinary sight gags, the plot is as far-fetched as the tales The Fox (Red Skelton) tells his radio audience. You have to wonder why anyone would think he could come up with a real-life solution on how to commit the perfect crime and get away with it. But then, that\\'s how unrealistic the comedy is.<br /><br />But--if you\\'re a true Red Skelton fan and enjoy a look back at how comedies were made in the \\'40s--you can at least enjoy the amiable cast supporting him. Ann Rutherford and Virginia Grey do nicely as his love interest and Conrad Veidt, as always, makes an interesting villain. One of his more amusing moments is his reaction to Skelton explaining the mysteries of wearing turbans. \"I never knew that,\" he muses, impressed by a minor point that is cleverly introduced.<br /><br />All in all, typical nonsense that requires you to accept the lack of credibility and just accept the gags as they are. Not always easy for a discriminating viewer as many of them simply fall flat, the way many comedies of this era do because the novelty of the sight gags and one-liners has simply worn off.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('y_test : {}'.format(test_y[37]))\n",
    "print('y_predict : {}'.format(final_model.predict(X_test)[37]))\n",
    "print('predict_prob : {:.3f}'.format(final_model.predict_proba(X_test)[:,1][37]))\n",
    "print()\n",
    "test_text[37]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 文章前半部分に、映画背景を知らなければよく理解できないでしょう的な内容があり、悪い結果に影響した？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】分散表現(アドバンス)\n",
    "**目的**\n",
    "\n",
    "- 主流である分散表現の理解\n",
    "\n",
    "分散表現の詳細はこちらを参考にしてください\n",
    "\n",
    "**【問】**\n",
    "以下の中から一つ選んで分散表現を獲得し、\n",
    "好きな単語群をt-SNE,PCAなどを用いて可視化してください。\n",
    "コーパスは自由です。\n",
    "\n",
    "- Word2Vec-CBoW(2〜3人)\n",
    "- Word2Vec-skip-gram(2〜3人)\n",
    "- fastText(2〜3人)\n",
    "\n",
    "また以下の4点についてもノートに書いてください。\n",
    "\n",
    "分布仮説とは何か？\n",
    "分散表現を得ることのメリットは何か？\n",
    "上で選んだモデルのメリット、デメリットは何か？\n",
    "なぜそのパラメータを選んだのか？\n",
    "\n",
    "**※省略**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題8】自然言語処理の応用事例\n",
    "**目的**\n",
    "\n",
    "- NLPの情報共有  \n",
    "現在自然言語処理はどのような企業でどのように活用されているか？   \n",
    "1つ例をあげて3~5分で発表してください。   \n",
    "(例)メルカリは商品説明をTF-IDFを用いてベクトル化して商品の異常検知を行っている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LegalForce\n",
    "- 2019年4月2日に正式版リリースとなった契約書自動レビューソフトウェア\n",
    "- １秒で不利な条文や欠落条項を指摘\n",
    "- 類似契約書のレコメンド\n",
    "- 自社法務部門チェックの時間が大幅に軽減される\n",
    "- 前職の営業時代にあったらとても嬉しいと思う。法務部門の契約書チェックに時間がかかり、とても苦労した"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
